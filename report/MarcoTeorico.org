#+TITLE: Marco Teorico
#+AUTHOR:  Ruben Ezequiel Torti Lopez
#+EMAIL:   ret0110@famaf.unc.edu.ar
#+OPTIONS: H:5 title:nil creator:nil timestamp:nil skip:nil toc:nil
#+STARTUP: indent hideblocks
#+TAGS: noexport(n)
#+EXPORT_SELECT_TAGS: export
#+EXPORT_EXCLUDE_TAGS: noexport
#+PROPERTY: session *R* 

#+LATEX_HEADER: \usepackage[T1]{fontenc}
#+LATEX_HEADER: \usepackage[utf8]{inputenc}
#+LATEX_HEADER: \usepackage{ifthen,figlatex}
#+LATEX_HEADER: \usepackage{longtable}
#+LATEX_HEADER: \usepackage{float}
#+LATEX_HEADER: \usepackage{wrapfig}
#+LATEX_HEADER: \usepackage{subfigure}
#+LATEX_HEADER: \usepackage{xspace}
#+LATEX_HEADER: \usepackage[spanish]{babel}
#+LATEX_HEADER: \usepackage{url}\urlstyle{sf}
#+LATEX_HEADER: \usepackage{amscd}
#+LATEX_HEADER: \usepackage{wrapfig}

#+LATEX_HEADER: \newcommand{\cl}{\textit{clasificadores lineales}}
#+LATEX_HEADER: \newcommand{\losss}{\textit{funciones de pérdida}}
#+LATEX_HEADER: \newcommand{\dg}{\textit{descenso de gradiente}}
#+LATEX_HEADER: \newcommand{\back}{\textit{backpropagation}}
#+LATEX_HEADER: \newcommand{\nn}{\textit{redes neuronales}}
#+LATEX_HEADER: \newcommand{\svms}{\textit{Support Vector Machines}}
#+LATEX_HEADER: \newcommand{\bow}{\textit{Bag of Words}}
#+LATEX_HEADER: \newcommand{\features}{\textit{features}}
#+LATEX_HEADER: \newcommand{\scores}{\textit{scores}}
#+LATEX_HEADER: \newcommand{\sift}{\textit{SIFT}}
#+LATEX_HEADER: \newcommand{\weigths}{\(\boldsymbol{W}\)}
#+LATEX_HEADER: \newcommand{\img}{\(\boldsymbol{x_i}\)}
#+LATEX_HEADER: \newcommand{\bias}{\(\boldsymbol{b}\)}
#+LATEX_HEADER: \newcommand{\func}{\(\boldsymbol{f}\)}
#+LATEX_HEADER: \newcommand{\loss}{\(\boldsymbol{L}\)}

#+LATEX_HEADER: \newcommand{\ml}{\textit{machine learning}}
#+LATEX_HEADER: \newcommand{\ML}{\textit{Machine Learning}}
#+LATEX_HEADER: \newcommand{\dl}{\textit{deep learning}}
#+LATEX_HEADER: \newcommand{\DL}{\textit{Deep Learning}}
#+LATEX_HEADER: \newcommand{\cnn}{\textit{convolutional neural networks}}
#+LATEX_HEADER: \newcommand{\CNN}{\textit{Convolutional Neural Networks}}

* Introducción
** Qué es la visión por computadoras

Para los seres humanos, percibir el mundo que nos rodea es una tarea
fácil. Millones de años de evolución nos han dotado con un sistema
visual altamente sofisticado que nos permite reconocer patrones muy
complejos del mundo tridimensional en el que vivimos. Distinguir
sombras, color, formas, o incluso cosas más generales, como
movimiento, potenciales amenazas o rostros de conocidos, son algunas
de las actividades que nuestros cerebros realizan casi de manera
inconsciente. Y si bien estas tareas pueden ser fáciles para nosotros,
no es tal el caso para las computadoras.

Richard Szeliski caracteriza a la visión por computadoras como un
\textit{problema inverso}, es decir, se busca describir el mundo que
uno ve en una o más imágenes y reconstruir sus propiedades tales como
forma, iluminación y distribuciones de color \cite{szeliski}

Una de las áreas principales de de la visión por computadoras es la
clasificación de imágenes. Es decir, dada una imagen y un conjunto de
categorías, determinar a cual de las categorías pertenece esa
imagen. Tener un buen entendimiento de los algoritmos de clasificación
es crucial para desarrollar otras tareas dentro de la visión por
computadoras, dado que muchos problemas pueden ser reducidos a
clasificación: detección de objetos, \textit{captioning} de imágenes,
segmentación, etc.

Sin embargo, es un problema más difícil de lo que aparenta. Una
fotografía es solamente un conjunto de números (píxeles), entonces
¿cómo darle significado semántico a un conjunto de números? Se podría
pensar en elaborar alguna métrica de distancia con los píxeles otra
imagen la cual sepamos está en la misma categoría, y si la distancia
es menor a un cierto umbral sabríamos que ambas pertenecen a la misma
clase. Sin embargo este enfoque carece de robustez, ya que el menor
cambio de \textit{iluminación} en las fotos podría alterar las
métricas y confundir a nuestro modelo. No solamente eso, los objetos
en las imágenes podrían estar ocultos por el ambiente
(\textit{oclusión}), o en una posición diferente
(\textit{deformación}), o ser exactamente iguales, pero variar en
colores y pequeños detalles (\textit{variación intraclase}).

Diferentes métodos se han utilizado a lo largo de la historia para
taclear este problema: \svms, árboles de decisión, \bow, etc. En la
mayoría de los casos las \features y descriptores que se extraían de
las imágenes debían ser implementadas manualmente (por ejemplo: histogramas de
colores o descriptores \sift \cite{Lowe-SIFT}).

En los últimos años toda la parafernalia relativa a la clasificación
de imágenes fue ampliamente superada por las Redes Neuronales
Convolucionales. Desde el año 2010, todos los equipos ganadores del
desafío Imagenet usaron Redes Neuronales Convolucionales, cada vez con
resultados más precisos \cite{imagenet}.

A pesar de haber tenido su golpe de popularidad en los últimos 6 años,
los primeros esbozos de modelar redes neuronales artificiales datan de
1958, cuando Frank Rosenblatt ideó el \textit{perceptron}, un
algoritmo para reconocimiento de patrones basado en una red de dos
capas de aprendizaje \cite{perceptron}. Sin embargo, en 1969 se
estableció que el poder de cómputo disponible en ese entonces no
bastaba para poder entrenar y correr grandes redes neuronales,
implicando que el área se estancara durante años \cite{minsky}. Tan
así es, que recién en 2006, con el abaratamiento de costos en hardware
de alto desempeño se pudieron implementar arquitecturas más complejas
(no necesariamente nuevas) y redes neuronales más profundas, algo que
se conoce como \DL, y que explicaremos más adelante.



** Gran cantidad de datos

Para poder entrenar Redes Neuronales Profundas, es necesario contar
con un conjunto de datos anotados muy grande, cuyos tamaños pueden ir
de los miles hasta los cientos de millones de imágenes. En la mayoría de los
casos, se requiere un gran esfuerzo humano para etiquetar tantas
imágenes.

La buena noticia es que actualmente contamos con una increíble
cantidad de imágenes para etiquetar. Para 2016, Cisco estima que el
51\% del trafico de Internet va a provenir de dispositivos WiFi, tales
como celulares, \textit{tablets}, \textit{smart TV's}, etc.  Más aún,
se estima que para el 2019 el 80\% del tráfico IP va a ser en forma de
píxeles (multimedia), superando al 67\% que existente en 2014
\cite{ciscostats}. Como tendencia podemos nombrar a Youtube, donde la
mitad de los videos son subidos desde dispositivos móviles
\cite{youtustats}.
 
Por otro lado, las redes sociales más populares como Facebook, Flickr
o Instagram almacenan una gigantesca cantidad de imágenes, contando la
última con más de 80 millones de imágenes subidas por día
\cite{instastats}. 

Es practicamente imposible contar con los recursos suficientes para
anotar tantos videos, imágenes y demás contenido multimedia. Para ello
debemos contar con herramientas de visión por computadoras para
filtrar, procesar y dar un sentido semántico a las imágenes.

Pero no podemos clasificar las imágenes si no contamos con una
herramienta poderosa que nos ayude, de la misma manera que no podemos
entrenar una herramienta poderosa si no tenemos la suficiente cantidad
de datos anotados.

Una posible solución a esto es la propuesta por \cite{LSM2015}, en
donde en vez de utilizar un gran dataset anotado a mano, proponen
utilizar información odométrica disponible en cámaras (giróscopos,
acelerómetros, etc) para pre-entrenar redes neuronales profundas, y
luego entrenarlas utilizando el dataset que se desee, obteniendo la
ventaja de no necesitar un dataset tan grande para lograr buena
precisión.

En este trabajo final nos proponemos reproducir este paper, analizando
cada paso para luego proponer mejoras y aplicaciones al mundo real.

El trabajo está organizado como sigue:
*** TODO organizacion del trabajo

* Marco Teórico
** Aprendizaje Automatico
*** Introducción

Las tecnicas de aprendizaje automatico tienen como objetivo
identificar patrones en conjuntos de datos utilizando herramientas de
la estadistica, teoria de la informacion, calculo y optimizacion entre
otras. De esta manera se pueden automatizar tareas, como por ejemplo
del filtro de correo basura (\textit{spam}), la verificacion de
rostros o incluso prediccion de precios en el mercado.

El aprendizaje automatico adquiere relevancia cuando las tareas que se
desean automatizar son demasiado complejas para programarse
directamente. Por ejemplo la verificacion de rostros debe tener en
cuenta detalles como variaciones en sombra, color, orientacion, por no
mencionar las diferentes caracteristicas que hay que extraer de una
cara para diferenciarla de otra (arrugas, prominencias y otros
rasgos).  Otro caso es el analisis de grandes volumenes de datos, como
estadisticas del clima para crear nuevos modelos.

Hay varios paradigmas o ejes dentro del aprendizaje automatico que
definen las caracteristicas de los algoritmos, las tecnicas de
entrenamiento y las potenciales aplicaciones de esos modelos:

**** Aprendizaje supervisado vs. no supervisado

Cuando se poseen anotaciones o alguna clase de etiqueta sobre los
datos a aprender, hablamos de aprendizaje supervisado. Retomando el
caso del verificador de rostros, las etiquetas serian el nombre o
algun identificador de cada persona y nuestro clasificador aprenderia
a diferenciar las caras tomando como referencia las anotaciones.

Por otro lado, cuando los datos no estan categorizados de antemano
hablamos de aprendizaje no supervisado. Por ejemplo, si se contara con
una lista de casas con sus respectivos precios, su area en metros
cubicos y cantidad de habitaciones y quisieramos encontrar alguna
relacion entre ellas. Los algoritmos no supervisados trabajan
netamente sobre los datos \textit{tal como estan}.

**** Aprendizaje pasivo vs. activo

El aprendizaje pasivo implica utilizar solamente los datos ya
existentes. El aprendizaje activo se refiere a interactuar con el
ambiente para obtener informacion, como por ejemplo preguntar a un
usuario si un rostro es de cierta persona.

**** Aprendizaje \textit{online} vs. estadistico (\textit{batch learning})

En el aprendizaje \textit{online} los datos estan disponibles de
manera secuencial, actualizando el modelo en cada paso para lograr
mejores predicciones/clasificaciones. En el aprendizaje estadistico
primero se analiza una gran cantidad de datos (tal vez la totalidad
del conjunto) y recien ahi se pueden obtener conclusiones o un modelo
final.

*** Clasificadores lineales

Un clasificador lineal combina linealmente las caracteristicas (o
\textit{features}) de los datos de entrada para determinar a que clase
pertenecen los mismos, usualmente entrenado mediante tecnicas de
aprendizaje supervisado.

Supongamos que queremos clasificar imagenes, es decir, asignar una
etiqueta a un conjunto de píxeles. Para ello vamos a definir una
función \func{} que mapee píxeles \(\boldsymbol{x}\) a probablidades
de cada etiqueta (\textit{scores}). Supongamos que contamos con un
conjunto de datos de imágenes \(\boldsymbol{x_i} \in
\boldsymbol{R^{D}}\), donde \(\boldsymbol{i = 1\cdots N}\),
\(\boldsymbol{D}\) es la dimensión de cada imagen y \(\boldsymbol{y_i
= 1\cdots K}\) es la etiqueta asociada. Es decir, tenemos
\(\boldsymbol{N}\) imágenes y \(\boldsymbol{K}\) categorías.

Vamos a definir nuestra función \(\boldsymbol{f\colon R^{D} \mapsto
R^{K}}\) como un mapeo lineal entre píxeles y \scores:

\begin{equation}
     \boldsymbol{f(x_i, W, b)= W x_i + b}
\end{equation}

Estamos asumiendo que la imagen \img{} es un vector de una sola columna
\([D \times 1]\), \weights{} es una matriz \([K \times D]\) y \bias{} es
otro vector \([K \times 1]\). A menudo la matriz \weights{} es llamada
los \textit{pesos} de \func{}, y a \bias{} el \textit{vector de sesgo}
dado que influencia los \scores{} de salida, pero sin interactuar con
\img{}.

Para entender mejor a los clasificadores lineales, podemos verlos de
la siguiente manera: si la imagen tiene \(32\times32\) píxeles y la
representamos con un vector columna de dimensión \(D\), entonces en
ese espacio \textit{D-dimensional} la imagen es solamente un
punto. Nuestro clasificador lineal entonces define una "línea" que
separa cada clase dentro de ese espacio multidimensional. Notar que en
realidad, la multiplicación \(W x_i\) está evaluado \(K\)
clasificadores en paralelo, donde cada uno es una fila de \weights{}.

Mas adelante veremos como definir \weights{} y \bias{} para obtener un
buen clasificador.

*** Entrenamiento
**** Función de costo

Una función de costo nos ayuda a saber que tan bien o mal está
actuando nuestro clasificador. Es decir, si la tasa de error del
clasificador es muy alta, el costo o la \textit{pérdida} será muy alta
y viceversa. Hay muchos tipos de funciones de costo, pero la idea
subyacente es la misma y puede ser expresada en la siguiente ecuación:

\begin{equation}
\boldsymbol{L}(\theta) = \frac{1}{N} \sum^{N}_{i} L(f(x_i;\theta), y_i)
\end{equation}

donde \(L\) es la función de pérdidad individual de cada muestra en el
conjunto de datos, \(f(x_i;\theta)\) es la predicción del modelo sobre
una muestra \(x_i\) con parámetros \(\theta\), \(y_i\) es el objetivo
(por ejemplo, la etiqueta de cada muestra del conjunto de datos en una
tarea de clasificación).

Un ejemplo de función de perdidad popular es la función de pérdida de
\texit{máquinas de vectores de soporte multiclase}:

\begin{equation}
     L_i = \sum_{j \neq i} \max{(0, f(x_i; \theta) - y_{i} + \Delta) }
\end{equation}

Se puede observar que esta función de pérdida busca que la clase
correcta tenga un puntaje más alto que las otras por un margen
\(\Delta\)

Cuando tenemos una función con la forma \( \max{(0,\_)} \) a menudo se
la llama función de pérdida bisagra (\textit{hinge loss} en inglés).

**** Clasificador \textit{Softmax}

La función \textit{Softmax} tiene la siguiente forma:

\begin{equation}
    \sigma(x)_j =  \frac{e^{f(x;\theta)_{j}}} {\sum_{k} e^{f(x;\theta)_{k}}}
\end{equation}

Actúa tomando un vector de valores reales arbitrarios y
transformándolos en un vector de probabilidades normalizadas (cuya
suma da uno).

Por lo tanto el clasificador Softmax tiene una función de pérdida
diferente. En vez de tratar a los resultados como puntajes para cada
clase (lo cual puede ser confuso y dificíl de comparar), Softmax
devuelve probabilidades normalizadas para cada clase.

Un clasificador Softmax no modifica la funcion \func{} que ya
conocemos, pero sí interpreta los puntajes como probabilidades
logarítmicas sin normalizar, reemplazando la pérdida bisagra por una
\textit{entropía cruzada}:

\begin{equation}
     L_i = - \log \bigg( \frac{\exp{f_{y_{i}}}} {\sum_j \exp{f_j}}\bigg)
\end{equation}

Que es equivalente a:

\begin{equation}
     L_i = - f_{y_{i}} + \log {\Big( \sum_j \exp{f_j}}\Big)}
\end{equation}

Donde \(f_{y_{i}}\) representa el elemento \textit{j}-ésimo del vector
de puntajes calculado por \(f\). Nuevamente, la pérdida total es el
promedio de las pérdidas de cada imagen.

**** TODO (MEJORAR ESCRITURA. ECUACIONES) Optimización: Descenso de Gradiente

Ya contamos con una función para medir que tan bien o que tan mal está
comportándose nuestro modelo, la \textit{función de pérdida}. Como se
puede observar, esta función depende de nuestro \weights{} y las
imágenes (o \features{} que estemos usando). Nosotros no tenemos
control sobre nuestro conjunto de datos de entrenamiento, pero sí
podemos modificar los parámetros de \weights{} para producir la menor
pérdida posible.

Vamos ahora a analizar uno de los métodos más usados en redes
neuronales para optimizar la pérdida: descenso de gradiente.

Tomemos un escenario hipotético: imaginemos por un momento que una
persona con los ojos vendados está atrapada entre montañas y busca
llegar al valle. Una manera de llegar al valle es probar dando un
pequeño paso a su alrededor, y "sentir" hacia donde desciende más
rápido la montaña, sólo valiéndose de la información local para
moverse. Cuando finalmente esté seguro hacia donde descender, dará
varios pasos en esa dirección, se detendrá y volverá a
observar. Sabemos que eventualmente llegará al fondo del valle, pues
lo único que tiene que hacer es seguir bajando por la pendiente de la
montaña.

Formalmente, la pendiente de la montaña es la pendiente de la función
de pérdida \loss{} que estemos utilizando, la elección de hacia donde
bajar se corresponde con el cálculo de la derivada de la función de
pérdida, mientras que la cantidad de pasos que realice se corresponde
con la \textit{tasa de aprendizaje}. En otras palabras, lo que estamos
haciendo es buscar el mínimo de \loss{}, y en consecuencia, el conjunto
de parámetros de \weights{} que minimicen el error.

***** TODO AGREGAR FORMULA MATEMATICA DE COMO UPDATEAR LOS PESOS Wn  = Wanterior - gradiente
**** \textit{Backpropagation}

Notemos que \loss{} es una función que depende de las imágenes de
entrada \img{}, \weights{} y \bias{}. Sin embargo el conjunto de datos
de entrenamiento es algo fijo en nuestro modelo, por lo que sólo nos
interesa calcular el gradiente sobre \weights{} y \bias{} para poder
actualizar sus parámetros.

En una función de una dimensión, la derivada se expresa como:
\begin{equation}
     \boldsymbol{\frac{df(x)}{dx} = \lim_{h\to 0} \frac{f(x + h) - f(x)}{h} }
\end{equation}

Cuando la función toma un vector de números en vez de uno solo, a las
derivadas las llamamos derivadas parciales y el \textit{gradiente} es
simplemente un vector de esas derivadas. Por ejemplo, sea \(f\) una
función que toma dos parámetros \(x\) e \(y\), entonces el gradiente
de \(f\) es \(\nabla f = [\frac{\partial f}{\partial x},
\frac{\partial f}{\partial y}]\)

Usualmente podemos diferenciar con métodos numéricos, asignando a
\(h\) números muy pequeños por ejemplo, pero esto requiere de muchos
cálculos, es lento y tan sólo una aproximación. Veremos más
adelante que la función \loss{} de las redes neuronales suele tener
decenas de millones de parámetros, y realizar tantas
operaciones para una sola actualización de los parámetros no es
conveniente. En la práctica usaremos el cálculo analítico del
gradiente, en el cual derivamos una fórmula directa que es muy rápida
de computar valiéndonos de la \textit{regla de la cadena}.

La \textit{regla de la cadena} nos ayuda a descomponer el cálculo del
gradiente de expresiones complejas en pequeños pasos. Por ejemplo,
tomemos la función:

\begin{equation}
    f(x,y,z) = \frac{x}{y^2} + z
\end{equation}

Si quisieramos obtener su gradiente en \(x\) de la manera tradicional,
calculando el cociente de \(f(x+h) - f(x)\) con \(h\) cuando \({h \to
0}\) deberíamos realizar muchos cálculos computacionalmente
costosos. En cambio, podemos ver a \(f\) como una composición de
funciones:

\begin{equation}
    f(x,y,z) = \frac{x}{y^2} + z = q + z
\end{equation}

Y calcular su gradiente valiéndonos de la \textit{regla de la cadena}:

\begin{equation}
\frac{\partial f}{\partial z} = q
\frac{\partial f}{\partial q} = z

\frac{\partial f}{\partial x} = \frac{\partial f}{\partial q} \frac{\partial q}{\partial x} = \frac{z}{y^2}
\frac{\partial f}{\partial y} = \frac{\partial f}{\partial q} \frac{\partial q}{\partial y} = \frac{-2zx}{y^3}
\end{equation}

Ahora podemos comenzar a estructurar nuestro algoritmo de optimización
en dos pasos: primero, evaluamos nuestra función \loss{} en los
parámetros actuales (\textit{forward pass}). Luego, partiendo de ese
resultado calculamos el gradiente en cada variable utilizando la
\texit{regla de la cadena}. De esta manera "propagamos" el error de la
predicción hacia atrás (\textit{backpropagation}) y corregimos
ligeramente los pesos para mejorar las futuras predicciones.

Una vez que contamos con el gradiente, actualizamos los parámetros de
\loss{} restándole un porcentaje del gradiente negativo calculado
(negativo porque queremos ir en dirección opuesta a donde crece la
función, o sea, ir a su mínimo). Ese porcentaje es llamado
\textit{tasa de aprendizaje} (\textit{learning rate}) y suele ser uno
de los parámetros más difíciles de elegir, ya que la calidad y rapidez
de aprendizaje dependen de él.

Idealmente computaríamos el gradiente sobre todo el conjunto de datos,
actualizaríamos los parámetros, y repetiríamos el ciclo hasta
conseguir un buen resultado. Sin embargo los conjuntos de datos para
entrenar las redes neuronales suelen tener cientos de miles o incluso
millones de imágenes, por lo cual se utiliza una técnica llamada
\textit{Descenso de Gradiente Estocástico} o \textit{SGD} por sus
siglas en inglés, en el cual se calcula el gradiente para una cantidad
predeterminada de imágenes (\textit{batches}), se actualizan los
parámetros y se vuelve a repetir el ciclo con otro subconjunto
distinto. Esto parte de la suposición de que todas las imágenes del
conjunto de datos estan correlacionadas entre sí. En teoría
\textit{SGD} utiliza una sola imagen por batch, pero dada la alta
paralelización que provee el hardware actual, conviene hacer lotes de
imágenes de 62, 128, 512 imágenes. El tamaño de los \textit{batches}
no es estrictamente un hiperparámetro que uno pueda
\textit{cross-}validar, sino que más bien depende del hardware sobre
el que se esté entrenando la red (en general se eligen potencias de
dos por cuestiones de eficiencia).

***** TODO graficar el grafo de computacion de la funcion de arriba.
***** TODO pseudocódigo de optimizacion

** Redes Neuronales

Hasta ahora vimos clasificadores lineales. Si conectaramos la salida
de un clasificador lineal \(s_1=W_1x+b_1\) con la entrada de otro
clasificador \(s_2=W_2y+b_2\), entonces obtendríamos un tercero:

\begin{equation}
s_3 = W_2 (W_1x + b_1) + b_2 = (W_2 W_1) x + (W_2 b_1) + b_2
s_3 = W_3 x + b_3
\end{equation}

Es fácil hacer un chequeo de dimensiones para ver que efectivamente
podemos "colapsar" las matrices \(W_2\) y \(W_1\) en una sola, por lo
cual terminamos con otro clasificador lineal.

Notemos que por más que combinemos miles de clasificadores lineales
vamos a obtener un nuevo clasificador también lineal.  Una manera de
romper la linealidad de estas "capas" de clasificadores es, por
ejemplo, agregar lo que se llama \textit{función de activación}:
 
\begin{equation}
    s = W_2 \max{0, W_1 x + b_1} + b_2
\end{equation}
 
 
Lo que acabamos de definir es una red neuronal básica de dos capas, de
una neurona cada una.

Una sola neurona puede funcionar como un clasificador también (notar
el parecido con los clasificadores lineales), siempre que se eliga la
función de pérdida adecuada.
 
** Funciones de activación comunes

Se han propuesto varias funciones de activación a lo largo de los
años. Inicialmente se intentó simular el comportamiento de las
conexiones sinápticas entre las neuronas mediante funciones como la
Sigmoide (\(\sigma\)) y la Tangente Hiperbólica (\(\tanh\), aunque
ambas ya estan en desuso por no poseer buenas propiedades (saturación
de gradiente).

Consecuentemente, nos concentraremos en un tipo especifico de función
de activación, los Rectificadores Lineales o ReLU por sus siglas en
inglés. Los rectificadores lineales son muy populares en las redes
convolucionales debido a sus buenas propiedades.
**** TODO CITAR BIBLIOGRAFIA CON PROBLEMA DE SATURACION DE GRADIENTE.
*** \textit{ReLU}
Una unidad ReLU establece un umbral en \(0\) a la salida de la
neurona. Es decir, la activación de una neurona va a ser \(0\) si su
salida fue negativa o un numero positivo en caso contrario:

\begin{equation}
f(x) = \max{(0,x)}
\end{equation}

Comparada con \(\sigma\) y \(\tanh\), requiere menos
operaciones y además no es saturante. 

Una desventaja de las \textit{ReLU} es que pueden provocar la "muerte"
de neuronas durante el entrenamiento. Si un gran gradiente fluye a
través de una \texit{ReLU} durante el proceso de
\textit{backpropagation} entonces va a actualizar los pesos de tal
manera que no se vuelva a activar la neurona. Pensemos que el proceso
de actualización de \weights{} implica restar un porcentaje del
gradiente en \weights{}, lo cual puede agravarse si nuestra tasa de
aprendizaje es muy grande. Una vez que la ReLU alcanza este estado, es
improbable que vuelva a activarse, dado que su gradiente en \(0\) es
también \(0\), por lo que un entrenamiendo mediante descenso de
gradiente y \textit{backpropagation} no va a modificar los pesos
locales, dejando a esa neurona "muerta".
**** TODO bibliografia de relu

*** \textit{Leaky ReLU}

Se puede solucionar el problema de la "muerte" de neuronas agregando
una pequeña pendiente negativa (de 0.01 por ejemplo) en los valores
negativos.

Es decir, la función queda:

\begin{equation}
f(x) = 1(x<0)(\alpha x) + 1(x >= 0)(x)
\end{equation}

De esta manera nos aseguramos que al menos un pequeño gradiente fluya
y se normalicen los pesos a mediano/largo plazo. Sin embargo no está
demostrado del todo que las \textit{Leaky ReLU} presenten una mejora
sustancial en el entrenamiento de las redes, por lo que las \{ReLU}
convencionales siguen siendo ampliamente usadas.
**** TODO agregar bibliografia de leaky realu

*** \texit{Maxout}

\begin{equation}
f(x) = \max{(w^{T}_{1} x + b_{1}, w^{T}_{2} x + b_{2})}
\end{equation}

Es una generalización de las funciones \textit{ReLU}, y obtiene lo
mejor de los dos mundos: por un lado la forma lineal y no saturante de
las \textit{ReLUs} y por el otro evita el problema de las neuronas que
se mueren. A pesar de ello tiene la desventaja de duplicar los
parámetros para cada neurona, lo cual no siempre es deseable, pues
conlleva en más tiempo de entrenamiento y más consumo de memoria y de
recursos, sobre todo en redes profundas.

Notar que una \textit{ReLU} normal es básicamente una \textit{maxout}
con \(w_1,b_1 = 0\).

** Entrenamiento de redes neuronales

Antes de comenzar a entrenar una red neuronal es necesario tener en
cuenta aspectos referidos al preprocesamiento de los datos, como
inicializar los pesos, que función de pérdida se va a utilizar y que
métodos de regularización se van a utilizar.

*** Preprocesamiento de datos

Las dos técnicas más comunes de preprocesamiento de datos para redes
neuronales son la substracción de la media y la normalización.

**** Substracción de la media

Como su nombre lo indica, se le resta la media a cada elemento del
conjunto de datos con el objetivo de \textit{centrar} los datos
alrededor del origen en todas las dimensiones. En las redes
convolucionales esto equivale a restarle el valor medio de los píxeles
a cada píxel de la imagen de entrada.

**** Normalización

Una manera de normalizar los datos es dividir cada dimensión por su
desviación estándar una vez que haya sido centrada en cero. De esta
manera se logra que las dimensiones tengan aproximadamente la misma
escala. Notar que en general los píxeles tienen valores en el rango de
0 a 255, por lo que sus dimensiones ya se encuentran en escalas
parecidas y cuando se trabaja con redes convolucionales no es
estrictamente necesario normalizar los datos de entrada.

**** Otras maneras de preprocesar datos

A la hora de entrenar redes convolucionales importan dos cosas: la
calidad de los datos y la cantidad. Es necesario que además de
normalizar las imágenes a un bajo nivel, se normalicen aspectos más
generales. Por ejemplo, si estuvieramos entrenando una red de
reconocimiento de rostros, es mucho mejor contar con un dataset de
caras alineadas en vez de un dataset de caras en diferentes posiciones
y ángulos. De esa manera vamos a lograr que la red aprenda mejor que
\textit{features} extraer de las imágenes.

Además no siempre se puede contar con un dataset de millones de
imágenes para entrenar nuestra red, por lo que hay que aumentar
nuestros datos con técnicas de \textit{data augmentation}: repetir la
misma imagen pero con diferentes variaciones en el color, brillo,
saturación, incluso hacer leves desplazamientos y rotaciones.

*** TODO --> (BORRAR Y EXPLICAR BREVEMENTE EN OTRA SECCION) Inicialización de pesos

A la hora de inicializar los pesos es escencial romper con la
simetría. Imaginemos que inicializamos todos los pesos en \(0\), algo
que podría parecer razonable. En una capa completamente conectada,
entonces todas las neuronas van a recibir el mismo valor de entrada
\(0\) (\(f(x)=\sum_i w_i x\) con \(w_i=0\)) por lo que sus salidas van
a ser todas iguales y por ende los gradientes que se calculen serán
los mismos, produciendo que los pesos se actualicen todos iguales y la
red no aprenda.

En cambio podemos inicializar los pesos con pequeños números
aleatorios cercanos a cero. Una opción común es utilizar una
distribución gaussiana con media cero y desviación estándar 0.01.

**** TODO regularizacion de la varianza
**** TODO expicar por que queremos valores cercanos a cero
*** Regularización

Cuando se ajusta un modelo sobre un conjunto de datos, puede surgir el
problema del \textit{sobre-ajuste}. Esto significa que nuestro modelo
ajusto sus parametros demasiado bien al conjunto de datos de
entrenamiento, provocando que aprendiera detalles insignificantes del
mismo, principalmente \textit{ruido}. Como consecuencia, cuando se lo
prueba en un conjunto de datos nuevos, el modelo presenta un bajo
rendimiento.

Queremos elegir los mejores parámetros de \weights{} para evitar este
problema, y eso lo podemos hacer agregando una penalidad de
regularización \(R(W)\). Lo que buscamos con esto es poner
preferencias para algunos conjuntos de \weights{} sobre otros.

De esta manera, nuestra función de pérdida ahora cuenta con dos
componentes: \textit{pérdida de los datos} y \textit{pérdida de
regularización}:

\begin{equation}
     \boldsymbol{ L =\frac{1}{N} \sum_{i} L_i + \lambda R(W)}
\end{equation}

Notar que la pérdida total es el promedio de las pérdidas de cada
imagen, y que la penalización de la regularización sólo se suma una
vez.

Las tecnicas de regularizacion más usadas son:

**** L2

Para cada peso de la red se calcula \(\frac{1}{2} \lambda w^2\) donde
\(\lambda\) es la tasa de regularización y se le suma a la función
objetivo. 

Una buena propiedad de la regularizacion es que al penalizar los pesos
grandes, obliga a \weights{} a generalizar y contemplar todas las
clases a la hora de clasificar. De esa manera, nuestro clasificador
final va a tomar en cuenta todas las dimensiones de entrada (algunas
con más o menos probabilidad) sin dar prioridad a una sola.

**** L1

Similar a la aterior, sólo que se le adiciona \(\lambda |w|\) a la
función objetivo. Los pesos tienden a converger a cero bajo la
regularización L1 y las redes tienden a usar un subconjunto de los
datos de entrada, convirtiendose en invariantes al ruido. En general
se prefiere la regularización L2 por obtenerse mejores resultados.

**** \texit{Dropout}

En pocas palabras, la técnica de \textout{dropout} \cite{dropout}
consiste en mantener activa una neurona con una probabilidad
\(\boldsymbol{p}\), o establecer su salida a cero en caso contrario.

***** TODO explayar mas dropout
*** Organización y entrenamiento de redes neuronales

Las redes neuronales estan organizadas como un grafo acíclico de
neuronas, donde las salidas de unas se transforma en la entrada de
otras. Las neuronas se organizan en distintas capas conectadas, de esa
manera los cálculos se hacen con operaciones entre matrices, algo que
no podríamos hacer tan fácil si tuvieramos neuronas conectadas
aleatoriamente entre ellas.

El tipo más común de capa de neuronas es la capa \textit{totalmente
conectada}, en donde cada neurona de la capa anterior se conecta con
todas las neuronas de la capa siguiente, pero no comparten conexiones
dentro de la misma capa.

Usualmente no se cuenta a la capa de entrada de las redes como una
capa más, y la capa de salida no tiene funciones de activación, dado
que generalmente representan las puntuaciones de cada clase (en
clasificación) o alguna métrica (en regresión).

*** Transferencia de aprendizaje

Entrenar un modelo con un tipo especifico de problema y luego utilizar
su \texit{conocimiento} para resolver otro problema nuevo, tal vez
incluso en un area distinta a la que fue pensado originalmente, es lo
que se llama transferencia de aprendizaje. Esta tecnica ha cobrado
importancia en \textit{deep learning} dado que a menudo las redes son
muy profundas y tardan semanas en entrenarse, por lo que contar con
modelos preentrenados sobre los cuales se puedan ajustar ligeramente
los parametros para resolver un nuevo problema es una ventaja.

** Redes Convolucionales
*** Diferencias con redes neuronales convencionales
Las redes convolucionales cuentan con los mismos artefactos que las
redes convencionales que ya discutimos (neuronas con pesos, funciones
de pérdida, capas completamente conectadas). Incluso los mismos
métodos de entrenamiento pueden ser aplicados. La diferencia radica en
que las redes convolucionales asumen que están trabajando con
imágenes, lo que permite optimizar la arquitectura de las mismas,
reduciendo parámetros y mejorando el proceso de aprendizaje.

Imaginemos por un momento que quisieramos aprender a clasificar un
conjunto de imágenes de 200x200 píxeles con 3 canales de colores. Eso
nos da una dimensión de entrada de 200x200x3, por lo que una neurona
completamente conectada en la primer capa oculta tendría 120000
conexiones y por ende esa misma cantidad de pesos a entrenar. Si
tenemos en cuenta que seguramente vamos a requerir más de una neurona
(comunmente cientos de ellas en una misma capa) podemos concluir que
este enfoque no escala bien para el procesamiento de imágenes.

Una red neuronal convolucional se aprovecha de la ventaja de que los
datos de entrada son imágenes y organiza las neuronas en 3
dimensiones: ancho, alto y profundidad, como se verá en la siguiente
sección.

*** Capas de una red convolucional
**** Capas Convolucionales

Una capa convolucional consta de un conjunto de filtros (o
\textit{kernels}) cuyos parametros se pueden aprender. En general cada
filtro es pequeño a lo ancho y alto, pero se aplica a toda la
profundidad del volumen de entrada. Notar que el volumen de entrada
puede bien ser una imagen o las activaciones de otra capa.

Durante el entrenamiento o la clasificacion de imagenes, estos filtros
se convolucionan a traves del ancho y alto de la imagen, produciendo
un mapa de activaciones en 2-D para cada filtro. Si "apilamos" los
mapas de activaciones de todos los filtros de una capa convolucional,
obtenemos un \textit{volumen} de salida.  En otras palabras, se
computa un producto punto entre el filtro y las distintas regiones de
la entrada. De esta manera cada elemento en el volumen de salida puede
ser interpretado como la salida de una neurona conectada a una pequeña
region de los datos de entrada, la cual comparte parametros (pesos)
con las otras neuronas que corresponden al mismo filtro.

Esta conexion a una pequeña region en los datos de entrada es un
hiperparametro de la red llamado campo receptivo. Es importante notar
que los campos receptivos son locales en una pequeña area en cuanto al
ancho y alto de la entrada, pero abarcan la totalidad de la
profundidad del volumen de entrada.

Otros hiperparametros relacionados con las capas convolucionales son
la cantidad de filtros (\textit{K}), el espacio en pixeles entre cada
aplicacion de los filtros (\textit{stride}) y por ultimo el relleno
con ceros o \textit{zero-padding}, donde se le agrega un "marco" de 1
o mas ceros a la entrada de la capa.

***** TODO imagenes

**** \textit{Pooling}

Las capas de \textit{pooling} reducen la dimension espacial de sus
entradas y por ende reducen la cantidad de parametros en la red,
ayudando a controlar el \textit{overfitting}. Lo mas comun es
insertar capas de \textit{pooling} luego de capas convolucionales.

La forma mas comun de \textit{pooling} es \textit{MAX Pooling}, en la
cual se calcula el maximo de un area local (generalmente 2x2 o 3x3) en
el ancho y largo del volumen de entrada y a traves de cada una de las
"rodajas" que conforman la profundidad del volumen. De esta manera se
reduce espacialmente la entrada, pero no su profundidad.

***** TODO imagenes
**** Capas Completamente Conectadas (Fully-Connected)

Como su nombre lo indica, cada neurona de esta capa tiene conexiones a
todas las salidas (o activaciones) de la capa anterior. Por lo tanto
sus activaciones se pueden calcular con una multiplicacion de matrices
junto con el calculo del \textit{bias}, como ya se vio para las redes
neuronales convencionales.

***** TODO explicacion. ecuacion.
**** TODO (AGREGAR BIBLIOGRAFIA) Arquitecturas 

Normalmente una red convolucional esta compuesta de varias capas
convolucionales (CONV), capas de \textit{pooling} (POOL), capas
completamente conectadas (FC por sus siglas en ingles) y funciones de
activacion, generalmente rectificadores lineales (RELU).

El patron usual en redes convolucionales es una capa CONV seguida de
una capa RELU seguida de una capa de \textit{pooling}. Esto se repite
una o varias veces hasta reducir espacialmente las dimensiones de la
entrada de la red. Luego es comun utilizar capas FC hasta reducir las
dimensiones a las dimensiones de salida, que en el caso de
clasificacion son las probabilidades de cada clase.

TODO: imagen ejemplo de red neuronal con [CONV-RELU-POOL]* FC FC etc.

A lo largo de los años ha habido varias arquitecturas de redes
convolucionales que cuentan con nombre propio, como por ejemplo LeNet,
creada en los 90 por Yann LeCun y utilizada para el reconocimiento de
digitos manuscriptos. Esta red fue utilizada con exito para leer
codigos postales y cheques bancarios.

En 2012, el ganador del desafio ImageNet ILSVRC, Alex Krizhevsky,
obtuvo un 16% de error utilizando una arquitectura llamada AlexNet. Su
arquitectura es muy similar a la de LeNet, aunque mas profunda y fue
una de las primeras en concatenar varias capas CONV antes de una capa
de \textit{pooling}.

Los ganadores del ISLVRC 2013 utilizaron una red llamada ZFNet, que
era basicamente una modificacion de AlexNet, con cambios en los
hiperparametros y las capas convolucionales.

En la misma competencia ILSVRC del 2014 se dieron a conocer dos redes,
GoogLeNet y VGGNet. Ambas demostraron que la profundidad de la red es
una caracteristica critica a la hora de obtener buenos resultados.

Si bien GoogLeNet fue la ganadora ese año, luego se demostro que
VGGNet es superior en muchas tareas de transferencia de aprendizaje,
por lo que es mas popular que GoogLeNet y se pueden encontrar muchos
modelos ya preentrenados.

Finalmente, ResNet (Residual Network), la red ganadora del ILSRVC
2015, cuenta con nada menos que 152 capas (VGGNet cuenta con 19) y
obteniendo un error de 3.57% en el top-5.

* Redes neuronales siamesas
** Conceptos generales sobre los cuales parte el trabajo
*** datasets, de que son, sobre que cosa van a entrenar (predecir cambios en la imagen)
*** Egomotion
*** SFA

* Plan de Trabajo
** Conseguir datasets
MINST: http://yann.lecun.com/exdb/mnist/
KITTI (odometry): http://www.cvlibs.net/datasets/kitti/eval_odometry.php
SF: aparentemente es un challenge de ICMLA 2011, hay que mandar un mail para pedirlo: http://www.icmla-conference.org/icmla11/challenge.htm

** Prueba de Concepto con MNIST
*** Preprocesamiento
El dataset tiene unas 60K imágenes. A cada dígito se le aplican dos
conjuntos de transformaciones aleatorias diferentes para generar los
pares (rotación y traslación).

*** Egomotion
Para pretraining de la red, hay que hacer un preprocesamiento del dataset:

  1. Traslación relativa en un rango de [-3,3]
  2. Rotación relativa en un rango de [-30°,30°].

La predicción es clasificación con tres capas soft-max loss (para
traslaciones en X,Y y rotacion en Z respectivamente). Cada SCNN
minimiza la suma de estas tres "losses".

Para que se pueda utilizar clasificación, hay que dividir los rangos
de traslación en en 7 classes y las rotaciones en 20 clases (donde
cada una corresponde a 3°)

*** Slow Feature Analysis (SFA)
Ellos comparan sus resultados (egomotion) contra SFA. En el paper
formulan SFA como un Contrastive Loss.

Para MNIST, hay que tomar a las imágenes cuya traslación relativa esté
entre [-1,1] y rotación relativa entre [-3°,3°] como temporalmente
cercanas (es el parámetro T de la ecuación en la sección 3.3 del
paper).

*** Arquitectura
BCCN: C96-P-C256-P
TCCN: F1000-D-Op

Para finetuning: BCCN-F500-D-Op

Para SFA, los valores optimos del parámetro m fueron 10 y 100.

*** Entrenamiento
Para pretraining: 40K iteraciones con learning rate inicial de 0.01,
reducido en un factor de 2 cada 10K iteraciones.

Para finetuning: 4K iteraciones con un learning rate constante de
0.01.

*** Evaluación
Las features obtenidas de las BCNN preentrenadas se evaluan teniendo
en cuenta el error en la clasificación de dígitos.  Se utilizan
conjuntos de entrenamiento de 100,300, 1K y 10K obtenidos del training
set de MNIST (sin transformaciones).  El test set que viene con MNIST
se utiliza para testing.
** Experimentos con KITTI y SF
*** Preprocesamiento KITTI
Tiene 20501 imágenes. Se calculan las transformaciones entre las
imágenes cercanas utilizando los datos odométricos del dataset.
Similar a MNIST: se crean 20 clases para las transformaciones en X,Y,Z
(el paper no explica como). Se toman imágenes que estén separadas a lo
sumo por +-7 frames.  Para el entrenamiento se extraen patches de
227x227 de las imágenes (Caffe tiene la opcion de cropear la imagen a
la hora de entrenar, pero no se como se aplica a redes siamesas,
probablemente tenga que hacerlo como parte del preprocesamiento).

Para SFA, el threshold para imágenes temporalmente cercanas (T) es
también de +-7
El numero total de imagenes usadas para entrenamiento es 20501

*** Preprocesamiento SF
Análogo a KITTI, solo que además de las transformaciones en X,Y,Z
agregan los 3 "euler angles" (no entendi eso).

*** Arquitectura
BCNN: C96-P-C256-P-C384-C384-C256-P (dice que estan inspiradas en las
primeras capas de AlexNet, extraer tamaño de filtros de esa red)
TCNN: C256-C128-F500-D-Op. Los kernels convolucionales con 3x3.

*** Entrenamiento
Se entrena por 60K iteraciones con batch size de 128, learning rate
inicial de 0.001 (reducido en un factor de 2 cada 20K iteraciones)

*** Evaluación
Los modelos KITTI-Net y SF-Net deben ser entrenados utilizando
alrededor de 20K imagenes unicas. Para hacer la comparacion mas justa
con las redes entrenadas con clases de imagenes, un model con AlexNet
sera entrenado con 20K imagenes tomadas de ILSVRC12 (20 ejemplos por
clase).  Las secciones de evaluacion en Intra-Class Keypoint Matching
y Visual Odometry los dejo para mas adelante.
**** Scene Recognition
Utilizar SUN database para el finetuning de las redes (SF-Net,
KITTI-Net y AlexNet-20K). El paper no aporta informacion sobre la
cantidad de iteraciones ni el learning rate usado.  Referirse al paper
para comparar resultados obtenidos.
**** Object Recognition
Utilizando subconjuntos de ILSVRC-2012 con 1, 5, 10 y 20 imagenes por
clase, hacer finetuning de KITTI-Net, KITTI-SFA-Net y AlexNet-Scratch
(AlexNet con pesos inicializados de manera aleatoria). Nuevamente el
paper no explica las iteraciones ni el learning rate utilizados.

* Datasets
1. MINST: http://yann.lecun.com/exdb/mnist/

2. KITTI (odometry): http://www.cvlibs.net/datasets/kitti/eval_odometry.php

3. SF: aparentemente es un challenge de ICMLA 2011, hay que mandar un mail para pedirlo: http://www.icmla-conference.org/icmla11/challenge.htm

4. ILSVRC2012: http://www.image-net.org/download-images (hay que crearse una cuenta)
* Herramientas   
Obtener acceso a algun server con Caffe+Ubuntu.

* Bibliografía
#+LaTeX: \bibliographystyle{abbrv}
#+LaTex: \bibliography{MarcoTeorico}
