#+TITLE: Marco Teorico
#+AUTHOR:  Ruben Ezequiel Torti Lopez
#+EMAIL:   ret0110@famaf.unc.edu.ar
#+OPTIONS: H:5 title:nil creator:nil timestamp:nil skip:nil toc:nil
#+STARTUP: indent hideblocks
#+TAGS: noexport(n)
#+EXPORT_SELECT_TAGS: export
#+EXPORT_EXCLUDE_TAGS: noexport
#+PROPERTY: session *R* 

#+LATEX_HEADER: \usepackage[T1]{fontenc}
#+LATEX_HEADER: \usepackage[utf8]{inputenc}
#+LATEX_HEADER: \usepackage{ifthen,figlatex}
#+LATEX_HEADER: \usepackage{longtable}
#+LATEX_HEADER: \usepackage{float}
#+LATEX_HEADER: \usepackage{wrapfig}
#+LATEX_HEADER: \usepackage{subfigure}
#+LATEX_HEADER: \usepackage{xspace}
#+LATEX_HEADER: \usepackage[spanish]{babel}
#+LATEX_HEADER: \usepackage{url}\urlstyle{sf}
#+LATEX_HEADER: \usepackage{amscd}
#+LATEX_HEADER: \usepackage{wrapfig}

#+LATEX_HEADER: \newcommand{\cl}{\textit{clasificadores lineales}}
#+LATEX_HEADER: \newcommand{\losss}{\textit{funciones de pérdida}}
#+LATEX_HEADER: \newcommand{\dg}{\textit{descenso de gradiente}}
#+LATEX_HEADER: \newcommand{\back}{\textit{backpropagation}}
#+LATEX_HEADER: \newcommand{\nn}{\textit{redes neuronales}}
#+LATEX_HEADER: \newcommand{\svms}{\textit{Support Vector Machines}}
#+LATEX_HEADER: \newcommand{\bow}{\textit{Bag of Words}}
#+LATEX_HEADER: \newcommand{\features}{\textit{features}}
#+LATEX_HEADER: \newcommand{\scores}{\textit{scores}}
#+LATEX_HEADER: \newcommand{\sift}{\textit{SIFT}}
#+LATEX_HEADER: \newcommand{\weigths}{\(\boldsymbol{W}\)}
#+LATEX_HEADER: \newcommand{\img}{\(\boldsymbol{x_i}\)}
#+LATEX_HEADER: \newcommand{\bias}{\(\boldsymbol{b}\)}
#+LATEX_HEADER: \newcommand{\func}{\(\boldsymbol{f}\)}
#+LATEX_HEADER: \newcommand{\loss}{\(\boldsymbol{L}\)}

#+LATEX_HEADER: \newcommand{\ml}{\textit{machine learning}}
#+LATEX_HEADER: \newcommand{\ML}{\textit{Machine Learning}}
#+LATEX_HEADER: \newcommand{\dl}{\textit{deep learning}}
#+LATEX_HEADER: \newcommand{\DL}{\textit{Deep Learning}}
#+LATEX_HEADER: \newcommand{\cnn}{\textit{convolutional neural networks}}
#+LATEX_HEADER: \newcommand{\CNN}{\textit{Convolutional Neural Networks}}

* Introducción
** Qué es la visión por computadoras

Para los seres humanos, percibir el mundo que nos rodea es una tarea
fácil. Millones de años de evolución nos han dotado con un sistema
visual altamente sofisticado que nos permite reconocer patrones muy
complejos del mundo tridimensional en el que vivimos. Distinguir
sombras, color, formas, o incluso cosas más generales, como
movimiento, potenciales amenazas o rostros de conocidos, son algunas
de las actividades que nuestros cerebros realizan casi de manera
inconsciente. Y si bien estas tareas pueden ser fáciles para nosotros,
no es tal el caso para las computadoras.

Richard Szeliski caracteriza a la visión por computadoras como un
\textit{problema inverso}, es decir, se busca describir el mundo que
uno ve en una o más imágenes y reconstruir sus propiedades tales como
forma, iluminación y distribuciones de color \cite{szeliski}

Una de las áreas principales de de la visión por computadoras es la
clasificación de imágenes. Es decir, dada una imagen y un conjunto de
categorías, determinar a cual de las categorías pertenece esa
imagen. Tener un buen entendimiento de los algoritmos de clasificación
es crucial para desarrollar otras tareas dentro de la visión por
computadoras, dado que muchos problemas pueden ser reducidos a
clasificación: detección de objetos, \textit{captioning} de imágenes,
segmentación, etc.

Sin embargo, es un problema más difícil de lo que aparenta. Una
fotografía es solamente un conjunto de números (píxeles), entonces
¿cómo darle significado semántico a un conjunto de números? Se podría
pensar en elaborar alguna métrica de distancia con los píxeles otra
imagen la cual sepamos está en la misma categoría, y si la distancia
es menor a un cierto umbral sabríamos que ambas pertenecen a la misma
clase. Sin embargo este enfoque carece de robustez, ya que el menor
cambio de \textit{iluminación} en las fotos podría alterar las
métricas y confundir a nuestro modelo. No solamente eso, los objetos
en las imágenes podrían estar ocultos por el ambiente
(\textit{oclusión}), o en una posición diferente
(\textit{deformación}), o ser exactamente iguales, pero variar en
colores y pequeños detalles (\textit{variación intraclase}).

Diferentes métodos se han utilizado a lo largo de la historia para
taclear este problema: \svms, árboles de decisión, \bow, etc. En la
mayoría de los casos las \features y descriptores que se extraían de
las imágenes debían ser implementadas manualmente (por ejemplo: histogramas de
colores o descriptores \sift \cite{Lowe-SIFT}).

En los últimos años toda la parafernalia relativa a la clasificación
de imágenes fue ampliamente superada por las Redes Neuronales
Convolucionales. Desde el año 2010, todos los equipos ganadores del
desafío Imagenet usaron Redes Neuronales Convolucionales, cada vez con
resultados más precisos \cite{imagenet}.

A pesar de haber tenido su golpe de popularidad en los últimos 6 años,
los primeros esbozos de modelar redes neuronales artificiales datan de
1958, cuando Frank Rosenblatt ideó el \textit{perceptron}, un
algoritmo para reconocimiento de patrones basado en una red de dos
capas de aprendizaje \cite{perceptron}. Sin embargo, en 1969 se
estableció que el poder de cómputo disponible en ese entonces no
bastaba para poder entrenar y correr grandes redes neuronales,
implicando que el área se estancara durante años \cite{minsky}. Tan
así es, que recién en 2006, con el abaratamiento de costos en hardware
de alto desempeño se pudieron implementar arquitecturas más complejas
(no necesariamente nuevas) y redes neuronales más profundas, algo que
se conoce como \DL, y que explicaremos más adelante.




** Gran cantidad de datos

Para poder entrenar Redes Neuronales Profundas, es necesario contar
con un conjunto de datos anotados muy grande, cuyos tamaños pueden ir
de los miles hasta los cientos de millones de imágenes. En la mayoría de los
casos, se requiere un gran esfuerzo humano para etiquetar tantas
imágenes.

La buena noticia es que actualmente contamos con una increíble
cantidad de imágenes para etiquetar. Para 2016, Cisco estima que el
51\% del trafico de Internet va a provenir de dispositivos WiFi, tales
como celulares, \textit{tablets}, \textit{smart TV's}, etc.  Más aún,
se estima que para el 2019 el 80\% del tráfico IP va a ser en forma de
píxeles (multimedia), superando al 67\% que existente en 2014
\cite{ciscostats}. Como tendencia podemos nombrar a Youtube, donde la
mitad de los videos son subidos desde dispositivos móviles
\cite{youtustats}.
 
Por otro lado, las redes sociales más populares como Facebook, Flickr
o Instagram almacenan una gigantesca cantidad de imágenes, contando la
última con más de 80 millones de imágenes subidas por día
\cite{instastats}. 

Es practicamente imposible contar con los recursos suficientes para
anotar tantos videos, imágenes y demás contenido multimedia. Para ello
debemos contar con herramientas de visión por computadoras para
filtrar, procesar y dar un sentido semántico a las imágenes.

Pero no podemos clasificar las imágenes si no contamos con una
herramienta poderosa que nos ayude, de la misma manera que no podemos
entrenar una herramienta poderosa si no tenemos la suficiente cantidad
de datos anotados.

Una posible solución a esto es la propuesta por \cite{LSM2015}, en
donde en vez de utilizar un gran dataset anotado a mano, proponen
utilizar información odométrica disponible en cámaras (giróscopos,
acelerómetros, etc) para pre-entrenar redes neuronales profundas, y
luego entrenarlas utilizando el dataset que se desee, obteniendo la
ventaja de no necesitar un dataset tan grande para lograr buena
precisión.

En este trabajo final nos proponemos reproducir este paper, analizando
cada paso para luego proponer mejoras y aplicaciones al mundo real.

El trabajo está organizado como sigue:
*** TODO organizacion del trabajo

* Marco Teórico

Para establecer un marco teórico que ayude a este trabajo especial ser
un poco más autocontenido, comenzaremos por explorar algunos conceptos
que conforman la base de \dl{}, tales como \cl{}, \loss{}, \dg{}, \back{}, luego
introduciremos lo que son las redes neuronales para terminar en redes
convolucionales, \dl{} y redes siamesas.

** Clasificadores lineales

Dado que clasificar una imagen es asignar una etiqueta a un conjunto
de píxeles, vamos a definir una función \func{} que mapee píxeles
\(\boldsymbol{x}\) a probablidades de cada etiqueta
(\textit{scores}). Supongamos que contamos con un conjunto de datos de
imágenes \(\boldsymbol{x_i} \in \boldsymbol{R^{D}}\), donde \(\boldsymbol{i =
1\cdots N}\), \(\boldsymbol{D}\) es la dimensión de cada imagen y
\(\boldsymbol{y_i = 1\cdots K}\) es la etiqueta asociada. Es decir,
tenemos \(\boldsymbol{N}\) imágenes y \(\boldsymbol{K}\) categorías.

Vamos a definir nuestra función \(\boldsymbol{f\colon R^{D} \mapsto
R^{K}}\) como un mapeo lineal entre píxeles y \scores:

\begin{equation}
     \boldsymbol{f(x_i, W, b)= W x_i + b}
\end{equation}

Estamos asumiendo que la imagen \img{} es un vector de una sola columna
\([D \times 1]\), \weights{} es una matriz \([K \times D]\) y \bias{} es
otro vector \([K \times 1]\). A menudo la matriz \weights{} es llamada
los \textit{pesos} de \func{}, y a \bias{} el \textit{vector de sesgo}
dado que influencia los \scores{} de salida, pero sin interactuar con
\img{}.

Notar que en realidad, la multiplicación \(W x_i\) está evaluado \(K\)
clasificadores en paralelo, donde cada uno es una fila de
\weights{}. Para entender mejor a los clasificadores lineales, podemos
verlos de la siguiente manera: si la imagen tiene \(32\times32\)
píxeles y la representamos con un vector columna de dimensión \(D\),
entonces en ese espacio \textit{D-dimensional} la imagen es solamente
un punto. Nuestro clasificador lineal entonces define una "línea" que
separa cada clase dentro de ese espacio multidimensional.

Todavía no mencionamos nada sobre como se definen \weights{} y
\bias{}. Un approach \textit{n\ddot{a}ive} sería probar diferentes
combinaciones para los parámetros de \weights{} y \bias{} hasta lograr
una buena precisión. Pero en general \weights{} y \bias{} tienen
muchas dimensiones (millones o miles de millones en redes neuronales,
como ya veremos) y elegirlos por prueba y error no es una opción.

En cambio, analizaremos cómo definir una función que, a medida que
entrenemos nuestro modelo, nos permita \textit{optimizar} esos
parámetros.

** Función de costo

A menudo también llamada función de pérdida o función objetivo, nos
ayuda a saber que tan bien o mal está actuando nuestro
clasificador. Es decir, si la tasa de error del clasificador es muy
alta, la \textit{pérdida} será muy alta y viceversa. Hay muchos tipos
de funciones de costo, analizaremos dos de las más conocidas: función
de pérdida de SVM Multiclase y Sofmax. En particular, esta última es
ampliamente usada en redes neuronales por sus propiedades.

*** Multiclass Support Vector Machine loss

La función de pérdida de SVM multiclase busca que la clase correcta de
cada imagen tenga un puntaje más alto que las otras clases por un
margen \(\Delta\). Más precisamente, dado el \textit{i}-ésimo ejemplo con
su respectiva etiqueta \(\boldsymbol{y_i}\), llamemos
\(\boldsymbol{s}\) al puntaje computado por el clasificador
lineal. Dado que es un vector columna, \(\boldsymbol{s_j}\) va a ser
el puntaje otorgado a la clase \(\boldsymbol{j} \in 1\cdots
\boldsymbol{K}\) (recordemos que \(K\) es la cantidad de
clases). Formalizamos a la función de perdida entonces de la siguiente
manera:

\begin{equation}
     \boldsymbol{L_i = \sum_{j \neq y_i} \max{(0, s_j - s_{y_{i}} + \Delta) }}
\end{equation}

Dado que en este caso particular estamos trabajando con clasificadores lineales:

\begin{equation}
     \boldsymbol{L_i = \sum_{j \neq y_i} \max{(0, w_{j}^{T}x_i -  w_{y_{i}}^{T}x_i + \Delta) }}
\end{equation}

Notemos que la funcion no necesariamente va a ser la misma una vez que
contemplemos clasificadores más complejos.

Cuando tenemos una función como la que acabamos de ver, en donde el
umbral se establece en cero (\( \max{(0,_)} \)), a menudo se las llama
funciones de pérdida \textit{hinge} (\textit{bisagra}), o por su
nombre en ingles, hinge loss.

¿Que pasaria si tuvieramos un \weights{} que clasifica correctamente
cada ejemplo? Es decir, si la perdida calculada fuera cero. Si
observamos bien la funcion de pérdida, notaremos que ese \weights{} no
necesariamente es único. Una forma de verlo es que si los parametros
de un \weights{} clasifican correctamente todos los ejemplos (pérdida
cero) entonces hay multiplicadores \(\lambda\) de esos parametros con
\(\lambda > 1\) que tambien van a dar pérdida cero, dado que la
transformación va a ser lineal (lo podemos ver como si estuvieramos
"agitando" la red entre valores positivos o negativos, dependiendo del
\(\lambda\)).

**** TODO ampliar explicacion

*** Regularización

Lo que queremos hacer es elegir mejores parámetros de \weights{} para evitar esta ambiguedad,
y eso lo podemos hacer agregando una penalidad de regularización
\(R(W)\). Lo que buscamos con esto es poner preferencias para algunos
conjuntos de \weights{} sobre otros.

La forma más común de regularización es la norma \(L2\), que penaliza los
pesos más grandes mediante una suma de los cuadrados de los mismos:

\begin{equation}
     \boldsymbol{ R(W) = \sum_{k} \sum_{l} W_{k,l}^{2}}
\end{equation}

De esta manera, nuestra función de pérdida ahora cuenta con dos
componentes: \textit{pérdida de los datos} y \textit{pérdida de
regularización}:

\begin{equation}
     \boldsymbol{ L =\frac{1}{N} \sum_{i} L_i + \lambda R(W)}
\end{equation}

O bien:

\begin{equation}
     \boldsymbol{ L =\frac{1}{N} \sum_{i} \sum_{j \neq y_i} \max{[0, f(x_i;W)_{j} -  f(x_i;W)_{y_{i}} + \Delta] } + \lambda R(W)}
\end{equation}

Notar que la pérdida total es el promedio de las pérdidas de cada
imagen, y que la penalización de la regularización sólo se suma una
vez.

Una buena propiedad de la regularizacion es que al penalizar los pesos
grandes, obliga a \weights{} a generalizar y contemplar todas las
clases a la hora de clasificar. De esa manera, nuestro clasificador
final va a tomar en cuenta todas las dimensiones de entrada (algunas
con más o menos probabilidad) sin dar prioridad a una sola.

*** Softmax

El clasificador Softmax tiene una función de pérdida diferente. En vez
de tratar a la salida del clasificador como puntajes para cada clase
(lo cual puede ser confuso y dificíl de comparar), Softmax devuelve
probabilidades normalizadas para cada clase.

Un clasificador Softmax no modifica la funcion \func{} que ya
conocemos, pero sí interpreta los puntajes como probabilidades
logarítmicas sin normalizar, reemplazando la \textit{hinge loss} por
una \textit{cross entropy loss}:

TODO explicar por que es el -logaritmo

\begin{equation}
     \boldsymbol{ L_i = - \log \bigg( \frac{\exp{f_{y_{i}}}} {\sum_j \exp{f_j}}\bigg)}
\end{equation}

Que es equivalente a:

\begin{equation}
     \boldsymbol{ L_i = - f_{y_{i}} + \log \Big( \sum_j \exp{f_j}}\Big)}
\end{equation}

Donde \(f_{y_{i}}\) representa el elemento \textit{j}-ésimo del vector
de puntajes calculado por \(f\). Nuevamente, la pérdida total es el
promedio de las pérdidas de cada imagen más la suma del término de
regularización \(R(W)\).

La \textit{función softmax} \(\frac{\exp{f_{j}}} {\sum_{k}
\exp{f_{k}}}\) toma un vector de valores reales arbitrarios y los
transforma en un vector de probabilidades normalizadas (cuya suma da
uno).

TODO Interpretacion estadistica de softmax:

** TODO optimizacion de un problema, mejorar descripcion
** Optimización: Descenso de Gradiente

Ya contamos con una función para medir que tan bien o que tan mal está
comportándose nuestro modelo, la \textit{función de pérdida}. Como se
puede observar, esta función depende de nuestro \weights{} y las
imágenes (o \features{} que estemos usando). Nosotros no tenemos
control sobre nuestro conjunto de datos de entrenamiento, pero sí
podemos modificar los parámetros de \weights para producir la menor
pérdida posible. Ahora bien, ¿de que manera podemos minimizar la
pérdida?

Una posible opción es probar diferentes parámetros de \weights{} y
quedarnos con la mejor combinación. Pero en las \nn{} estos parámetros
suelen ser decenas de millones, así que no es una buena idea probarlos
por fuerza bruta.

Otra opción podría ser una búsqueda local: variar \weights{}
ligeramente en un factor \(\delta \W\) y si \(W + \delta W\) resulta
en una menor pérdida, actualizar sus parámetros.

Sin embargo, ambos métodos mencionados son poco eficientes, por no
decir que no logran optimizar adecuadamente. Basta con ver que ambos
se basan en actualizaciones de \weights{} aleatorias hasta lograr
minimizar la pérdida.

Vamos ahora a analizar uno de los métodos más usados en \nn{} para
optimizar la pérdida: descenso de gradiente.

Tomemos un escenario hipotético: imaginemos por un momento que una
persona con los ojos vendados está atrapada entre montañas y busca
llegar al valle. Una manera de llegar al valle es probar dando un
pequeño paso a su alrededor, y "sentir" hacia donde desciende más
rápido la montaña, sólo valiéndose de la información local para
moverse. Cuando finalmente esté seguro hacia donde descender, dará
varios pasos en esa dirección, se detendrá y volverá a
observar. Sabemos que eventualmente llegará al fondo del valle, pues
lo único que tiene que hacer es seguir bajando por la pendiente de la
montaña.

Formalmente, la pendiente de la montaña es la pendiente de la función
de pérdida \loss{} que estemos utilizando, la elección de hacia donde
bajar se corresponde con el cálculo de la derivada de la función de
pérdida, mientras que la cantidad de pasos que realice se corresponde
con la \textit{tasa de aprendizaje}. En otras palabras, lo que estamos
haciendo es buscar el mínimo de \loss{}, y en consecuencia, el conjunto
de parámetros de \weights{} que minimicen el error.

*** TODO Explayar sobre gradient descent

** \textit{Backpropagation}

Notemos que \loss{} es una función que depende de las imágenes de
entrada \img{}, \weights{} y \bias{}. Sin embargo el conjunto de datos
de entrenamiento es algo fijo en nuestro modelo, por lo que sólo nos
interesa calcular el gradiente sobre \weights{} y \bias{} para poder
actualizar sus parámetros.

En una función de una dimensión, la derivada se expresa como:
\begin{equation}
     \boldsymbol{\frac{df(x)}{dx} = \lim_{h\to 0} \frac{f(x + h) - f(x)}{h} }
\end{equation}

Cuando la función toma un vector de números en vez de uno solo, a las
derivadas las llamamos derivadas parciales y el \textit{gradiente} es
simplemente un vector de esas derivadas. Por ejemplo, sea \(f\) una
función que toma dos parámetros \(x\) e \(y\), entonces el gradiente
de \(f\) es \(\nabla f = [\frac{\partial f}{\partial x},
\frac{\partial f}{\partial y}]\)

Usualmente podemos diferenciar con métodos numéricos, asignando a
\(h\) números muy pequeños por ejemplo, pero esto requiere de muchos
cálculos, es lento y tan sólo una aproximación. Veremos más
adelante que la función \loss{} de las redes neuronales suele tener
decenas de millones de parámetros, y realizar tantas
operaciones para una sola actualización de los parámetros no es
conveniente. En la práctica usaremos el cálculo analítico del
gradiente, en el cual derivamos una fórmula directa que es muy rápida
de computar valiéndonos de la \textit{regla de la cadena}.

La \textit{regla de la cadena} nos ayuda a descomponer el cálculo del
gradiente de expresiones complejas en pequeños pasos. Por ejemplo,
tomemos la función:

\begin{equation}
    f(x,y,z) = \frac{x}{y^2} + z
\end{equation}

Si quisieramos obtener su gradiente en \(x\) de la manera tradicional,
calculando el cociente de \(f(x+h) - f(x)\) con \(h\) cuando \({h \to
0}\) deberíamos realizar muchos cálculos computacionalmente
costosos. En cambio, podemos ver a \(f\) como una composición de
funciones:

\begin{equation}
    f(x,y,z) = \frac{x}{y^2} + z = q + z
\end{equation}

Y calcular su gradiente valiéndonos de la \textit{regla de la cadena}:

\begin{equation}
\frac{\partial f}{\partial z} = q
\frac{\partial f}{\partial q} = z

\frac{\partial f}{\partial x} = \frac{\partial f}{\partial q} \frac{\partial q}{\partial x} = \frac{z}{y^2}
\frac{\partial f}{\partial y} = \frac{\partial f}{\partial q} \frac{\partial q}{\partial y} = \frac{-2zx}{y^3}
\end{equation}

TODO: graficar el grafo de computacion de la funcion de arriba.

Ahora podemos comenzar a estructurar nuestro algoritmo de optimización
en dos pasos: primero, evaluamos nuestra función \loss{} en los
parámetros actuales (\textit{forward pass}). Luego, partiendo de ese
resultado calculamos el gradiente en cada variable utilizando la
\texit{regla de la cadena}. De esta manera "propagamos" el error de la
predicción hacia atrás (\textit{backpropagation}) y corregimos
ligeramente los pesos para mejorar las futuras predicciones.

Una vez que contamos con el gradiente, actualizamos los parámetros de
\loss{} restándole un porcentaje del gradiente negativo calculado
(negativo porque queremos ir en dirección opuesta a donde crece la
función, o sea, ir a su mínimo). Ese porcentaje es llamado
\textit{tasa de aprendizaje} (\textit{learning rate}) y suele ser uno
de los parámetros más difíciles de elegir, ya que la calidad y rapidez
de aprendizaje dependen de él.

TODO: pseudocódigo de optimizacion

Idealmente computaríamos el gradiente sobre todo el conjunto de datos,
actualizaríamos los parámetros, y repetiríamos el ciclo hasta
conseguir un buen resultado. Sin embargo los conjuntos de datos para
entrenar las redes neuronales suelen tener cientos de miles o incluso
millones de imágenes, por lo cual se utiliza una técnica llamada
\textit{Descenso de Gradiente Estocástico} o \textit{SGD} por sus
siglas en inglés, en el cual se calcula el gradiente para una cantidad
predeterminada de imágenes (\textit{batches}), se actualizan los
parámetros y se vuelve a repetir el ciclo con otro subconjunto
distinto. Esto parte de la suposición de que todas las imágenes del
conjunto de datos estan correlacionadas entre sí. En teoría
\textit{SGD} utiliza una sola imagen por batch, pero dada la alta
paralelización que provee el hardware actual, conviene hacer lotes de
imágenes de 62, 128, 512 imágenes. El tamaño de los \textit{batches}
no es estrictamente un hiperparámetro que uno pueda
\textit{cross-}validar, sino que más bien depende del hardware sobre
el que se esté entrenando la red (en general se eligen potencias de
dos por cuestiones de eficiencia).

** Redes Neuronales

Hasta ahora vimos clasificadores lineales. Si conectaramos la salida
de un clasificador lineal \(s_1=W_1x+b_1\) con la entrada de otro
clasificador \(s_2=W_2y+b_2\), entonces obtendríamos un tercero:

\begin{equation}
s_3 = W_2 (W_1x + b_1) + b_2 = (W_2 W_1) x + (W_2 b_1) + b_2
s_3 = W_3 x + b_3
\end{equation}

Es fácil hacer un chequeo de dimensiones para ver que efectivamente
podemos "colapsar" las matrices \(W_2\) y \(W_1\) en una sola, por lo
cual terminamos con otro clasificador lineal.

Notemos que por más que combinemos miles de clasificadores lineales
vamos a obtener un nuevo clasificador también lineal.  Una manera de
romper la linealidad de estas "capas" de clasificadores es, por
ejemplo, agregar lo que se llama \textit{función de activación}:
 
\begin{equation}
    s = W_2 \max{0, W_1 x + b_1} + b_2
\end{equation}
 
 
Lo que acabamos de definir es una red neuronal básica de dos capas, de
una neurona cada una.

Una sola neurona puede funcionar como un clasificador también (notar
el parecido con los clasificadores lineales), siempre que se eliga la
función de pérdida adecuada.
 
** Inspiración biológica de las neuronas

Nuestro cerebro está compuesto de más de doscientos tipos de neuronas,
sin embargo nos centraremos en el tipo estándar de neurona, un modelo
\textit{näive}:

TODO: dibujo clasico de neurona

El cuerpo de la neurona esta compuesto de tres partes principales, el
arbol dendrítico, el cuerpo celular o soma y una extension llamada
axón.  El arbol dendrítico se conecta con los axones de otras neuronas
y recibe impulsos de estas.  Una neurona puede estar conectada a
cientos o miles de otras neuronas desde las cuales recibe impulsos,
los cuales pueden o no activar a la neurona.  Si la neurona se activa,
entonces retransmite el impulso a través de su axón.

Notar que en realidad las conexiones del arbol dendrítico no son todas
iguales.  Los axones y las extremidades del arbol dendritico tienen un
pequeño espacio entre ellos llamado espacio sináptico. Si la exitación
que proviene de un axón es suficiente, entonces el impulso se
transmite a la neurona, caso contrario no. Decimos que la primera es
una transmision exitadora, pues aumenta la posibilidad de transmitir
el impulso, mientras que el otro caso se denomina transmisión
inhibidora, dado que reduce esa posibilidad.  De esta manera surge la
noción de \textit{pesos sinápticos}, que determinan cuando se activan
las conexiones y cuando no.  Otro aspecto a tener en cuenta es el
\textit{estímulo acumulativo}, en donde los estimulos de varios
receptores del arbol dendrítico se combinan de alguna manera para
activar o no la neurona (no hay punto intermedio). A esa función que
toma los impulsos de entrada y determina si emitir el impulso de
salida la llamaremos \textit{función de activación}, y representa la
frecuencia a la que se activa la neurona.

Ahora podemos dar un modelo más formal de como se comporta una
neurona.

TODO grafica de neurona con inputs, weights, sumatoria, funcion de activacion, etc.

En la Figura, las entradas \(x_i\) interactúan multiplicativamente con
los pesos. En nuestra analogía con la neurona biológica, esas son las
sinapsis. Luego, el el cuerpo de la célula, esos resultados se suma
junto con un \textit{bias}, y luego se calcula la función de
activación para decidir si activar o no el axón.

Historicamente se usaba la función sigmoide ( \(\sigma\) ) como
función de activación, por tener la propiedad de transformar la
entrada a un rango entre 0 y 1, y tener además una derivada fácil de
calcular (útil para \textit{backpropagation}), pero fue desplazada por
una mejor alternativa en los últimos años, las ReLU, o
\textit{Rectifier Linear Unit} en inglés, que son más fáciles de
calcular y obtienen mejores resultados.

** Funciones de activación comunes
*** Sigmoide

\begin{equation}
\sigma(x) = \frac{1}{1+\exp{-x}}
\end{equation}

TODO grafico de la funcion

Como se puede ver en la Figura XX, la fución sigmoide toma valores
reales y los "comprime" en el rango \((0,1)\). En particular, los
números muy pequeños se transforman en 0 y los muy grandes
en 1. Durante mucho tiempo esta función fue utilizada como activadora
dado que simula el comportamiento de una neurona bastante bien (desde
no activarse hasta saturarse) y porque además cuenta con una derivada
fácil de calcular:

\begin{equation}
    \tilde{\sigma(x)} = \sigma(x) (1 - \sigma(x))
\end{equation}

Sin embargo, al analizar la derivada descubrimos un problema: el
sigmoide satura los gradientes. Supongamos que durante la etapa
\texit{feed-forward} que la salida de \(\sigma\) fue muy cercano a
\(0\) ó \(1\). Entonces el gradiente local durante
\textit{backpropagation} va a ser muy cercano a \(0\), por lo que al
multiplicarlo por el gradiente de la salida de \(\sigma\) lo va a
anular y casi nada de la señal original va a ser retrasmitida a los
pesos a la hora de actualizarlos. Adicionalmente si los pesos
iniciales de la red fueran muy grandes, \(\sigma\) también se va a
saturar y vamos a tener el mismo problema.

Otro potencial inconveniente de usar \(\sigma\) es que los resultados
no están centrados en \(0\) (de hecho, siempre son
positivos). Supongamos que la entrada \(\boldsymbol{x}\) a una neurona
es positiva en todos sus elementos, entonces el gradiente en
\weights{} de \(f=Wx+b\) va a ser todo positivo o negativo durante
\textit{backpropagation}, dependiendo del gradiente de la expresion
\(f\). Esto podría introducir un \textit{zig-zag} en la actualización
de los pesos, aunque una vez que se suman todos los gradientes a lo
largo de un \textit{batch} de datos los pesos pueden tener signos
variables, por lo que este problema no tiene consecuencias tan
severas.

*** Tangente Hiperbólica
\begin{equation}
f(x) = \tanh(x)
\end{equation}

Analogamente al sigmoide, la tangente hiperbólica transforma números
reales al rango \([-1,1]\). Notemos que también sufre del problema de
la saturación, pero su salida está centrada en cero, por lo que se la
prefiere sobre la sigmoide.

TODO Grafico de tanh

*** \textit{ReLU}

\begin{equation}
f(x) = \max{(0,x)}
\end{equation}

Básicamente es poner un umbral en \(0\) a la salida de la
neurona. Comparada con \(\sigma\) y \(\tanh\), requiere menos
operaciones y además no es saturante.

Las \textit{ReLU} pueden provocar la "muerte" de neuronas durante el
entrenamiento. Si un gran gradiente fluye a través de una \texit{ReLU}
durante \textit{backpropagation} entonces va a actualizar los pesos de
tal manera que no se vuelva a activar la neurona. Pensemos que el
proceso de actualización de \weights{} implica restar un porcentaje
del gradiente en \weights{}. Esto se puede agravar si nuestra tasa de
aprendizaje es muy grande.

Luego de esa actualización, la neurona va a permanecer apagada
siempre, pues su entrada va a ser siempre negativa.

TODO explicar mejor,
https://www.quora.com/What-is-the-dying-ReLU-problem-in-neural-networks

*** \textit{Leaky ReLU}

Se puede solucionar el problema de la "muerte" de neuronas agregando
una pequeña pendiente negativa (de 0.01 por ejemplo) en los valores
negativos.

Es decir, la función queda:

\begin{equation}
f(x) = 1(x<0)(\alpha x) + 1(x >= 0)(x)
\end{equation}

De esa manera podemos evitar la muerte de una neurona para el caso
antes mencionado.

*** \texit{Maxout}

\begin{equation}
f(x) = \max{(w^{T}_{1} x + b_{1}, w^{T}_{2} x + b_{2})}
\end{equation}

Es una generalización de las funciones \textit{ReLU}, y obtiene lo
mejor de los dos mundos: la forma lineal y no saturante de las
\textit{ReLUs} y evita el problema de las neuronas que se mueren. A
pesar de eso tiene el problema de duplicar los parámetros para cada
neurona, lo cual no siempre es deseable (más tiempo de entrenamiento,
más consumo de memoria y de recursos, sobre todo en redes profundas).

Notar que una \textit{ReLU} normal es básicamente una \textit{maxout}
con \(w_1,b_1 = 0\).

** Entrenamiento de redes neuronales

Antes de comenzar a entrenar una red neuronal es necesario tener en
cuenta aspectos referidos al preprocesamiento de los datos, como
inicializar los pesos, que función de pérdida se va a utilizar y que
métodos de regularización se van a utilizar.

*** Preprocesamiento de datos

Las dos técnicas más comunes de preprocesamiento de datos para redes
neuronales son la substracción de la media y la normalización.

**** Substracción de la media

Como su nombre lo indica, se le resta la media a cada elemento del
conjunto de datos con el objetivo de \textit{centrar} los datos
alrededor del origen en todas las dimensiones. En las redes
convolucionales esto equivale a restarle el valor medio de los píxeles
a cada píxel de la imagen de entrada.

**** Normalización

Una manera de normalizar los datos es dividir cada dimensión por su
desviación estándar una vez que haya sido centrada en cero. De esta
manera se logra que las dimensiones tengan aproximadamente la misma
escala. Notar que en general los píxeles tienen valores en el rango de
0 a 255, por lo que sus dimensiones ya se encuentran en escalas
parecidas y cuando se trabaja con redes convolucionales no es
estrictamente necesario normalizar los datos de entrada.

**** Otras maneras de preprocesar datos

A la hora de entrenar redes convolucionales importan dos cosas: la
calidad de los datos y la cantidad. Es necesario que además de
normalizar las imágenes a un bajo nivel, se normalicen aspectos más
generales. Por ejemplo, si estuvieramos entrenando una red de
reconocimiento de rostros, es mucho mejor contar con un dataset de
caras alineadas en vez de un dataset de caras en diferentes posiciones
y ángulos. De esa manera vamos a lograr que la red aprenda mejor que
\textit{features} extraer de las imágenes.

Además no siempre se puede contar con un dataset de millones de
imágenes para entrenar nuestra red, por lo que hay que aumentar
nuestros datos con técnicas de \textit{data augmentation}: repetir la
misma imagen pero con diferentes variaciones en el color, brillo,
saturación, incluso hacer leves desplazamientos y rotaciones.

*** Inicialización de pesos

TODO expicar por que queremos valores cercanos a cero

A la hora de inicializar los pesos es escencial romper con la
simetría. Imaginemos que inicializamos todos los pesos en \(0\), algo
que podría parecer razonable. En una capa completamente conectada,
entonces todas las neuronas van a recibir el mismo valor de entrada
\(0\) (\(f(x)=\sum_i w_i x\) con \(w_i=0\)) por lo que sus salidas van
a ser todas iguales y por ende los gradientes que se calculen serán
los mismos, produciendo que los pesos se actualicen todos iguales y la
red no aprenda.

En cambio podemos inicializar los pesos con pequeños números
aleatorios cercanos a cero. Una opción común es utilizar una
distribución gaussiana con media cero y desviación estándar 0.01.

TODO regularizacion de la varianza

*** Regularización

Como ya se mencionó, hay varias maneras de prevenir
\textit{overfitting} en nuestra red mediante técnicas de
regularización. Las más usadas son:

**** L2

Para cada peso de la red se calcula \(\frac{1}{2} \lambda w^2\) donde
\(\lambda\) es la tasa de regularización y se le suma a la función
objetivo. La regularización L2 penaliza los grandes valores de \(w\)
logrando una distribución más difusa de los pesos (en vez de unos
pocos pesos grandes).

**** L1

Similar a la aterior, sólo que se le adiciona \(\lambda |w|\) a la
función objetivo. Los pesos tienden a converger a cero bajo la
regularización L1 y las redes tienden a usar un subconjunto de los
datos de entrada, convirtiendose en invariantes al ruido. En general
se prefiere la regularización L2 por obtenerse mejores resultados.

**** \texit{Dropout}

En pocas palabras, la técnica de \textout{dropout} \cite{dropout}
consiste en mantener activa una neurona con una probabilidad
\(\boldsymbol{p}\), o establecer su salida a cero en caso contrario.

TODO explayar mas dropout

*** TODO Funciones de pérdida

El objetivo de las funciones de pérdida es comparar los resultados de
la red contra los resultados esperados para luego optimizar los pesos
y minimizar los errores. La función de pérdida calcula un promedio de
las pérdidas de cada elemento del dataset (en general cada elemento de
un \textit{batch}).

*** TODO Organización y entrenamiento de redes neuronales

Las redes neuronales estan organizadas como un grafo acíclico de
neuronas, donde las salidas de unas se transforma en la entrada de
otras. Las neuronas se organizan en distintas capas conectadas, de esa
manera los cálculos se hacen con operaciones entre matrices, algo que
no podríamos hacer tan fácil si tuvieramos neuronas conectadas
aleatoriamente entre ellas.

El tipo más común de capa de neuronas es la capa \textit{totalmente
conectada}, en donde cada neurona de la capa anterior se conecta con
todas las neuronas de la capa siguiente, pero no comparten conexiones
dentro de la misma capa.

Usualmente no se cuenta a la capa de entrada de las redes como una
capa más, y la capa de salida no tiene funciones de activación, dado
que generalmente representan las puntuaciones de cada clase (en
clasificación) o alguna métrica (en regresión).



** redes convolucionales
*** Diferencias con redes neuronales convencionales
*** Capas de una red convolucional
**** Capas Convolucionales
**** Pooling
**** Capas Completamente conectadas (Fully-connected)
*** Arquitecturas
**** Patrones de capas, patrones de tamaños de capas.
**** Ejemplos 
** redes siamesas

* Entrenamiento de redes siamesas utilizando información odométrica
** Conceptos generales sobre los cuales parte el trabajo
*** datasets, de que son, sobre que cosa van a entrenar (predecir cambios en la imagen)
*** Egomotion
*** SFA

* Plan de Trabajo
** Conseguir datasets
MINST: http://yann.lecun.com/exdb/mnist/
KITTI (odometry): http://www.cvlibs.net/datasets/kitti/eval_odometry.php
SF: aparentemente es un challenge de ICMLA 2011, hay que mandar un mail para pedirlo: http://www.icmla-conference.org/icmla11/challenge.htm

** Prueba de Concepto con MNIST
*** Preprocesamiento
El dataset tiene unas 60K imágenes. A cada dígito se le aplican dos
conjuntos de transformaciones aleatorias diferentes para generar los
pares (rotación y traslación).

*** Egomotion
Para pretraining de la red, hay que hacer un preprocesamiento del dataset:

  1. Traslación relativa en un rango de [-3,3]
  2. Rotación relativa en un rango de [-30°,30°].

La predicción es clasificación con tres capas soft-max loss (para
traslaciones en X,Y y rotacion en Z respectivamente). Cada SCNN
minimiza la suma de estas tres "losses".

Para que se pueda utilizar clasificación, hay que dividir los rangos
de traslación en en 7 classes y las rotaciones en 20 clases (donde
cada una corresponde a 3°)

*** Slow Feature Analysis (SFA)
Ellos comparan sus resultados (egomotion) contra SFA. En el paper
formulan SFA como un Contrastive Loss.

Para MNIST, hay que tomar a las imágenes cuya traslación relativa esté
entre [-1,1] y rotación relativa entre [-3°,3°] como temporalmente
cercanas (es el parámetro T de la ecuación en la sección 3.3 del
paper).

*** Arquitectura
BCCN: C96-P-C256-P
TCCN: F1000-D-Op

Para finetuning: BCCN-F500-D-Op

Para SFA, los valores optimos del parámetro m fueron 10 y 100.

*** Entrenamiento
Para pretraining: 40K iteraciones con learning rate inicial de 0.01,
reducido en un factor de 2 cada 10K iteraciones.

Para finetuning: 4K iteraciones con un learning rate constante de
0.01.

*** Evaluación
Las features obtenidas de las BCNN preentrenadas se evaluan teniendo
en cuenta el error en la clasificación de dígitos.  Se utilizan
conjuntos de entrenamiento de 100,300, 1K y 10K obtenidos del training
set de MNIST (sin transformaciones).  El test set que viene con MNIST
se utiliza para testing.
** Experimentos con KITTI y SF
*** Preprocesamiento KITTI
Tiene 20501 imágenes. Se calculan las transformaciones entre las
imágenes cercanas utilizando los datos odométricos del dataset.
Similar a MNIST: se crean 20 clases para las transformaciones en X,Y,Z
(el paper no explica como). Se toman imágenes que estén separadas a lo
sumo por +-7 frames.  Para el entrenamiento se extraen patches de
227x227 de las imágenes (Caffe tiene la opcion de cropear la imagen a
la hora de entrenar, pero no se como se aplica a redes siamesas,
probablemente tenga que hacerlo como parte del preprocesamiento).

Para SFA, el threshold para imágenes temporalmente cercanas (T) es
también de +-7
El numero total de imagenes usadas para entrenamiento es 20501

*** Preprocesamiento SF
Análogo a KITTI, solo que además de las transformaciones en X,Y,Z
agregan los 3 "euler angles" (no entendi eso).

*** Arquitectura
BCNN: C96-P-C256-P-C384-C384-C256-P (dice que estan inspiradas en las
primeras capas de AlexNet, extraer tamaño de filtros de esa red)
TCNN: C256-C128-F500-D-Op. Los kernels convolucionales con 3x3.

*** Entrenamiento
Se entrena por 60K iteraciones con batch size de 128, learning rate
inicial de 0.001 (reducido en un factor de 2 cada 20K iteraciones)

*** Evaluación
Los modelos KITTI-Net y SF-Net deben ser entrenados utilizando
alrededor de 20K imagenes unicas. Para hacer la comparacion mas justa
con las redes entrenadas con clases de imagenes, un model con AlexNet
sera entrenado con 20K imagenes tomadas de ILSVRC12 (20 ejemplos por
clase).  Las secciones de evaluacion en Intra-Class Keypoint Matching
y Visual Odometry los dejo para mas adelante.
**** Scene Recognition
Utilizar SUN database para el finetuning de las redes (SF-Net,
KITTI-Net y AlexNet-20K). El paper no aporta informacion sobre la
cantidad de iteraciones ni el learning rate usado.  Referirse al paper
para comparar resultados obtenidos.
**** Object Recognition
Utilizando subconjuntos de ILSVRC-2012 con 1, 5, 10 y 20 imagenes por
clase, hacer finetuning de KITTI-Net, KITTI-SFA-Net y AlexNet-Scratch
(AlexNet con pesos inicializados de manera aleatoria). Nuevamente el
paper no explica las iteraciones ni el learning rate utilizados.

* Datasets
1. MINST: http://yann.lecun.com/exdb/mnist/

2. KITTI (odometry): http://www.cvlibs.net/datasets/kitti/eval_odometry.php

3. SF: aparentemente es un challenge de ICMLA 2011, hay que mandar un mail para pedirlo: http://www.icmla-conference.org/icmla11/challenge.htm

4. ILSVRC2012: http://www.image-net.org/download-images (hay que crearse una cuenta)
* Herramientas   
Obtener acceso a algun server con Caffe+Ubuntu.

* Bibliografía
#+LaTeX: \bibliographystyle{abbrv}
#+LaTex: \bibliography{MarcoTeorico}
