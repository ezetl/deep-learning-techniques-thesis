#+TITLE: Marco Teorico
#+AUTHOR:  Ruben Ezequiel Torti Lopez
#+EMAIL:   ret0110@famaf.unc.edu.ar
#+OPTIONS: H:5 title:nil creator:nil timestamp:nil skip:nil toc:nil
#+STARTUP: indent hideblocks
#+TAGS: noexport(n)
#+EXPORT_SELECT_TAGS: export
#+EXPORT_EXCLUDE_TAGS: noexport
#+PROPERTY: session *R* 

#+LATEX_HEADER: \usepackage[T1]{fontenc}
#+LATEX_HEADER: \usepackage[utf8]{inputenc}
#+LATEX_HEADER: \usepackage{ifthen,figlatex}
#+LATEX_HEADER: \usepackage{longtable}
#+LATEX_HEADER: \usepackage{float}
#+LATEX_HEADER: \usepackage{wrapfig}
#+LATEX_HEADER: \usepackage{subfigure}
#+LATEX_HEADER: \usepackage{xspace}
#+LATEX_HEADER: \usepackage[spanish]{babel}
#+LATEX_HEADER: \usepackage{url}\urlstyle{sf}
#+LATEX_HEADER: \usepackage{amscd}
#+LATEX_HEADER: \usepackage{wrapfig}
#+LATEX_HEADER: \usepackage{amsmath}

#+LATEX_HEADER: \newcommand{\cl}{\textit{clasificadores lineales}}
#+LATEX_HEADER: \newcommand{\losss}{\textit{funciones de pérdida}}
#+LATEX_HEADER: \newcommand{\dg}{\textit{descenso de gradiente}}
#+LATEX_HEADER: \newcommand{\back}{\textit{backpropagation}}
#+LATEX_HEADER: \newcommand{\nn}{\textit{redes neuronales}}
#+LATEX_HEADER: \newcommand{\svms}{\textit{Support Vector Machines}}
#+LATEX_HEADER: \newcommand{\bow}{\textit{Bag of Words}}
#+LATEX_HEADER: \newcommand{\features}{\textit{features}}
#+LATEX_HEADER: \newcommand{\scores}{\textit{scores}}
#+LATEX_HEADER: \newcommand{\sift}{\textit{SIFT}}
#+LATEX_HEADER: \newcommand{\weights}{\(\boldsymbol{W}\)}
#+LATEX_HEADER: \newcommand{\img}{\(\boldsymbol{x_i}\)}
#+LATEX_HEADER: \newcommand{\bias}{\(\boldsymbol{b}\)}
#+LATEX_HEADER: \newcommand{\func}{\(\boldsymbol{f}\)}
#+LATEX_HEADER: \newcommand{\loss}{\(\boldsymbol{L}\)}

#+LATEX_HEADER: \newcommand{\ml}{\textit{machine learning}}
#+LATEX_HEADER: \newcommand{\ML}{\textit{Machine Learning}}
#+LATEX_HEADER: \newcommand{\dl}{\textit{deep learning}}
#+LATEX_HEADER: \newcommand{\DL}{\textit{Deep Learning}}
#+LATEX_HEADER: \newcommand{\cnn}{\textit{convolutional neural networks}}
#+LATEX_HEADER: \newcommand{\CNN}{\textit{Convolutional Neural Networks}}

* Introducción

Para los seres humanos, percibir el mundo que nos rodea es una tarea
fácil. Millones de años de evolución nos han dotado con un sistema
visual altamente sofisticado que nos permite reconocer patrones muy
complejos del mundo tridimensional en el que vivimos. Distinguir
formas, sombras y color, o incluso cosas más generales, como
movimiento, potenciales amenazas y rostros de conocidos, son algunas
de las actividades que nuestros cerebros realizan casi de manera
inconsciente. Y si bien estas tareas pueden ser fáciles para nosotros,
no es tal el caso para las computadoras.

Richard Szeliski caracteriza a la visión por computadoras como un
\textit{problema inverso}, es decir, se busca describir el mundo que
uno ve en una o más imágenes y reconstruir sus propiedades tales como
forma, iluminación y distribuciones de color \cite{szeliski}

Una de las áreas principales de de la visión por computadoras es la
clasificación de imágenes. Es decir, dada una imagen y un conjunto de
categorías, determinar a cual de las categorías pertenece esa
imagen. Tener un buen entendimiento de los algoritmos de clasificación
es crucial para desarrollar otras tareas dentro de la visión por
computadoras, dado que muchos problemas pueden ser reducidos a
clasificación: detección de objetos, descripcion de imágenes y
segmentación entre otros.

Sin embargo, es un problema más difícil de lo que aparenta. Una
fotografía es solamente un conjunto de números (píxeles), entonces
¿cómo darle significado semántico a un conjunto de números? Se podría
pensar en elaborar alguna métrica de distancia con los píxeles otra
imagen la cual sepamos está en la misma categoría, y si la distancia
es menor a un cierto umbral sabríamos que ambas pertenecen a la misma
clase. Sin embargo este enfoque carece de robustez, ya que el menor
cambio de \textit{iluminación} (o sea, variaciones en los píxeles)
podría alterar las métricas y confundir a nuestro modelo. No solamente
eso, los objetos en las imágenes podrían estar ocultos por el ambiente
(\textit{oclusión}), o en una posición diferente
(\textit{deformación}), o ser exactamente iguales, pero variar en
colores y pequeños detalles (\textit{variación intraclase}).

Diferentes métodos se han utilizado a lo largo de la historia para
taclear este problema: \textit{máquinas de vectores de soporte},
árboles de decisión, \textit{bolsas de palabras}, etc. En la mayoría
de los casos las \features y descriptores que se extraían de las
imágenes debían ser implementadas manualmente (por ejemplo:
histogramas de colores o descriptores \sift \cite{Lowe-SIFT}).

En los últimos años toda la parafernalia relativa a la clasificación
de imágenes fue ampliamente superada por las Redes Neuronales
Convolucionales. Desde el año 2010, todos los equipos ganadores del
desafío Imagenet usaron Redes Neuronales Convolucionales, cada vez con
resultados más precisos \cite{imagenet}.

A pesar de haber tenido su golpe de popularidad en los últimos años,
los primeros esbozos de modelar redes neuronales artificiales datan de
1958, cuando Frank Rosenblatt ideó el \textit{perceptron}, un
algoritmo para reconocimiento de patrones basado en una red de dos
capas de aprendizaje \cite{perceptron}. Sin embargo, en 1969 se
estableció que el poder de cómputo disponible en ese entonces no
bastaba para poder entrenar y correr grandes redes neuronales,
implicando que el área se estancara durante años \cite{minsky}. Tan
así es, que recién en 2006, con el abaratamiento de costos en hardware
de alto desempeño se pudieron implementar arquitecturas más complejas
(no necesariamente nuevas) y redes neuronales más profundas, algo que
se conoce como Aprendizaje Profundo (\textit{Deep Learning}).

Para poder entrenar Redes Neuronales Profundas, es necesario contar
con un conjunto de datos anotados muy grande, cuyos tamaños pueden ir
de las decenas de miles hasta millones de imágenes. Generalmente se
requiere un gran esfuerzo humano para etiquetar tantas imágenes.

Actualmente contamos con una increíble cantidad de imágenes para
etiquetar. Para 2016, Cisco estima que el 51\% del trafico de Internet
va a provenir de dispositivos WiFi, tales como celulares,
\textit{tablets}, \textit{smart TV's}, etc.  Más aún, se estima que
para el 2019 el 80\% del tráfico IP va a ser en forma de píxeles
(multimedia), superando al 67\% que existente en 2014
\cite{ciscostats}. Como tendencia podemos nombrar a Youtube, donde la
mitad de los videos son subidos desde dispositivos móviles
\cite{youtustats}. Por otro lado, las redes sociales más populares
como Facebook, Flickr o Instagram almacenan una gigantesca cantidad de
imágenes, contando la última con más de 80 millones de imágenes
subidas por día \cite{instastats}. Sin embargo, es practicamente
imposible contar con los recursos suficientes para anotar tantos
videos, imágenes y demás contenido multimedia.

Una posible solución al entrenamiento de redes profundas cuando no se
puede anotar una gran cantidad de datos es la propuesta por Agrawal et
al. \cite{LSM2015}. En la misma proponen utilizar información
odométrica disponible en cámaras (giróscopos, acelerómetros, etc) para
pre-entrenar redes neuronales profundas, y luego realizar una
transferencia de aprendizaje sobre un conjunto de datos anotados que
se desee, obteniendo la ventaja de no necesitar un conjunto tan grande
para lograr buena precisión.

En este trabajo final nos proponemos reproducir este paper, analizando
cada paso para luego proponer mejoras y aplicaciones al mundo real.

El trabajo está organizado como sigue: en la Sección \ref{sec:marco}
se introducirán conceptos del aprendizaje automático y las redes
neuronales artificiales para concluir con redes convolucionales, en la
Sección \ref{sec:siamesa} se presentará un método para entrenar
modelos de aprendizaje profundo mediante redes siamesas, que luego se
utilizará para reproducir los resultados de \cite{LSM2015} en la
Sección \ref{sec:odometry}. Finalmente, la Sección \ref{sec:concl}
presenta pensamientos finales y trabajo a futuro.

* Marco Teórico
#+LaTeX: \label{sec:marco}
** Aprendizaje Automático
*** Introducción

Las técnicas de aprendizaje automético tienen como objetivo
identificar patrones en conjuntos de datos utilizando herramientas de
la estadística, teoría de la información, cálculo y optimización entre
otras. De esta manera se pueden automatizar tareas, como por ejemplo
del filtro de correo basura (\textit{spam}), la verificación de
rostros o incluso predicción de precios en el mercado.

El aprendizaje automático adquiere relevancia cuando las tareas que se
desean automatizar son demasiado complejas para programarse
directamente. Por ejemplo la verificación de rostros debe tener en
cuenta detalles como variaciones en sombra, color, orientación, por no
mencionar las diferentes características que hay que extraer de una
cara para diferenciarla de otra (arrugas, prominencias y otros
rasgos).  Otro caso es el análisis de grandes volúmenes de datos, como
estadísticas del clima para crear nuevos modelos.

Hay varios paradigmas o ejes dentro del aprendizaje automatico que
definen los tipos de algoritmos, las técnicas de
entrenamiento y las potenciales aplicaciones de esos modelos:

**** Aprendizaje supervisado vs. no supervisado

Cuando se poseen anotaciones o alguna clase de etiqueta sobre los
datos a aprender, hablamos de aprendizaje supervisado. Retomando el
caso del verificador de rostros, las etiquetas serían el nombre o
algun identificador de cada persona y nuestro clasificador aprendería
a diferenciar las caras tomando como referencia las anotaciones.

Por otro lado, cuando los datos no estan categorizados de antemano
hablamos de aprendizaje no supervisado. Por ejemplo, si se contara con
una lista de casas con sus respectivos precios, su área en metros
cúbicos y cantidad de habitaciones y quisieramos encontrar alguna
relación entre ellas. Los algoritmos no supervisados trabajan
netamente sobre los datos \textit{tal como están}.

**** Aprendizaje pasivo vs. activo

El aprendizaje pasivo implica utilizar solamente los datos ya
existentes. El aprendizaje activo se refiere a interactuar con el
ambiente para obtener información, como por ejemplo preguntar a un
usuario si un rostro es de cierta persona y utilizar los datos
proporcionados durante su etrenamiento.

**** Aprendizaje \textit{online} vs. estadistico (\textit{batch learning})

En el aprendizaje \textit{online} los datos estan disponibles de
manera secuencial, actualizando el modelo en cada paso para lograr
mejores predicciones/clasificaciones. En el aprendizaje estadístico
primero se analiza una gran cantidad de datos (tal vez la totalidad
del conjunto) y solamente luego de haberlos analizado se pueden
obtener conclusiones o un modelo final.

*** Clasificadores lineales

Un clasificador lineal combina linealmente las caracteristicas (o
\textit{features}) de los datos de entrada para determinar a que clase
pertenecen los mismos, usualmente entrenado mediante técnicas de
aprendizaje supervisado.

Imaginemos que queremos clasificar imágenes, es decir, asignar una
etiqueta a un conjunto de píxeles. Para ello vamos a definir una
función \func{} que mapee píxeles \(\boldsymbol{x}\) a probablidades
de cada etiqueta (\textit{scores}). Supongamos que contamos con un
conjunto de datos de imágenes \(\boldsymbol{x_i} \in
\boldsymbol{R^{D}}\), donde \(\boldsymbol{i = 1\cdots N}\),
\(\boldsymbol{D}\) es la dimensión de cada imagen y \(\boldsymbol{y_i
= 1\cdots K}\) es la etiqueta asociada. Es decir, tenemos
\(\boldsymbol{N}\) imágenes y \(\boldsymbol{K}\) categorías.

Vamos a definir nuestra función \(\boldsymbol{f\colon R^{D} \mapsto
R^{K}}\) como un mapeo lineal entre píxeles y \scores:

\begin{equation}
     \boldsymbol{f(x_i, W, b)= W x_i + b}
\end{equation}

Asumimos que la imagen \img{} es un vector de una sola columna
\([D \times 1]\), \weights{} es una matriz \([K \times D]\) y \bias{} es
otro vector \([K \times 1]\). A menudo la matriz \weights{} es llamada
los \textit{pesos} de \func{}, y a \bias{} el \textit{vector de sesgo}
dado que influencia los \scores{} de salida, pero sin interactuar con
\img{}.

Para entender mejor a los clasificadores lineales, podemos verlos de
la siguiente manera: si la imagen tiene \(32\times32\) píxeles y la
representamos con un vector columna de dimensión \(D\), entonces en
ese espacio \textit{D-dimensional} la imagen es solamente un
punto. Nuestro clasificador lineal entonces define una "línea" (o un
hiperplano mejor dicho) que separa cada clase dentro de ese espacio
multidimensional. Notar que en realidad, la multiplicación
\(\boldsymbol{W x_i}\) está evaluado \(\boldsymbol{K}\) clasificadores
en paralelo, donde cada uno es una fila de \weights{}.

Mas adelante veremos como definir \weights{} y \bias{} para obtener un
buen clasificador.

*** Entrenamiento
En el caso de los clasificadores lineales, entrenar un modelo se
traduce en encontrar buenos valores de \weights{} y \bias{} que
minimicen el error.

Es muy común, cuando se cuenta con un conjunto de datos lo
suficientemente grande, dividirlo en al menos 3 subconjuntos
disjuntos: uno para entrenar el modelo, un segundo para validar el
modelo durante el entrenamiento y un tercero para probar el modelo una
vez entrenado. De esta manera se puede medir que tan bien el modelo
aprendió características relevantes a la clasificación y las pudo
aplicar a un conjunto de datos completamente nuevo (conjunto de
pruebas). Si la precisión que obtuvo nuestro modelo sobre este
conjunto de pruebas es muy baja, es un síntoma de que algo no anda
bien en el entrenamiento (ver problema de \textit{sobre-ajuste} en la
Sección \ref{sec:regular}).

A grandes rasgos, el proceso de entrenamiento de un clasificador
consta de dos etapas: la primera es medir el error actual del modelo
con algún conjunto de datos de validación, la segunda es actualizar
los parámetros del clasificador (\weights{} y \bias{}) para minimizar
ese error. Por lo tanto hay dos aspectos a tener en cuenta antes de
entrenar un modelo: cómo medir efectivamente la tasa de error y cómo
actualizar sus parámetros para minimizarla. Para el primer caso se
define lo que se llama una \textit{función de pérdida}, mientras que
para el segundo analizaremos una técnica muy utilizada en aprendizaje
automático denominada \textit{descenso de gradiente}. Esto no
significa que sea la única alternativa para entrenar modelos, pero al
ser ampliamente utilizada en redes neuronales artifiales será la única
que analizaremos.

**** Función de costo

Una función de costo nos ayuda a saber que tan bien o mal está
actuando nuestro clasificador. Es decir, si la tasa de error del
clasificador es muy alta, el costo o la \textit{pérdida} será muy alta
y viceversa. Hay muchos tipos de funciones de costo, pero la idea
subyacente es la misma y puede ser expresada en la siguiente ecuación:

\begin{equation}
\boldsymbol{L}(\theta) = \frac{1}{N} \sum^{N}_{i} L(f(x_i;\theta), y_i)
\end{equation}

donde \(L\) es la función de pérdidad individual de cada muestra en el
conjunto de datos, \(f(x_i;\theta)\) es la predicción del modelo sobre
una muestra \(x_i\) con parámetros \(\theta\), \(y_i\) es el objetivo
(por ejemplo, la etiqueta de cada muestra del conjunto de datos en una
tarea de clasificación). Notar que para el caso de un clasificador
lineal los parámetros \(\theta\) son \weights{} y \bias{}. De ahora en
adelante utilizaremos \(\theta\) o \weights{} indiferentemente para
hablar de los parámetros de nuestro modelo.

Un ejemplo de función de perdida popular es la función de pérdida de
\textit{máquinas de vectores de soporte multiclase}. Sea \(f(x_i;
\theta)_j\) el puntaje asignado por el clasificador \(f\) a la clase
\(j\) con \(x_i\) como dato de entrada y parámetros \(\theta\) y sea
\(f(x_i, \theta)_{y_i}\) el puntaje asignado por \(f\) a la clase
verdadera de \(x_i\), o sea \(y_i\), entonces la pérdida para \(x_i\)
se calcula de la siguiente manera:

\begin{equation}
     L_i = \sum_{j \neq y_i} \max{(0, f(x_i; \theta)_j - f(x_i; \theta)_{y_{i}} + \Delta) }
\end{equation}

Se puede observar que esta función de pérdida busca que la clase
correcta tenga un puntaje más alto que las otras por un margen
\(\Delta\).

Cuando tenemos una función con la forma \( \max{(0,\_)} \) a menudo se
la llama función de pérdida bisagra (\textit{hinge loss} en inglés).

**** Descenso de Gradiente
#+LaTeX: \label{sec:sgd}

Ya contamos con una función para medir que tan bien o que tan mal está
comportándose nuestro modelo, la \textit{función de pérdida}. Como se
puede observar, esta función depende de nuestro \weights{} y las
imágenes (o \features{} que estemos usando). Nosotros no tenemos
control sobre nuestro conjunto de datos de entrenamiento, pero sí
podemos modificar los parámetros de \weights{} para producir la menor
pérdida posible.

El descenso de gradiente se utiliza para optimizar los pesos partiendo
de la premisa que el modelo es diferenciable con respecto a
\weights{}. Dado que queremos minimizar la funcion de costo \loss{},
lo que vamos a hacer es calcular su gradiente \(\boldsymbol{\nabla
L}\) respecto a cada parámetro y luego modificar cada uno ligeramente
con el objetivo de alcanzar un mínimo en la función. Entonces, si
\(\theta_{n}\) son nuestros parámetros en el paso \(n\) del
entrenamiento, calculamos \(\theta_{n+1}\) de la siguiente manera:

\begin{equation}
    \theta_{n+1} = \theta_n - \epsilon \frac{1}{m} \sum^{m}_{i} \nabla_{\theta_{n}} L(f(x_i; \theta_n), y_i)
\end{equation}

Donde \(\epsilon\) es conocido como la \textit{tasa de aprendizaje} y
\(m\) es la cantidad de elementos en el conjunto de datos. En la
ecuacion se puede observar que se modifican los parámetros con
respecto a la dirección opuesta al gradiente, dado que el mismo indica
la dirección de crecimiento de una función pero nosotros queremos
encontrar un mínimo.

Existen variantes mas sofisticadas del descenso de gradiente
(\textit{Momentum}, \textit{Nesterov Momentum}, \textit{Adagrad},
\textit{Rmsprop} entre otros). Lo más comun es utilizar alguna de
ellas con una técnica llamada \textit{descenso de gradiente
estocástico}, que se basa en calcular el gradiente de un subconjunto
del total de datos (\textit{batch}) y actualizar \weights{} al final
de cada \textit{batch}. Esto es muy útil dado que es
computacionalmente costoso calcular el gradiente de todo un conjunto
de datos con miles de imágenes a la vez y calcular el gradiente de un
\textit{batch} aproxima bastante bien el gradiente del total.

**** Clasificador \textit{Softmax}
Antes de saltar de lleno a las redes neuronales artificiales vamos a
describir brevemente un tipo de clasificador muy utilizado en las
mismas, el clasificador \textit{Softmax}.

La función \textit{Softmax} tiene la siguiente forma:

\begin{equation}
    \sigma(x)_j =  \frac{e^{f(x;\theta)_{j}}} {\sum_{k} e^{f(x;\theta)_{k}}}
\end{equation}

Actúa tomando un vector de valores reales arbitrarios y
transformándolos en un vector de probabilidades normalizadas (cuya
suma da uno).

Por lo tanto el clasificador Softmax tiene una función de pérdida
diferente. En vez de tratar a los resultados como puntajes para cada
clase (lo cual puede ser confuso y dificíl de comparar), Softmax
devuelve probabilidades normalizadas para cada clase.

Un clasificador Softmax no modifica la funcion \(f\) que ya
conocemos, pero sí interpreta los puntajes como probabilidades
logarítmicas sin normalizar, reemplazando la pérdida bisagra por una
\textit{entropía cruzada}:

\begin{equation}
     L_i = - \log \bigg( \frac{e^{f(x_i, \theta)_{y_{i}}}} {\sum_j e^{f(x_i, \theta)_j}}\bigg)
\end{equation}

Que es equivalente a:

\begin{equation}
     L_i = - f(x_i, \theta)_{y_{i}} + \log {\Big( \sum_j e^{f(x_i, \theta)_j}\Big)}
\end{equation}

Donde \(f_{y_{i}}\) representa el elemento \textit{j}-ésimo del vector
de puntajes calculado por \(f\). Nuevamente, la pérdida total es el
promedio de las pérdidas de cada imagen.

** Redes Neuronales Artificiales

Hasta ahora analizamos clasificadores lineales y un tipo particular
llamado softmax. Si conectáramos la salida de un clasificador lineal
\(s_1=W_1x+b_1\) con la entrada de otro clasificador \(s_2=W_2y+b_2\),
entonces obtendríamos un tercero:

\begin{equation}
s_3 = W_2 (W_1x + b_1) + b_2 = (W_2 W_1) x + (W_2 b_1) + b_2
\end{equation}

\begin{equation}
s_3 = W_3 x + b_3
\end{equation}

Es fácil hacer un chequeo de dimensiones para ver que efectivamente
podemos "colapsar" las matrices \(W_2\) y \(W_1\) en una sola, por lo
cual terminamos con otro clasificador lineal.

Notemos que por más que combinemos miles de clasificadores lineales
vamos a obtener un nuevo clasificador también lineal.  Una manera de
romper la linealidad de estas "capas" de clasificadores es, por
ejemplo, agregar lo que se llama \textit{función de activación}:
 
\begin{equation}
    s = W_2 \max{(0, W_1 x + b_1)} + b_2
\end{equation}
 
 
Lo que acabamos de definir es una red neuronal básica de dos capas, de
una neurona cada una.

Una sola neurona puede funcionar como un clasificador también (notar
el parecido con los clasificadores lineales), siempre que se eliga la
función de pérdida adecuada.
 
*** Funciones de activación comunes

Se han propuesto varias funciones de activación a lo largo de los
años. 

Inicialmente se intentó simular el comportamiento de las conexiones
sinápticas mediante la función de activación Sigmoide (\(\sigma\)),
por tener la propiedad de transformar la entrada a un rango entre 0 y
1, y tener además una derivada fácil de calcular (útil para
\textit{backpropagation}).  Luego se propuso la Tangente Hiperbólica
(\(\tanh\)), pero ambas fueron desplazadas en favor de las unidades
\textit{ReLU}, o \textit{Rectifier Linear Unit} en inglés, que son más
fáciles de calcular y no sufren del problema de saturación de
gradiente que poseen \(\sigma\) y \(\tanh\).

Nos concentraremos entonces en las unidades \textit{ReLU}, actualmente
muy populares en las redes convolucionales debido a sus buenas
propiedades.

Hay tres tipos de rectificadores lineales:

**** \textit{ReLU}
Una unidad ReLU establece un umbral en \(0\) a la salida de la
neurona. Es decir, la activación de una neurona va a ser \(0\) si su
salida fue negativa o un numero positivo en caso contrario:

\begin{equation}
f(x) = \max{(0,x)}
\end{equation}

Comparada con \(\sigma\) y \(\tanh\), requiere menos operaciones, no
es saturante y converge hasta 6 veces más rápido que las funciones
sigmoide y tanh \cite{NIPS2012_4824}.

Una desventaja de las \textit{ReLU} es que pueden provocar la "muerte"
de neuronas durante el entrenamiento. Si un gran gradiente fluye a
través de una \textit{ReLU} durante el proceso de
\textit{backpropagation} entonces va a actualizar los pesos de esa
neurona de tal manera que no se vuelva a activar. Pensemos que el
proceso de actualización de \weights{} implica restar un porcentaje
del gradiente en \weights{}. Si el gradiente es muy grande entonces
los pesos sobre los que se realice la actualización terminarán siendo
muy pequeños. Como consecuencia, la unidad \textit{ReLU} no volverá a
activarse, pues sus valores de entrada siempre van a ser valores
negativos. Esta situación puede agravarse si la tasa de
aprendizaje es muy grande.

Una vez que la ReLU alcanza este estado, es improbable que vuelva a
activarse, dado que su gradiente en \(0\) es también \(0\), por lo que
un entrenamiendo mediante descenso de gradiente y
\textit{backpropagation} no va a modificar los pesos locales, dejando
a esa neurona "muerta".

**** \textit{Leaky ReLU}

Se puede solucionar el problema de la "muerte" de neuronas agregando
una pequeña pendiente negativa (de 0.01 por ejemplo) en los valores
negativos de la \textit{ReLU}. Esta función de activación es la que se
conoce como \textit{Leaky ReLU} \cite{zhang2014improving}:

\begin{equation}
f(x) = 1(x<0)(\alpha x) + 1(x >= 0)(x)
\end{equation}

De esta manera nos aseguramos que al menos un pequeño gradiente fluya
durante \textit{backpropagation} cuando la neurona emite resultados
negativos, permitiendo que se normalicen los pesos a mediano/largo
plazo. Sin embargo no está demostrado del todo que las \textit{Leaky
ReLU} presenten una mejora sustancial en el entrenamiento de las
redes, por lo que las \{ReLU} convencionales siguen siendo ampliamente
usadas.

**** \textit{Maxout}

\begin{equation}
f(x) = \max{(w^{T}_{1} x + b_{1}, w^{T}_{2} x + b_{2})}
\end{equation}

\textit{Maxout} \cite{Maxout} es una generalización de las funciones
\textit{ReLU}, y obtiene lo mejor de los dos mundos: por un lado la
forma lineal y no saturante de las \textit{ReLUs} y por el otro evita
el problema de las neuronas que se mueren. A pesar de ello tiene la
desventaja de duplicar los parámetros para cada neurona, lo cual no
siempre es deseable, pues implica más tiempo de entrenamiento y
más consumo de memoria y recursos, sobre todo en redes profundas.

Notar que una \textit{ReLU} normal es básicamente una \textit{maxout}
con \(w_1,b_1 = 0\).

*** Inspiración biológica de las redes neuronales artificiales

Nuestro cerebro está compuesto de más de doscientos tipos de neuronas,
sin embargo nos centraremos en el tipo estándar de neurona, un modelo
\textit{näive}:

TODO: dibujo clasico de neurona

El cuerpo de la neurona esta compuesto de tres partes principales, el
arbol dendrítico, el cuerpo celular o soma y una extensión llamada
axón.  El árbol dendrítico se conecta con los axones de otras neuronas
y recibe impulsos de éstas.  Una neurona puede estar conectada a
cientos o miles de otras neuronas desde las que recibe impulsos,
los cuales pueden o no activar a la neurona.  Si la neurona se activa,
entonces retransmite el impulso a través de su axón.

Notar que en realidad las conexiones del árbol dendrítico no son todas
iguales.  Los axones y las extremidades del arbol dendrítico tienen un
pequeño espacio entre ellos llamado espacio sináptico. Si la exitación
que proviene de un axón es suficiente, entonces el impulso se
transmite a la neurona, caso contrario no. Decimos que la primera es
una transmisión exitadora, pues aumenta la posibilidad de transmitir
el impulso, mientras que el otro caso se denomina transmisión
inhibidora, dado que reduce esa posibilidad.  De esta manera surge la
noción de \textit{pesos sinápticos}, que determinan cuando se activan
las conexiones y cuando no.  Otro aspecto a tener en cuenta es el
\textit{estímulo acumulativo}, en donde los estímulos de varios
receptores del arbol dendrítico se combinan de alguna manera para
activar o no la neurona (no hay punto intermedio). Este sistema de
tomar los impulsos de entrada y determinar si emitir el impulso de
salida se corresponde con nuestra \textit{función de activación} que
ya vimos. La función de activación representa entonces la frecuencia con
la que se activa la neurona.

Ahora podemos dar un modelo más formal de una neurona:

TODO grafica de neurona con inputs, weights, sumatoria, funcion de activacion, etc.

En la Figura, las entradas \(x_i\) interactúan multiplicativamente con
los pesos. En nuestra analogía con la neurona biológica, esas son las
sinapsis. Luego, el el cuerpo de la célula, esos resultados se suma
junto con un \textit{bias}, y luego se calcula la función de
activación para decidir si activar o no el axón.

** Entrenamiento de redes neuronales artificiales

Entrenar una red neuronal artificial no es muy distinto a entrenar un
clasificador lineal. Necesitamos definir una función de pérdida y un
método para ajustar los parámetros. Veremos además, como en otras
tareas de aprendizaje automático, que hay que tener en cuenta el
formato de los datos de entrada al model (tal vez eliminar ruido o
redundancia, normalizar las dimensiones). Esta tarea se denomina preprocesamiento de datos.

También analizaremos varias técnicas para evitar el sobre-ajuste de
modelos. El sobre-ajuste surge cuando un modelo aprende "ruido" y
detalles particulares del conjunto de datos en vez e características
generales que ayuden a la tarea de clasificación. 

Finalizaremos esta sección con un análisis de la organización interna
de las redes neuronales artificiales y qué algoritmos se utilizan
para entrenar.

*** Preprocesamiento de datos

Antes de comenzar con el entrenamiento de una red neuronal artificial
es conveniente analizar los datos y si es necesario normalizarlos para
que todos estén en el mismo rango de valores.

El preprocesamiento de datos, como alinear imágenes o normalizar
valores ayuda a una mejor convergencia de los modelos. Las dos
técnicas más comunes de preprocesamiento de datos para redes
neuronales son la substracción de la media y la normalización.

**** Substracción de la media

Como su nombre lo indica, se le resta la media a cada elemento del
conjunto de datos con el objetivo de \textit{centrar} los datos
alrededor del origen en todas las dimensiones. En las redes
convolucionales esto equivale a restarle el valor medio de los píxeles
a cada píxel de la imagen de entrada.

**** Normalización

Una manera de normalizar los datos es dividir cada dimensión por su
desviación estándar una vez que haya sido centrada en cero. De esta
manera se logra que las dimensiones tengan aproximadamente la misma
escala. Notar que en general los píxeles tienen valores en el rango de
0 a 255, por lo que sus dimensiones ya se encuentran en escalas
parecidas y cuando se trabaja con redes convolucionales no es
estrictamente necesario normalizar los datos de entrada.

**** Otras maneras de preprocesar datos

A la hora de entrenar redes convolucionales importan dos cosas: la
calidad de los datos y la cantidad. Es necesario que además de
preprocesar los datos con las técnicas usuales (substracción de media
por ejemplo), se tengan en cuenta aspectos de más alto nivel. Por ejemplo,
si estuvieramos entrenando una red de reconocimiento de rostros, es
mucho mejor contar con un dataset de caras alineadas en vez de un
dataset de caras en diferentes posiciones y ángulos. De esa manera
vamos a lograr que la red aprenda mejor que \textit{features} extraer
de las imágenes.

Además no siempre se puede contar con un dataset de millones de
imágenes para entrenar nuestra red, por lo que hay que aumentar
nuestros datos con técnicas de \textit{data augmentation}: repetir la
misma imagen pero con diferentes variaciones en el color, brillo,
saturación, incluso hacer leves desplazamientos y rotaciones.

*** Inicialización de pesos

A la hora de inicializar los pesos es escencial romper con la
simetría. Imaginemos que inicializamos todos los pesos en \(0\), algo
que podría parecer razonable. En una capa completamente conectada,
entonces todas las neuronas van a recibir el mismo valor de entrada
\(0\) (\(f(x)=\sum_i w_i x\) con \(w_i=0\)) por lo que sus salidas van
a ser todas iguales y por ende los gradientes que se calculen serán
los mismos, produciendo que los pesos se actualicen todos iguales y la
red no aprenda.

En cambio podemos inicializar los pesos con pequeños números
aleatorios cercanos a cero. Una opción común es utilizar una
distribución gaussiana con media cero y desviación estándar 0.01. Este
método, si bien es bastante \textit{ad-hoc}, es bastante usado. Hay
muchas otras maneras más sofisticadas de inicializar los pesos de una
red, pero su análisis escapa al alcance de este trabajo final.

*** Evitando el sobre-ajuste: Regularización y Dropout
#+LaTeX: \label{sec:regular}

Cuando se ajusta un modelo sobre un conjunto de datos, puede surgir el
problema del \textit{sobre-ajuste}. Esto significa que nuestro modelo
ajusto sus parametros demasiado bien al conjunto de datos de
entrenamiento, provocando que aprendiera detalles insignificantes del
mismo, principalmente \textit{ruido}. Como consecuencia, cuando se lo
prueba en un conjunto de datos nuevos, el modelo presenta un bajo
rendimiento.

Queremos elegir los mejores parámetros de \weights{} para evitar este
problema, y eso lo podemos hacer agregando una penalidad de
regularización \(R(W)\). Lo que buscamos con esto es poner
preferencias para algunos conjuntos de \weights{} sobre otros.

De esta manera, nuestra función de pérdida ahora cuenta con dos
componentes: \textit{pérdida de los datos} y \textit{componente de
regularización}:

\begin{equation}
     \boldsymbol{ L =\frac{1}{N} \sum_{i} L_i + \lambda R(W)}
\end{equation}

Notar que la pérdida total es el promedio de las pérdidas de cada
imagen, y que la penalización de la regularización sólo se suma una
vez.

Las técnicas de regularizacion más usadas son:

**** L2

Para cada peso de la red se calcula \(\frac{1}{2} \lambda w^2\) donde
\(\lambda\) es la tasa de regularización y se le suma a la función
objetivo. 

Una buena propiedad de la regularizacion es que al penalizar los pesos
grandes, obliga a \weights{} a generalizar y contemplar todas las
clases a la hora de clasificar. De esa manera, nuestro clasificador
final va a tomar en cuenta todas las dimensiones de entrada (algunas
con más o menos probabilidad) sin dar prioridad a una sola.

**** L1

Similar a la aterior, sólo que se le adiciona \(\lambda |w|\) a la
función objetivo. Los pesos tienden a converger a cero bajo la
regularización L1 y las redes tienden a usar un subconjunto de los
datos de entrada, convirtiendose en invariantes al ruido. En general
se prefiere la regularización L2 por obtenerse mejores resultados.

**** \textit{Dropout}

La técnica de \textit{dropout} \cite{dropout} consiste en mantener
activa una neurona con una probabilidad \(\boldsymbol{p}\), o
establecer su salida a cero en caso contrario.

Si consideramos una red neuronal con \(L\) capas, sea \(l \in
\{1,\dots,L\}\) el índice de cada capa oculta de la red. Sea
\(\boldsymbol{z}^{(l)}\) el vector de entrada a la capa \(l\),
\(\boldsymbol{y}^{(l)}\) el vector de salidas de la capa \(l\)
(\(\boldsymbol{y}^{(0)} = \boldsymbol{x}\) son los datos de entrada a
la red). \(W^{(l)}\) y \(\boldsymbol{b}^{(l)}\) son los parametros de
la capa \(l\). Dada una neurona \(i\) de la capa \(l\), la operacion
de \textit{feed-forward} de la red puede ser descripta como:

\begin{equation}
z^{(l+1)}_{i} = \boldsymbol{w}^{(l+1)}_{i} \boldsymbol{y}^{l} + b^{(l+1)}_{i},
\end{equation}

\begin{equation}
y^{(l+1)}_{i} = A(z^{(l+1)}_{i})
\end{equation}

Donde \(A\) es una función de activación. Si ahora agregamos \textit{dropout}:

\begin{equation}
r^{(l)}_{j} \sim Bernoulli(p),
\end{equation}

\begin{equation}
\tilde{\boldsymbol{y}}^{(l)} = \boldsymbol{r}^{(l)} * \boldsymbol{y}^{(l)},
\end{equation}

\begin{equation}
z^{(l+1)}_{i} = \boldsymbol{w}^{(l+1)}_{i} \tilde{\boldsymbol{y}}^{l} + b^{(l+1)}_{i},
\end{equation}

\begin{equation}
y^{(l+1)}_{i} = A(z^{(l+1)}_{i})
\end{equation}

Aquí \(*\) denota el producto elemento a elemento y
\(\boldsymbol{r}^{(l)}\) es un vector de variables aleatorias de
Bernoulli con probabilidad \(p\) de ser \(1\). Para cada capa se
calcula este vector \(\boldsymbol{r}^{(l)}\) y luego se lo multiplica
elemento a elemento por \(\boldsymbol{y}^{(l)}\) para reducir la
cantidad de neuronas activas, obteniendo como resultado
\(\tilde{\boldsymbol{y}}^{(l)}\) que a su vez va a ser la entrada de
la capa siguiente.

En cada iteración del entrenamiento, \textit{dropout} elimina neuronas
aleatoriamente y utiliza una \textit{subred} con menos neuronas que la
original, lo cual impide a las neuronas co-adaptarse entre si. La
co-adaptación ocurre cuando dos o más neuronas consecutivas dependen
mucho entre ellas para detectar \textit{features}, en vez de que cada
neurona busque un tipo particular de \textit{feature}.

Otra manera de pensarlo es la siguiente: una red neuronal con \(n\)
neuronas puede ser vista como una colección de \(2^n\)
\textit{subredes} que comparten todas los mismos pesos (\weights{}),
por lo cual la cantidad total de parámetros sigue siendo a lo sumo
\(O(n^2)\). Para cada elemento en el conjunto de entrenamiento se
elige una de estas \(2^n\) redes y apenas se la entrena. Esto es
comparable a entrenar distintos modelos y luego promediar sus
predicciones, algo que en general es muy útil en aprendizaje
automático pero rara vez se hace en aprendizaje profundo debido a que
cada modelo tarda mucho en entrenarse y es muy tedioso elegir buenos
hiperparámetros.

*** Organización y entrenamiento de redes neuronales

Las redes neuronales estan organizadas como un grafo acíclico de
neuronas, donde las salidas de unas se transforma en la entrada de
otras. Las neuronas se organizan en distintas capas conectadas, de esa
manera los cálculos se hacen con operaciones entre matrices, algo que
no podríamos hacer tan fácil si tuvieramos neuronas conectadas
aleatoriamente entre ellas.

El tipo más común de capa de neuronas es la capa \textit{totalmente
conectada}, en donde cada neurona de la capa anterior se conecta con
todas las neuronas de la capa siguiente, pero no comparten conexiones
dentro de la misma capa.

Usualmente no se cuenta a la capa de entrada de las redes como una
capa más, y la capa de salida no tiene funciones de activación, dado
que generalmente representan las puntuaciones de cada clase (en
clasificación) o alguna métrica (en regresión).

Las redes neuronales se entrenan partiendo del principio del descenso
del gradiente que se explicó en la Sección \ref{sec:sgd}. Notemos que
\loss{} es una función que depende de las imágenes de entrada \img{},
\weights{} y \bias{}. Sin embargo, como ya dijimos, el conjunto de
datos de entrenamiento es algo fijo en nuestro modelo, por lo que sólo
nos interesa calcular el gradiente sobre \weights{} y \bias{} para
poder actualizar sus parámetros. Ahora bien, derivar una función con
millones de parámetros (cantidad que suelen tener las redes neuronales
artificiales) es computacionalmente costoso, por lo que para
actualizar \weights{} con los nuevos pesos se utiliza un algoritmo
llamado \textit{backpropagation}.

**** \textit{Backpropagation}

En una función de una dimensión, llamémosle \(g\), la derivada se
expresa como:
\begin{equation}
     \boldsymbol{\frac{dg(x)}{dx} = \lim_{h\to 0} \frac{g(x + h) - g(x)}{h} }
\end{equation}

Cuando la función toma un vector de números en vez de uno solo, a las
derivadas las llamamos derivadas parciales y el \textit{gradiente} es
simplemente un vector de esas derivadas. Por ejemplo, sea \(g\) una
función que toma dos parámetros \(x\) e \(y\), entonces el gradiente
de \(g\) es \(\nabla g = [\frac{\partial g}{\partial x},
\frac{\partial g}{\partial y}]\)

Usualmente podemos diferenciar con métodos numéricos, asignando a
\(h\) números muy pequeños por ejemplo, pero esto requiere de muchos
cálculos, es lento y tan sólo una aproximación. Veremos más
adelante que la función \loss{} de las redes neuronales suele tener
decenas de millones de parámetros, y realizar tantas
operaciones para una sola actualización de \weights{} no es
conveniente. En la práctica usaremos el cálculo analítico del
gradiente, en el cual derivamos una fórmula directa que es muy rápida
de computar valiéndonos de la \textit{regla de la cadena}.

La \textit{regla de la cadena} nos ayuda a descomponer el cálculo del
gradiente de expresiones complejas en pequeños pasos. Por ejemplo,
tomemos nuevamente una función \(g\):

\begin{equation}
    g(x,y,z) = \frac{x}{y^2} + z
\end{equation}

Si quisieramos obtener su gradiente en \(x\) de la manera tradicional,
calculando el cociente de \(g(x+h) - g(x)\) con \(h\) cuando \({h \to
0}\) deberíamos realizar muchos cálculos computacionalmente
costosos. En cambio, podemos ver a \(g\) como una composición de
funciones:

\begin{equation}
    g(x,y,z) = \frac{x}{y^2} + z = q + z
\end{equation}

Y calcular su gradiente valiéndonos de la \textit{regla de la cadena}:

\begin{equation}
\frac{\partial g}{\partial z} = q
\end{equation}

\begin{equation}
\frac{\partial g}{\partial q} = z
\end{equation}

\begin{equation}
\frac{\partial g}{\partial x} = \frac{\partial g}{\partial q} \frac{\partial q}{\partial x} = \frac{z}{y^2}
\end{equation}

\begin{equation}
\frac{\partial g}{\partial y} = \frac{\partial g}{\partial q} \frac{\partial q}{\partial y} = \frac{-2zx}{y^3}
\end{equation}

Ahora podemos comenzar a estructurar nuestro algoritmo de optimización
en dos pasos: primero, evaluamos nuestra función \loss{} en los
parámetros actuales (\textit{forward pass}). Luego, partiendo de ese
resultado calculamos el gradiente en cada variable utilizando la
\textit{regla de la cadena}. De esta manera "propagamos" el error de la
predicción hacia atrás (\textit{backpropagation}) y corregimos
ligeramente los pesos para mejorar las futuras predicciones.

Una vez que contamos con el gradiente, actualizamos los parámetros de
\loss{} restándole un porcentaje del gradiente negativo calculado
(negativo porque queremos ir en dirección opuesta a donde crece la
función, o sea, ir a su mínimo). Ese porcentaje es llamado
\textit{tasa de aprendizaje} (\textit{learning rate}) y suele ser uno
de los parámetros más difíciles de elegir, ya que la calidad y rapidez
de aprendizaje dependen de él.

Idealmente computaríamos el gradiente sobre todo el conjunto de datos,
actualizaríamos los parámetros, y repetiríamos el ciclo hasta
conseguir un buen resultado. Sin embargo los conjuntos de datos para
entrenar las redes neuronales suelen tener cientos de miles o incluso
millones de imágenes, por lo cual se utiliza una técnica llamada
\textit{Descenso de Gradiente Estocástico} o \textit{SGD} por sus
siglas en inglés, en el cual se calcula el gradiente para una cantidad
predeterminada de imágenes (\textit{batches}), se actualizan los
parámetros y se vuelve a repetir el ciclo con otro subconjunto
distinto. Esto parte de la suposición de que todas las imágenes del
conjunto de datos estan correlacionadas entre sí. En teoría
\textit{SGD} utiliza una sola imagen por batch, pero dada la alta
paralelización que provee el hardware actual, conviene hacer lotes de
imágenes de 62, 128, 512 imágenes. El tamaño de los \textit{batches}
no es estrictamente un hiperparámetro que uno pueda
\textit{cross-}validar, sino que más bien depende del hardware sobre
el que se esté entrenando la red (en general se eligen potencias de
dos por cuestiones de eficiencia).
**** Transferencia de aprendizaje

Entrenar un modelo con un tipo específico de problema y luego utilizar
su \textit{conocimiento} para resolver otro problema nuevo, tal vez
incluso en un área distinta a la que fue pensado originalmente, es lo
que se llama transferencia de aprendizaje. Esta técnica ha cobrado
importancia en \textit{deep learning} dado que a menudo las redes son
muy profundas y tardan semanas en entrenarse, por lo que contar con
modelos preentrenados sobre los cuales se puedan ajustar ligeramente
los parámetros para resolver un nuevo problema es una ventaja. La
mayoría de los \textit{frameworks} modernos para implementar redes
neuronales soportan realizar transferencia de aprendizaje utilizando
modelos pre-entrenados.

** Redes Convolucionales
*** Introducción

Antes de introducirnos en el mundo de las redes convolucionales es
necesario definir qué es una convolución.

Una matriz de convolución, o \textit{kernel}, es una matriz
generalmente cuadrada y pequeña utilizada extensamente para detectar o
resaltar bordes y enfocar o desenfocar imágenes dependiendo de sus
valores y tamaño. Son muy utilizadas en el mundo de la visión por
computadoras, sobre todo en los pasos de extracción de
\textit{features} de una imagen a la hora de aplicar algoritmos de
aprendizaje automático.

Una convolución entre un \textit{kernel} y una imagen se realiza
sumando las multiplicaciones elemento a elemento entre \textit{kernel}
y una región de la imagen. Por ejemplo, sea \(C\) un \textit{kernel}
de \(3x3\) y \(A\) un pedazo de una imagen también de dimension
\(3x3\), entonces la convolución entre \(C\) y \(A\) (denotada con el símbolo\(*\)) es:

\begin{equation}
C
=
\begin{bmatrix}
    0  & 1 & 0 \\
    1  & -4 & 1 \\
    0  & 1 & 0 \\
\end{bmatrix}
\end{equation}

\begin{equation}
A
=
\begin{bmatrix}
    a  & b & c \\
    d  & e & f \\
    g  & h & i \\
\end{bmatrix}
\end{equation}

\begin{equation}
A * C = (a*0) + (b*1) + (c*0) + (d*1) + (e*-4) + (f*1) + (g*0) + (h*1) + (i*0)
\end{equation}

Observemos dos cosas: 
\begin{enumerate}

\item El resultado de la convolución entre un \textit{kernel} y su
correspondiente pedazo en la imagen (que hasta ahora es de un canal)
es un valor escalar, o sea un píxel correspondiente al canal de la
imagen sobre el cual hayamos convolucionado. Es decir, si
convolucionamos un \textit{kernel} a través de los 3 canales de una
imagen (rojo, verde y azul) vamos a obtener como resultado 3 valores
que se van a combinar para crear un píxel RGB (\textit{Red-Green-Blue}
por sus siglas en inglés).

\item Uno no realiza una sola convolución con un solo pedazo de la imagen,
sino que lo hace sobre \textit{toda} la imagen. Esto significa que el
\textit{kernel} se va "desplazando" a lo largo y ancho de la imagen
para generar, en cada ocasión, un escalar que va a formar parte de la
nueva imagen convolucionada.

\end{enumerate}

Las redes convolucionales hacen uso extensivo de estos
\textit{kernels}. De hecho, \textit{aprenden a generar}
\textit{kernels} para encontrar diversas características en las
imágenes, tanto de bajo nivel (bordes o colores) como de alto nivel
(neuronas que se activan cuando una persona sonríe, por ejemplo). Si
sumamos esto con la no linealidad propia de las redes neuronales
artificiales, obtenemos una poderosa herramienta de clasificación de
imágenes.


*** Diferencias con redes neuronales artificales convencionales
Las redes convolucionales cuentan con los mismos artefactos que las
redes convencionales que ya discutimos (neuronas con pesos, funciones
de pérdida, capas completamente conectadas). Incluso los mismos
métodos de entrenamiento pueden ser aplicados. La diferencia radica en
que las redes convolucionales asumen que están trabajando con
imágenes, lo que permite optimizar la arquitectura de las mismas,
reduciendo parámetros y mejorando el proceso de aprendizaje.

Imaginemos por un momento que quisieramos aprender a clasificar un
conjunto de imágenes de 200x200 píxeles con 3 canales de colores. Eso
nos da una dimensión de entrada de 200x200x3, por lo que una neurona
completamente conectada en la primer capa oculta tendría 120000
conexiones y por ende esa misma cantidad de pesos a entrenar. Si
tenemos en cuenta que seguramente vamos a requerir más de una neurona
(comúnmente cientos de ellas en una misma capa) podemos concluir que
este enfoque no escala bien para el procesamiento de imágenes.

Una red neuronal convolucional se aprovecha de la ventaja de que los
datos de entrada son imágenes y organiza las neuronas en 3
dimensiones: ancho, alto y profundidad. Tal como hicimos con las redes
neuronales convencionales, en la siguiente sección analizaremos los
tipos de capas de una red neuronal convolucional. Al final de la
Sección se dará una descripción general de la arquitectura de una red
convolucional y varios ejemplos de redes convolucionales conocidas.

*** Capas de una red convolucional
**** Capas Convolucionales

Una capa convolucional consta de un conjunto de filtros (o
\textit{kernels}) cuyos parámetros se pueden aprender. En general cada
filtro es pequeño a lo ancho y alto, pero se aplica a toda la
profundidad del volumen de entrada. Notar que el volumen de entrada
puede bien ser una imagen o las activaciones de otra capa.

Durante el entrenamiento o la clasificación de imagenes, estos filtros
se convolucionan a traves del ancho y alto de la imagen, produciendo
un mapa de activaciones en 2-D para cada filtro. Si "apilamos" los
mapas de activaciones de todos los filtros de una capa convolucional,
obtenemos un \textit{volumen} de salida.  En otras palabras, se
computa un producto punto entre el filtro y las distintas regiones de
la entrada. De esta manera cada elemento en el volumen de salida puede
ser interpretado como la salida de una neurona conectada a una pequeña
region de los datos de entrada, la cual comparte parámetros (pesos)
con las otras neuronas que corresponden al mismo filtro.

Esta conexión a una pequeña región en los datos de entrada es un
hiperparámetro de la red llamado \textit{campo receptivo}. Es
importante notar que los \textit{campos receptivos} son locales en una
pequeña área en cuanto al ancho y alto de la entrada, pero abarcan la
totalidad de la profundidad del volumen de entrada.

Otros hiperparámetros relacionados con las capas convolucionales son
la cantidad de filtros (\textit{K}), el espacio en píxeles entre cada
aplicacion de los filtros (\textit{stride}) y por ultimo el relleno
con ceros o \textit{zero-padding}, donde se le agrega un "marco" de 1
o mas ceros a la entrada de la capa.

**** \textit{Pooling}

Las capas de \textit{pooling} reducen la dimensión espacial de sus
entradas y por ende reducen la cantidad de parametros en la red,
ayudando a controlar el \textit{overfitting}. Lo más común es
insertar capas de \textit{pooling} luego de capas convolucionales.

Un método de \textit{pooling} muy usado es \textit{MAX Pooling}, en el
cual se calcula el máximo de un área local (generalmente 2x2 o 3x3) en
el ancho y largo del volumen de entrada y a través de cada una de las
"rodajas" que conforman la profundidad del volumen. De esta manera se
reduce espacialmente la entrada, pero no su profundidad.

**** Capas Completamente Conectadas (Fully-Connected)

Como su nombre lo indica, cada neurona de esta capa tiene conexiones a
todas las salidas (o activaciones) de la capa anterior. Por lo tanto
sus activaciones se pueden calcular con una multiplicacion de matrices
junto con el calculo del \textit{bias}, como ya se vio para las redes
neuronales convencionales.

*** Arquitecturas conocidas de redes convolucionales 

Normalmente una red convolucional esta compuesta de varias capas
convolucionales (CONV), capas de \textit{pooling} (POOL), capas
completamente conectadas (FC por sus siglas en ingles) y funciones de
activacion, generalmente rectificadores lineales (RELU).

El patron usual en redes convolucionales es una capa CONV seguida de
una capa RELU seguida de una capa de \textit{pooling}. Esto se repite
una o varias veces hasta reducir espacialmente las dimensiones de la
entrada de la red. Luego es comun utilizar capas FC hasta reducir las
dimensiones a las dimensiones de salida, que en el caso de
clasificacion son las probabilidades de cada clase.

A lo largo de los años ha habido varias arquitecturas de redes
convolucionales que cuentan con nombre propio, como por ejemplo LeNet
\cite{Lecun98gradient-basedlearning}, creada en los 90 por Yann LeCun
y utilizada para el reconocimiento de digitos manuscriptos. Esta red
fue utilizada con exito para leer codigos postales y cheques
bancarios.

En 2012, el ganador del desafio ImageNet ILSVRC, Alex Krizhevsky,
obtuvo un 16% de error utilizando una arquitectura llamada AlexNet
\cite{NIPS2012_4824}. Su arquitectura es muy similar a la de LeNet,
aunque mas profunda y fue una de las primeras en concatenar varias
capas CONV antes de una capa de \textit{pooling}.

Los ganadores del ISLVRC 2013 utilizaron una red llamada ZFNet
\cite{DBLP:journals/corr/ZeilerF13}, que era basicamente una
modificacion de AlexNet, con cambios en los hiperparametros y las
capas convolucionales.

En la misma competencia ILSVRC del 2014 se dieron a conocer dos redes,
GoogLeNet \cite{43022} y VGGNet \cite{Simonyan14c}. Ambas demostraron
que la profundidad de la red es una caracteristica critica a la hora
de obtener buenos resultados.

Si bien GoogLeNet fue la ganadora ese año, luego se demostro que
VGGNet es superior en muchas tareas de transferencia de aprendizaje,
por lo que es mas popular que GoogLeNet y se pueden encontrar muchos
modelos ya preentrenados.

Finalmente, ResNet (Residual Network) \cite{he15deepresidual}, la red
ganadora del ILSRVC 2015, cuenta con nada menos que 152 capas (VGGNet
cuenta con 19) y obteniendo un error de 3.57% en el top-5.

* Redes neuronales siamesas
#+LaTeX: \label{sec:siamesa}
* Entrenamiento de modelos de aprendizaje profundo utilizando información odométrica
#+LaTeX: \label{sec:odometry}
** datasets, de que son, sobre que cosa van a entrenar (predecir cambios en la imagen)
** Egomotion
** SFA

* Conclusiones 
#+LaTeX: \label{sec:concl}
* Plan de Trabajo                                :noexport:
** Datasets
1. MINST: http://yann.lecun.com/exdb/mnist/

2. KITTI (odometry): http://www.cvlibs.net/datasets/kitti/eval_odometry.php

3. SF: aparentemente es un challenge de ICMLA 2011, hay que mandar un mail para pedirlo: http://www.icmla-conference.org/icmla11/challenge.htm

4. ILSVRC2012: http://www.image-net.org/download-images (hay que crearse una cuenta)

** Prueba de Concepto con MNIST
DEADLINE: <2016-04-29 vie> 

EL objetivo es entender como hacer redes siamesas con Caffe

*** [100%] Preprocesamiento
Train set: 60K imagenes. Test set 10K imagenes.

Para pretraining de la red, hay que hacer un preprocesamiento del
dataset:
  1. Traslación relativa en un rango de [-3,3]
  2. Rotación relativa en un rango de [-30°,30°]
Tanto las traslaciones como las rotaciones fueron hechas con numeros
enteros (es decir, los angulos son -30º,-29º,-28º,..,29,30; igual para
las traslaciones).

Para cada par nuevo creado se eligieron las traslaciones y rotaciones
de manera aleatoria, de manera que cada par esta compuesto por la
imagen original y la imagen transformada aleatoriamente.

En total entrenaron con 5 millones de pares de imagenes. Eso significa
que hay que hacer 85 pares para 10000 imagenes y 83 pares para las
otras 50000 imagenes.

DUDA: no queda claro en el paper si el par esta compuesto por la
imagen original mas la imagen transformada o si esta compuesto por una
imagen previamente transformada a la cual se le hace una
transformacion relativa. Por lo pronto voy a efectuar el experimento
con la original+transformada.
**** DONE Crear codigo (c++) para levantar MNIST y devolver una lista de Mat's
**** DONE Modificar codigo para crear las transformaciones de rotacion y traslacion (OpenCV)
**** DONE Hacer que las rotaciones y traslaciones sean aleatorias
**** DONE Modificar codigo para guardar lmdb
**** DONE Modificar algunos aspectos de la parte de lmdb para guardar las nuevas imagenes (dos imagenes mergeadas en una, dimensiones: 28x28x2)
**** DONE Investigar como guardar multiples etiquetas por imagen (traslacion y rotacion)
https://groups.google.com/forum/#!searchin/caffe-users/multilabel/caffe-users/RuT1TgwiRCo/hoUkZOeEDgAJ
https://github.com/BVLC/caffe/issues/2407

Se probaron varias cosas:
***** Armar una DB para cada label (X,Y y Z) pero no anduvo
***** Armar una sola DB para todas las labels y despues slicearla pero no anduvo
para cada clase crear array de bytes asi: 0 0 0 1 donde si hay un cero
significa que esa label esta inactiva y si hay 1 significa que esta
activa

Va a haber un solo 1 por clase claramente

Entonces agarro y creo la base de datos de labels nomas, con la
dimension a lo ancho que sea la dimension de la clase de mayor tama;o
(en este caso las rotaciones, que son 61) y la profundidad que sea la
cantidad de clases a clasificar (en este caso 3: X, Y y Z).

Luego Sliceo la base de datos y con la capa ArgMax obtengo el indice
del mayor elemento de ese arreglo, que termina siendo la clase a la
que corresponde la imagen. A ese argmax obtenido lo mando a la capa de
accuracy/softmax por ejemplo

***** Armar una sola DB para datos y labels y despues slicear los labels
*** [66%] Entrenamiento
**** DONE Armar la red (.prototxt) teniendo en cuenta el Slice, los multiple Softmax y loss
Slice de los labels:
https://groups.google.com/forum/#!searchin/caffe-users/multilabel/caffe-users/RuT1TgwiRCo/hoUkZOeEDgAJ

BCCN: C96-P-C256-P
TCCN: F1000-D-Op

Para finetuning: BCCN-F500-D-Op

Para SFA, los valores optimos del parámetro m fueron 10 y 100.

La predicción es clasificación con tres capas soft-max loss (para
traslaciones en X,Y y rotacion en Z respectivamente). Cada SCNN
minimiza la suma de estas tres "losses".

Para que se pueda utilizar clasificación, hay que dividir los rangos
de traslación en en 7 classes y las rotaciones en 20 clases (donde
cada una corresponde a 3°)

Para MNIST, hay que tomar a las imágenes cuya traslación relativa esté
entre [-1,1] y rotación relativa entre [-3°,3°] como temporalmente
cercanas (es el parámetro T de la ecuación en la sección 3.3 del
paper).

**** DONE Iteraciones, learning rate, step
Para pretraining: 40K iteraciones con learning rate inicial de 0.01,
reducido en un factor de 2 cada 10K iteraciones.

Para finetuning: 4K iteraciones con un learning rate constante de
0.01.
**** TODO [%] Experimentos a realizar
Todos se basan en el pre-entrenamiento descripto en el item y luego finetuning
***** Egomotion, lr 0.01. Finetuning con 100 imagenes
***** Egomotion, lr 0.01. Finetuning con 300 imagenes
***** Egomotion, lr 0.01. Finetuning con 1000 imagenes
***** Egomotion, lr 0.01. Finetuning con 10000 imagenes

***** Egomotion, lr 0.001. Finetuning con 100 imagenes
***** Egomotion, lr 0.001. Finetuning con 300 imagenes
***** Egomotion, lr 0.001. Finetuning con 1000 imagenes
***** Egomotion, lr 0.001. Finetuning con 10000 imagenes

***** Egomotion, lr 0.0001. Finetuning con 100 imagenes
***** Egomotion, lr 0.0001. Finetuning con 300 imagenes
***** Egomotion, lr 0.0001. Finetuning con 1000 imagenes
***** Egomotion, lr 0.0001. Finetuning con 10000 imagenes

***** SFA, lr 0.01. Finetuning con 100 imagenes
***** SFA, lr 0.01. Finetuning con 300 imagenes
***** SFA, lr 0.01. Finetuning con 1000 imagenes
***** SFA, lr 0.01. Finetuning con 10000 imagenes

***** SFA, lr 0.001. Finetuning con 100 imagenes
***** SFA, lr 0.001. Finetuning con 300 imagenes
***** SFA, lr 0.001. Finetuning con 1000 imagenes
***** SFA, lr 0.001. Finetuning con 10000 imagenes

***** SFA, lr 0.0001. Finetuning con 100 imagenes
***** SFA, lr 0.0001. Finetuning con 300 imagenes
***** SFA, lr 0.0001. Finetuning con 1000 imagenes
***** SFA, lr 0.0001. Finetuning con 10000 imagenes

***** Entrenamiento standar desde cero, lr 0.01. Finetuning con 100 imagenes
***** Entrenamiento standar desde cero, lr 0.01. Finetuning con 300 imagenes
***** Entrenamiento standar desde cero, lr 0.01. Finetuning con 1000 imagenes
***** Entrenamiento standar desde cero, lr 0.01. Finetuning con 10000 imagenes

***** Entrenamiento standar desde cero, lr 0.001. Finetuning con 100 imagenes
***** Entrenamiento standar desde cero, lr 0.001. Finetuning con 300 imagenes
***** Entrenamiento standar desde cero, lr 0.001. Finetuning con 1000 imagenes
***** Entrenamiento standar desde cero, lr 0.001. Finetuning con 10000 imagenes

***** Entrenamiento standar desde cero, lr 0.0001. Finetuning con 100 imagenes
***** Entrenamiento standar desde cero, lr 0.0001. Finetuning con 300 imagenes
***** Entrenamiento standar desde cero, lr 0.0001. Finetuning con 1000 imagenes
***** Entrenamiento standar desde cero, lr 0.0001. Finetuning con 10000 imagenes


*** Evaluación
Las features obtenidas de las BCNN preentrenadas se evaluan teniendo
en cuenta el error en la clasificación de dígitos.  Se utilizan
conjuntos de entrenamiento de 100,300, 1K y 10K obtenidos del training
set de MNIST (sin transformaciones).  El test set que viene con MNIST
se utiliza para testing.

** Experimentos con KITTI y SF
*** Preprocesamiento
DEADLINE: <2016-05-13 vie>

Analizar como se eligen las clases (es un problema de
clasificacion). Hacer todos los scripts de preprocesamiento.
Crear las lmdb.

**** KITTI
Tiene 20501 imágenes. Se calculan las transformaciones entre las
imágenes cercanas utilizando los datos odométricos del dataset.
Similar a MNIST: se crean 20 clases para las transformaciones en X,Y,Z
(el paper no explica como). Se toman imágenes que estén separadas a lo
sumo por +-7 frames.  Para el entrenamiento se extraen patches de
227x227 de las imágenes (Caffe tiene la opcion de cropear la imagen a
la hora de entrenar, pero no se como se aplica a redes siamesas,
probablemente tenga que hacerlo como parte del preprocesamiento).

Para SFA, el threshold para imágenes temporalmente cercanas (T) es
también de +-7
El numero total de imagenes usadas para entrenamiento es 20501

**** SF
Análogo a KITTI, solo que además de las transformaciones en X,Y,Z
agregan los 3 "euler angles" (no entendi eso).

*** Arquitectura
BCNN: C96-P-C256-P-C384-C384-C256-P (dice que estan inspiradas en las
primeras capas de AlexNet, extraer tamaño de filtros de esa red)
TCNN: C256-C128-F500-D-Op. Los kernels convolucionales con 3x3.

*** Entrenamiento
DEADLINE: <2016-05-31 mar>
Se entrena por 60K iteraciones con batch size de 128, learning rate
inicial de 0.001 (reducido en un factor de 2 cada 20K iteraciones)

*** Evaluación
Los modelos KITTI-Net y SF-Net deben ser entrenados utilizando
alrededor de 20K imagenes unicas. Para hacer la comparacion mas justa
con las redes entrenadas con clases de imagenes, un model con AlexNet
sera entrenado con 20K imagenes tomadas de ILSVRC12 (20 ejemplos por
clase).  Las secciones de evaluacion en Intra-Class Keypoint Matching
y Visual Odometry los dejo para mas adelante.
**** Scene Recognition
Utilizar SUN database para el finetuning de las redes (SF-Net,
KITTI-Net y AlexNet-20K). El paper no aporta informacion sobre la
cantidad de iteraciones ni el learning rate usado.  Referirse al paper
para comparar resultados obtenidos.
**** Object Recognition
Utilizando subconjuntos de ILSVRC-2012 con 1, 5, 10 y 20 imagenes por
clase, hacer finetuning de KITTI-Net, KITTI-SFA-Net y AlexNet-Scratch
(AlexNet con pesos inicializados de manera aleatoria). Nuevamente el
paper no explica las iteraciones ni el learning rate utilizados.
** Mejoras al sistema
DEADLINE: <2016-06-17 vie>
Probar con otras redes.
Otros datasets (elegir datasets pequeños y ver que pasa).

* Bibliografía
#+LaTeX: \bibliographystyle{abbrv}
#+LaTex: \bibliography{MarcoTeorico}
