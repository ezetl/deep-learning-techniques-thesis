#+TITLE: Marco Teorico
#+AUTHOR:  Ruben Ezequiel Torti Lopez
#+EMAIL:   ret0110@famaf.unc.edu.ar
#+OPTIONS: H:5 title:nil creator:nil timestamp:nil skip:nil toc:nil
#+STARTUP: indent hideblocks
#+TAGS: noexport(n)
#+EXPORT_SELECT_TAGS: export
#+EXPORT_EXCLUDE_TAGS: noexport
#+PROPERTY: session *R* 

#+LATEX_HEADER: \usepackage[T1]{fontenc}
#+LATEX_HEADER: \usepackage[utf8]{inputenc}
#+LATEX_HEADER: \usepackage{ifthen,figlatex}
#+LATEX_HEADER: \usepackage{longtable}
#+LATEX_HEADER: \usepackage{float}
#+LATEX_HEADER: \usepackage{wrapfig}
#+LATEX_HEADER: \usepackage{subfigure}
#+LATEX_HEADER: \usepackage{xspace}
#+LATEX_HEADER: \usepackage[spanish]{babel}
#+LATEX_HEADER: \usepackage{url}\urlstyle{sf}
#+LATEX_HEADER: \usepackage{amscd}
#+LATEX_HEADER: \usepackage{wrapfig}

#+LATEX_HEADER: \newcommand{\ml}{\textit{machine learning}}
#+LATEX_HEADER: \newcommand{\ML}{\textit{Machine Learning}}
#+LATEX_HEADER: \newcommand{\dl}{\textit{deep learning}}
#+LATEX_HEADER: \newcommand{\DL}{\textit{Deep Learning}}
#+LATEX_HEADER: \newcommand{\cnn}{\textit{convolutional neural networks}}
#+LATEX_HEADER: \newcommand{\CNN}{\textit{Convolutional Neural Networks}}

* Introducción
** Que es computer vision

Para los seres humanos, percibir el mundo que nos rodea es una tarea
fácil. Millones de años de evolución nos han dotado con un sistema
visual altamente sofisticado que nos permite reconocer patrones muy
complejos del mundo tridimensional en el que vivimos. Distinguir
sombras, color, formas, o incluso cosas más generales, como
movimiento, potenciales amenazas o rostros de conocidos, son algunas
de las actividades que nuestros cerebros realizan casi de manera
inconsciente. Y si bien estas tareas pueden ser fáciles para nosotros,
no es tal el caso para las computadoras.

Richard Szeliski caracteriza a la visión por computadoras como un
\textit{problema inverso}, es decir, se busca describir el mundo que
uno ve en una o más imágenes y reconstruir sus propiedades tales como
forma, iluminación y distribuciones de color \cite{szeliski}

Una de las areas que más impulso ha tomado en los últimos años dentro
de la visión por computadoras es la clasificación de imágenes. Es
decir, dada una imagen y un conjunto de categorías, determinar a cual
de las categorías pertenece esa imagen. 
*** TODO definir mejor clasificación
*** TODO poner ejemplo de clasificación.
Inicialmente, para clasificar imágenes se usaba ....

** Gran cantidad de datos

Para 2016, Cisco estima que el 51\% del trafico de Internet va a
provenir de dispositivos WiFi, tales como celulares, \textit{tablets},
\textit{smart TV's}, etc.  Más aún, se estima que para el 2019 el 80\%
del tráfico IP va a ser video, superando al 67\% que existente en 2014
\cite{ciscostats}. Como tendencia podemos nombrar a Youtube, donde la
mitad de los videos son subidos desde dispositivos móviles
\cite{youtustats}.
 
Por otro lado, las redes sociales más populares como Facebook, Flickr
o Instagram almacenan una gigantesca cantidad de imágenes, contando la
última con más de 80 millones de imágenes subidas por día
\cite{instastats}. 

Con tantos videos, imágenes y demás contenido multimedia, no hay
posibilidades para el hombre de contar con los recursos suficientes
para anotar y clasificar cada uno de estos elementos. Para ello
debemos contar con herramientas de visión por computadoras para
filtrar, procesar y dar un sentido semántico a las imágenes.

** Introduccion de neural networks

Con la aparición de las redes neuronales en los '70s .... pero no se logró
imponer hasta que no se contara con un hardware que pudiera llevar a
cabo los entrenamientos en un tiempo razonable...

** Convolutional neural networks y deep learning
Deep learning es.... Convolutional neural networks provienen de...

** tomar cosas del paper
Trabajo Relacionado/State of the art, Hipótesis, Key words (de arxiv)

* Marco Teórico
Para establecer un marco teórico que ayude a este trabajo especial ser
un poco más autocontenido, comenzaremos por explorar algunos conceptos
básicos de \ml, luego nos introduciremos en \dl mientras se explican
conceptos de visión por computadoras.
** Definir conceptos generales de Machine learning

*** Objetivos y definicion de machine learning
usar diapositivas
*** Hiperparametros, significado
*** Medir correctitud de modelos aprendidos con distintos medidores (falsos positivos, falsos negativos, etc.)
** introduccion a neural networks
 Usar libro online de deeplearning, Usar libro del MIT.
 Componentes de una red neuronal
 Entrenamiento de una red neuronal: feed forward, back propagation, SGD, dropout, fine tuning. etc.
** redes convolucionales y deep learning
 diferencias con redes normales
** capas de una red 
** arquitecturas conocidas
(LeNet5, AlexNet, VGG, etc)
** redes siamesas


* Entrenamiento de redes siamesas utilizando información odométrica
** Conceptos generales sobre los cuales parte el trabajo
*** datasets, de que son, sobre que cosa van a entrenar (predecir cambios en la imagen)
*** Egomotion
*** SFA

* Plan de Trabajo
** Conseguir datasets
MINST: http://yann.lecun.com/exdb/mnist/
KITTI (odometry): http://www.cvlibs.net/datasets/kitti/eval_odometry.php
SF: aparentemente es un challenge de ICMLA 2011, hay que mandar un mail para pedirlo: http://www.icmla-conference.org/icmla11/challenge.htm

** Prueba de Concepto con MNIST
*** Preprocesamiento
El dataset tiene unas 60K imágenes. A cada dígito se le aplican dos
conjuntos de transformaciones aleatorias diferentes para generar los
pares (rotación y traslación).

*** Egomotion
Para pretraining de la red, hay que hacer un preprocesamiento del dataset:

  1. Traslación relativa en un rango de [-3,3]
  2. Rotación relativa en un rango de [-30°,30°].

La predicción es clasificación con tres capas soft-max loss (para
traslaciones en X,Y y rotacion en Z respectivamente). Cada SCNN
minimiza la suma de estas tres "losses".

Para que se pueda utilizar clasificación, hay que dividir los rangos
de traslación en en 7 classes y las rotaciones en 20 clases (donde
cada una corresponde a 3°)

*** Slow Feature Analysis (SFA)
Ellos comparan sus resultados (egomotion) contra SFA. En el paper
formulan SFA como un Contrastive Loss.

Para MNIST, hay que tomar a las imágenes cuya traslación relativa esté
entre [-1,1] y rotación relativa entre [-3°,3°] como temporalmente
cercanas (es el parámetro T de la ecuación en la sección 3.3 del
paper).

*** Arquitectura
BCCN: C96-P-C256-P
TCCN: F1000-D-Op

Para finetuning: BCCN-F500-D-Op

Para SFA, los valores optimos del parámetro m fueron 10 y 100.

*** Entrenamiento
Para pretraining: 40K iteraciones con learning rate inicial de 0.01,
reducido en un factor de 2 cada 10K iteraciones.

Para finetuning: 4K iteraciones con un learning rate constante de
0.01.

*** Evaluación
Las features obtenidas de las BCNN preentrenadas se evaluan teniendo en cuenta el error en la clasificación de dígitos.
Se utilizan conjuntos de entrenamiento de 100,300, 1K y 10K obtenidos del training set de MNIST (sin transformaciones).
El test set que viene con MNIST se utiliza para testing.
** Experimentos con KITTI y SF
*** Preprocesamiento KITTI
Tiene 20501 imágenes. Se calculan las transformaciones entre las
imágenes cercanas utilizando los datos odométricos del dataset.
Similar a MNIST: se crean 20 clases para las transformaciones en X,Y,Z
(el paper no explica como). Se toman imágenes que estén separadas a lo
sumo por +-7 frames.  Para el entrenamiento se extraen patches de
227x227 de las imágenes (Caffe tiene la opcion de cropear la imagen a
la hora de entrenar, pero no se como se aplica a redes siamesas,
probablemente tenga que hacerlo como parte del preprocesamiento).

Para SFA, el threshold para imágenes temporalmente cercanas (T) es
también de +-7

*** TODO Preprocesamiento SF
Análogo a KITTI, solo que además de las transformaciones en X,Y,Z
agregan los 3 "euler angles" (no entendí eso).

*** Arquitectura
*** Evaluación
**** Scene Recognition
**** Object Recognition
**** Intra-Class Keypoint Matching
**** Visual Odometry

** Aporte: imagenes satelitales? modificaciones a las redes?
   En el paper dicen que solo probaron con una red "standard" para
   fines demostrativos, tal vez con otras arquitecturas se obtengan
   distintos resultados.

* Herramientas   
Obtener acceso a algun server con Caffe+Ubuntu.

* Bibliografía
#+LaTeX: \bibliographystyle{abbrv}
#+LaTex: \bibliography{MarcoTeorico}
