#+TITLE: Reconocimiento visual empleando técnicas de apredizaje profundo
#+AUTHOR:  Rubén Ezequiel Torti López
#+EMAIL:   ret0110@famaf.unc.edu.ar
#+CREATOR: Rubén Ezequiel Torti López
#+LANGUAGE: es
#+OPTIONS: H:5 title:nil creator:nil timestamp:nil skip:nil toc:nil
#+STARTUP: indent hideblocks
#+TAGS: noexport(n)
#+EXPORT_SELECT_TAGS: export
#+EXPORT_EXCLUDE_TAGS: noexport
#+PROPERTY: session *R* 

#+LATEX_HEADER: \usepackage[T1]{fontenc}
#+LATEX_HEADER: \usepackage[utf8]{inputenc}
#+LATEX_HEADER: \usepackage{ifthen,figlatex}
#+LATEX_HEADER: \usepackage{longtable}
#+LATEX_HEADER: \usepackage{float}
#+LATEX_HEADER: \usepackage{wrapfig}
#+LATEX_HEADER: \usepackage{subfigure}
#+LATEX_HEADER: \usepackage{xspace}
#+LATEX_HEADER: \usepackage[spanish]{babel}
#+LATEX_HEADER: \usepackage{url}\urlstyle{sf}
#+LATEX_HEADER: \usepackage{amscd}
#+LATEX_HEADER: \usepackage{wrapfig}
#+LATEX_HEADER: \usepackage{amsmath}

#+LATEX_HEADER: \newcommand{\cl}{\textit{clasificadores lineales}}
#+LATEX_HEADER: \newcommand{\losss}{\textit{funciones de pérdida}}
#+LATEX_HEADER: \newcommand{\dg}{\textit{descenso de gradiente}}
#+LATEX_HEADER: \newcommand{\back}{\textit{backpropagation}}
#+LATEX_HEADER: \newcommand{\nn}{\textit{redes neuronales}}
#+LATEX_HEADER: \newcommand{\svms}{\textit{Support Vector Machines}}
#+LATEX_HEADER: \newcommand{\bow}{\textit{Bag of Words}}
#+LATEX_HEADER: \newcommand{\features}{\textit{features}}
#+LATEX_HEADER: \newcommand{\scores}{\textit{scores}}
#+LATEX_HEADER: \newcommand{\sift}{\textit{SIFT}}
#+LATEX_HEADER: \newcommand{\weights}{\(\boldsymbol{W}\)}
#+LATEX_HEADER: \newcommand{\img}{\(\boldsymbol{x_i}\)}
#+LATEX_HEADER: \newcommand{\bias}{\(\boldsymbol{b}\)}
#+LATEX_HEADER: \newcommand{\func}{\(\boldsymbol{f}\)}
#+LATEX_HEADER: \newcommand{\loss}{\(\boldsymbol{L}\)}

#+LATEX_HEADER: \newcommand{\ml}{\textit{machine learning}}
#+LATEX_HEADER: \newcommand{\ML}{\textit{Machine Learning}}
#+LATEX_HEADER: \newcommand{\dl}{\textit{deep learning}}
#+LATEX_HEADER: \newcommand{\DL}{\textit{Deep Learning}}
#+LATEX_HEADER: \newcommand{\cnn}{\textit{convolutional neural networks}}
#+LATEX_HEADER: \newcommand{\CNN}{\textit{Convolutional Neural Networks}}

* Introducción

Para los seres humanos, percibir el mundo que nos rodea es una tarea
fácil. Millones de años de evolución nos han dotado con un sistema
visual altamente sofisticado que nos permite reconocer patrones muy
complejos del mundo tridimensional en el que vivimos. Distinguir
formas, sombras y color, o incluso cosas más generales, como
movimiento, potenciales amenazas y rostros de conocidos, son algunas
de las actividades que nuestros cerebros realizan casi de manera
inconsciente. Y si bien estas tareas pueden ser fáciles para nosotros,
no es tal el caso para las computadoras.

Richard Szeliski caracteriza a la visión por computadoras como un
\textit{problema inverso}, es decir, se busca describir el mundo que
uno ve en una o más imágenes y reconstruir sus propiedades tales como
forma, iluminación y distribuciones de color \cite{szeliski}

Una de las áreas principales de de la visión por computadoras es la
clasificación de imágenes. Es decir, dada una imagen y un conjunto de
categorías, determinar a cual de las categorías pertenece esa
imagen. Tener un buen entendimiento de los algoritmos de clasificación
es crucial para desarrollar otras tareas dentro de la visión por
computadoras, dado que muchos problemas pueden ser reducidos a
clasificación: detección de objetos, descripcion de imágenes y
segmentación entre otros.

Sin embargo, es un problema más difícil de lo que aparenta. Una
fotografía es solamente un conjunto de números (píxeles), entonces
¿cómo darle significado semántico a un conjunto de números? Se podría
pensar en elaborar alguna métrica de distancia con los píxeles otra
imagen la cual sepamos está en la misma categoría, y si la distancia
es menor a un cierto umbral sabríamos que ambas pertenecen a la misma
clase. Sin embargo este enfoque carece de robustez, ya que el menor
cambio de \textit{iluminación} (o sea, variaciones en los píxeles)
podría alterar las métricas y confundir a nuestro modelo. No solamente
eso, los objetos en las imágenes podrían estar ocultos por el ambiente
(\textit{oclusión}), o en una posición diferente
(\textit{deformación}), o ser exactamente iguales, pero variar en
colores y pequeños detalles (\textit{variación intraclase}).

Diferentes métodos se han utilizado a lo largo de la historia para
taclear este problema: \textit{máquinas de vectores de soporte},
árboles de decisión, \textit{bolsas de palabras}, etc. En la mayoría
de los casos las \features y descriptores que se extraían de las
imágenes debían ser implementadas manualmente (por ejemplo:
histogramas de colores o descriptores \sift \cite{Lowe-SIFT}).

En los últimos años toda la parafernalia relativa a la clasificación
de imágenes fue ampliamente superada por las Redes Neuronales
Convolucionales. Desde el año 2010, todos los equipos ganadores del
desafío Imagenet usaron Redes Neuronales Convolucionales, cada vez con
resultados más precisos \cite{imagenet}.

A pesar de haber tenido su golpe de popularidad en los últimos años,
los primeros esbozos de modelar redes neuronales artificiales datan de
1958, cuando Frank Rosenblatt ideó el \textit{perceptron}, un
algoritmo para reconocimiento de patrones basado en una red de dos
capas de aprendizaje \cite{perceptron}. Sin embargo, en 1969 se
estableció que el poder de cómputo disponible en ese entonces no
bastaba para poder entrenar y correr grandes redes neuronales,
implicando que el área se estancara durante años \cite{minsky}. Tan
así es, que recién en 2006, con el abaratamiento de costos en hardware
de alto desempeño se pudieron implementar arquitecturas más complejas
(no necesariamente nuevas) y redes neuronales más profundas, algo que
se conoce como Aprendizaje Profundo (\textit{Deep Learning}).

Para poder entrenar Redes Neuronales Profundas, es necesario contar
con un conjunto de datos anotados muy grande, cuyos tamaños pueden ir
de las decenas de miles hasta millones de imágenes. Generalmente se
requiere un gran esfuerzo humano para etiquetar tantas imágenes.

Actualmente contamos con una increíble cantidad de imágenes para
etiquetar. Para 2016, Cisco estima que el 51\% del trafico de Internet
va a provenir de dispositivos WiFi, tales como celulares,
\textit{tablets}, \textit{smart TV's}, etc.  Más aún, se estima que
para el 2019 el 80\% del tráfico IP va a ser en forma de píxeles
(multimedia), superando al 67\% que existente en 2014
\cite{ciscostats}. Como tendencia podemos nombrar a Youtube, donde la
mitad de los videos son subidos desde dispositivos móviles
\cite{youtustats}. Por otro lado, las redes sociales más populares
como Facebook, Flickr o Instagram almacenan una gigantesca cantidad de
imágenes, contando la última con más de 80 millones de imágenes
subidas por día \cite{instastats}. Sin embargo, es practicamente
imposible contar con los recursos suficientes para anotar tantos
videos, imágenes y demás contenido multimedia.

Una posible solución al entrenamiento de redes profundas cuando no se
puede anotar una gran cantidad de datos es la propuesta por Agrawal et
al. \cite{LSM2015}. En la misma proponen utilizar información
odométrica disponible en cámaras (giróscopos, acelerómetros, etc) para
pre-entrenar redes neuronales profundas, y luego realizar una
transferencia de aprendizaje sobre un conjunto de datos anotados que
se desee, obteniendo la ventaja de no necesitar un conjunto tan grande
para lograr buena precisión.

En este trabajo final nos proponemos reproducir este paper, analizando
cada paso para luego proponer mejoras y aplicaciones al mundo real.

El trabajo está organizado como sigue: en la Sección \ref{sec:marco}
se introducirán conceptos del aprendizaje automático y las redes
neuronales artificiales para concluir con redes convolucionales, en la
Sección \ref{sec:siamesa} se presentará un método para entrenar
modelos de aprendizaje profundo mediante redes siamesas, que luego se
utilizará para reproducir los resultados de \cite{LSM2015} en la
Sección \ref{sec:odometry}. Finalmente, la Sección \ref{sec:concl}
presenta pensamientos finales y trabajo a futuro.

* Marco Teórico
#+LaTeX: \label{sec:marco}
** Aprendizaje Automático
*** Introducción

Las técnicas de aprendizaje automético tienen como objetivo
identificar patrones en conjuntos de datos utilizando herramientas de
la estadística, teoría de la información, cálculo y optimización entre
otras. De esta manera se pueden automatizar tareas, como por ejemplo
del filtro de correo basura (\textit{spam}), la verificación de
rostros o incluso predicción de precios en el mercado.

El aprendizaje automático adquiere relevancia cuando las tareas que se
desean automatizar son demasiado complejas para programarse
directamente. Por ejemplo la verificación de rostros debe tener en
cuenta detalles como variaciones en sombra, color, orientación, por no
mencionar las diferentes características que hay que extraer de una
cara para diferenciarla de otra (arrugas, prominencias y otros
rasgos).  Otro caso es el análisis de grandes volúmenes de datos, como
estadísticas del clima para crear nuevos modelos.

Hay varios paradigmas o ejes dentro del aprendizaje automatico que
definen los tipos de algoritmos, las técnicas de
entrenamiento y las potenciales aplicaciones de esos modelos:

**** Aprendizaje supervisado vs. no supervisado

Cuando se poseen anotaciones o alguna clase de etiqueta sobre los
datos a aprender, hablamos de aprendizaje supervisado. Retomando el
caso del verificador de rostros, las etiquetas serían el nombre o
algun identificador de cada persona y nuestro clasificador aprendería
a diferenciar las caras tomando como referencia las anotaciones.

Por otro lado, cuando los datos no estan categorizados de antemano
hablamos de aprendizaje no supervisado. Por ejemplo, si se contara con
una lista de casas con sus respectivos precios, su área en metros
cúbicos y cantidad de habitaciones y quisieramos encontrar alguna
relación entre ellas. Los algoritmos no supervisados trabajan
netamente sobre los datos \textit{tal como están}.

**** Aprendizaje pasivo vs. activo

El aprendizaje pasivo implica utilizar solamente los datos ya
existentes. El aprendizaje activo se refiere a interactuar con el
ambiente para obtener información, como por ejemplo preguntar a un
usuario si un rostro es de cierta persona y utilizar los datos
proporcionados durante su etrenamiento.

**** Aprendizaje \textit{online} vs. estadistico (\textit{batch learning})

En el aprendizaje \textit{online} los datos estan disponibles de
manera secuencial, actualizando el modelo en cada paso para lograr
mejores predicciones/clasificaciones. En el aprendizaje estadístico
primero se analiza una gran cantidad de datos (tal vez la totalidad
del conjunto) y solamente luego de haberlos analizado se pueden
obtener conclusiones o un modelo final.

*** Clasificadores lineales

Un clasificador lineal combina linealmente las caracteristicas (o
\textit{features}) de los datos de entrada para determinar a que clase
pertenecen los mismos, usualmente entrenado mediante técnicas de
aprendizaje supervisado.

Imaginemos que queremos clasificar imágenes, es decir, asignar una
etiqueta a un conjunto de píxeles. Para ello vamos a definir una
función \func{} que mapee píxeles \(\boldsymbol{x}\) a probablidades
de cada etiqueta (\textit{scores}). Supongamos que contamos con un
conjunto de datos de imágenes \(\boldsymbol{x_i} \in
\boldsymbol{R^{D}}\), donde \(\boldsymbol{i = 1\cdots N}\),
\(\boldsymbol{D}\) es la dimensión de cada imagen y \(\boldsymbol{y_i
= 1\cdots K}\) es la etiqueta asociada. Es decir, tenemos
\(\boldsymbol{N}\) imágenes y \(\boldsymbol{K}\) categorías.

Definamos ahora una función \(\boldsymbol{f\colon R^{D} \mapsto
R^{K}}\) como un mapeo lineal entre píxeles y \scores:

\begin{equation}
     \boldsymbol{f(x_i, W, b)= W x_i + b}
\end{equation}

Asumimos que la imagen \img{} es un vector de una sola columna
\([D \times 1]\), \weights{} es una matriz \([K \times D]\) y \bias{} es
otro vector \([K \times 1]\). A menudo la matriz \weights{} es llamada
los \textit{pesos} de \func{}, y a \bias{} el \textit{vector de sesgo}
dado que influencia los \scores{} de salida, pero sin interactuar con
\img{}.

Para entender mejor a los clasificadores lineales, podemos verlos de
la siguiente manera: si la imagen tiene \(32\times32\) píxeles y la
representamos con un vector columna de dimensión \(D\) (en este caso
\(D=1024=32*32\)), entonces en ese espacio \textit{D-dimensional} la
imagen es solamente un punto. Como se observa en la Figura
\ref{fig:cl} de manera simplificada, nuestro clasificador lineal
define una "línea" (un hiperplano en realidad) que separa cada clase
dentro de ese espacio multidimensional. Notar que en realidad la
multiplicación \(\boldsymbol{W x_i}\) está evaluado \(\boldsymbol{K}\)
clasificadores en paralelo, donde cada uno es una fila de \weights{}.


#+name: linear-classifier
#+begin_src python :session :exports none :results silent
import matplotlib
import matplotlib.pyplot as plt
from matplotlib import style
import os
import random
import numpy as np
from sklearn import svm

style.use("ggplot")

try:
    os.mkdir("images")
except:
    pass

matplotlib.use('Agg')

N = 50
x1 = np.random.normal(2, 0.5, size=50)
y1 = np.random.normal(2, 0.5, size=50)

x2 = np.random.normal(3.5, 0.5, size=50)
y2 = np.random.normal(3.5, 0.5, size=50)

fig = plt.figure()
axes = plt.gca()
axes.set_xlim([0,5])
axes.set_ylim([0,5])
ax1 = fig.add_subplot(111)
ax1.set_axis_bgcolor('white')  
ax1.grid(False, which='both')
#plt.tick_params(axis='x', which='both', bottom='off', top='off', labelbottom='off')
#plt.tick_params(axis='y', which='both', bottom='off', top='off', labelbottom='off')
ax1.axes.get_xaxis().set_ticks([])
ax1.axes.get_yaxis().set_ticks([])
ax1.spines['right'].set_visible(False)
ax1.spines['top'].set_visible(False)
for spine in ['left', 'bottom']:
    ax1.spines[spine].set_color('k')

ax1.scatter(x1, y1, s=20, c='b', marker="s")
ax1.scatter(x2, y2, s=20, c='r', marker="o")

# Fit a linear classifier
X = zip(x1,y1) + zip(x2,y2)
Y = [0]*50 + [1]*50 # 2 classes
linear_clf = svm.LinearSVC()
linear_clf.fit(X, Y)

# Get parameters and plot
coef = linear_clf.coef_[0]
a = -coef[0] / coef[1]
xx = np.linspace(-10,10)

yy = a * xx - linear_clf.intercept_[0] / coef[1]
yy2 = a * xx - linear_clf.intercept_[0] / coef[1] + 1
yy3 = a * xx - linear_clf.intercept_[0] / coef[1] - 1

ax1.plot(xx, yy, 'k-',  c='orchid', label=r'$Wx + b$')
ax1.plot(xx, yy2, '--',  c='mediumaquamarine', label=r'$Wx + (b + m)$')
ax1.plot(xx, yy3, '--',  c='sandybrown', label=r'$Wx + (b - m)$')

plt.legend(frameon=False)

plt.savefig('images/linear-classifier.pdf')
#+end_src

#+attr_latex: width=0.8\textwidth,placement=[p]
#+label: fig:cl
#+caption: Clasificador lineal. Cada punto representa una muestra en un espacio de dimensión \(\boldsymbol{D}=2\) con \(\boldsymbol{K}=2\) categorías. La tarea del clasificador es establecer un hiperplano entre las dos clases de datos, definido por la ecuación \(f(x_i, W, b)= W x_i + b\). A modo de ejemplo están graficados dos clasificadores lineales más con el \textit{vector de sesgo} ligeramente modificado. Se puede observar que \bias{} no afecta al clasificador sino que simplemente lo traslada a lo largo de las dimensiones.
[[file:images/linear-classifier.pdf]]

Mas adelante veremos como definir \weights{} y \bias{} para obtener un
buen clasificador.

*** Entrenamiento
En el caso de los clasificadores lineales, entrenar un modelo se
traduce en encontrar buenos valores de \weights{} y \bias{} que
minimicen el error.

Es muy común, cuando se cuenta con un conjunto de datos lo
suficientemente grande, dividirlo en al menos 3 subconjuntos
disjuntos: uno para entrenar el modelo, un segundo para validar el
modelo durante el entrenamiento y un tercero para probar el modelo una
vez entrenado. De esta manera se puede medir que tan bien el modelo
aprendió características relevantes a la clasificación y las pudo
aplicar a un conjunto de datos completamente nuevo (conjunto de
pruebas). Si la precisión que obtuvo nuestro modelo sobre este
conjunto de pruebas es muy baja, es un síntoma de que algo no anda
bien en el entrenamiento (ver problema de \textit{sobre-ajuste} en la
Sección \ref{sec:regular}).

A grandes rasgos, podemos describir el proceso de entrenamiento de un
clasificador de la siguiente manera:

\begin{enumerate}

\item Primero se mide el error actual del model con el conjunto (o un
      subconjunto) de datos de entrenamiento

\item Luego se actualizan los parámetros del clasificador (\weights{} y
      \bias{}) para minimizar ese error.

\item Se repiten los pasos anteriores hasta lograr la precisión deseada

\end{enumerate}

Por lo tanto hay dos aspectos a tener en cuenta antes de
entrenar un modelo: cómo medir efectivamente la tasa de error y cómo
actualizar sus parámetros para minimizarla. Para el primer caso se
define lo que se llama una \textit{función de pérdida}, mientras que
para el segundo analizaremos una técnica muy utilizada en aprendizaje
automático denominada \textit{descenso de gradiente}. Esto no
significa que sea la única alternativa para entrenar modelos, pero al
ser ampliamente utilizada en redes neuronales artifiales será la única
que analizaremos.

**** Función de costo

Una función de costo nos ayuda a saber que tan bien o mal está
actuando nuestro clasificador. Es decir, si la tasa de error del
clasificador es muy alta, el costo o la \textit{pérdida} será muy alta
y viceversa. Hay muchos tipos de funciones de costo, pero la idea
subyacente es la misma y puede ser expresada en la siguiente ecuación:

\begin{equation}
\boldsymbol{L}(\theta) = \frac{1}{N} \sum^{N}_{i} L(f(x_i;\theta), y_i)
\end{equation}

donde \(L\) es la función de pérdidad individual de cada muestra en el
conjunto de datos, \(f(x_i;\theta)\) es la predicción del modelo sobre
una muestra \(x_i\) con parámetros \(\theta\), \(y_i\) es el objetivo
(por ejemplo, la etiqueta de cada muestra del conjunto de datos en una
tarea de clasificación). Notar que para el caso de un clasificador
lineal los parámetros \(\theta\) son \weights{} y \bias{}. De ahora en
adelante utilizaremos \(\theta\) o \weights{} indiferentemente para
hablar de los parámetros de nuestro modelo.

Un ejemplo de función de perdida popular es la función de pérdida de
\textit{máquinas de vectores de soporte multiclase}. Sea \(f(x_i;
\theta)_j\) el puntaje asignado por el clasificador \(f\) a la clase
\(j\) con \(x_i\) como dato de entrada y parámetros \(\theta\) y sea
\(f(x_i, \theta)_{y_i}\) el puntaje asignado por \(f\) a la clase
verdadera de \(x_i\), o sea \(y_i\), entonces la pérdida para \(x_i\)
se calcula de la siguiente manera:

\begin{equation}
     L_i = \sum_{j \neq y_i} \max{(0, f(x_i; \theta)_j - f(x_i; \theta)_{y_{i}} + \Delta) }
\end{equation}

Se puede observar que esta función de pérdida busca que la clase
correcta tenga un puntaje más alto que las otras por un margen
\(\Delta\).

Cuando tenemos una función con la forma \( \max{(0,\_)} \) a menudo se
la llama función de pérdida bisagra (\textit{hinge loss} en inglés).

**** Descenso de Gradiente
#+LaTeX: \label{sec:sgd}

Ya contamos con una función para medir que tan bien o que tan mal está
comportándose nuestro modelo, la \textit{función de pérdida}. Como se
puede observar, esta función depende de nuestro \weights{} y las
imágenes (o \features{} que estemos usando). Nosotros no tenemos
control sobre nuestro conjunto de datos de entrenamiento, pero sí
podemos modificar los parámetros de \weights{} para producir la menor
pérdida posible.

El descenso de gradiente se utiliza para optimizar los pesos partiendo
de la premisa que el modelo es diferenciable con respecto a
\weights{}. Dado que queremos minimizar la funcion de costo \loss{},
lo que vamos a hacer es calcular su gradiente \(\boldsymbol{\nabla
L}\) respecto a cada parámetro y luego modificar cada uno ligeramente
con el objetivo de alcanzar un mínimo en la función. Entonces, si
\(\theta_{n}\) son nuestros parámetros en el paso \(n\) del
entrenamiento, calculamos \(\theta_{n+1}\) de la siguiente manera:

\begin{equation}
    \theta_{n+1} = \theta_n - \epsilon \frac{1}{m} \sum^{m}_{i} \nabla_{\theta_{n}} L(f(x_i; \theta_n), y_i)
\end{equation}

Donde \(\epsilon\) es conocido como la \textit{tasa de aprendizaje} y
\(m\) es la cantidad de elementos en el conjunto de datos. En la
ecuación se puede observar que se modifican los parámetros con
respecto a la dirección opuesta al gradiente, dado que el mismo indica
la dirección de crecimiento de una función pero nosotros queremos
encontrar un mínimo (Figura \ref{fig:gd}).

#+name: gradient-descent
#+begin_src python :session :exports none :results silent
import matplotlib
import matplotlib.pyplot as plt
import matplotlib.cm as cm
import matplotlib.mlab as mlab
from matplotlib import style
import numpy as np
from sklearn import svm

style.use("ggplot")

matplotlib.use('Agg')

fig = plt.figure()
axes = plt.gca()
axes.set_xlim([-2.5,2.5])
axes.set_ylim([-3,3])
ax1 = fig.add_subplot(111)
ax1.set_axis_bgcolor('white')  
ax1.grid(False, which='both')
ax1.axes.get_xaxis().set_ticks([])
ax1.axes.get_yaxis().set_ticks([])
ax1.spines['right'].set_visible(False)
ax1.spines['top'].set_visible(False)
ax1.spines['left'].set_visible(False)
ax1.spines['bottom'].set_visible(False)

delta = 0.025
x = np.arange(-3.0, 3.0, delta)
y = np.arange(-2.0, 2.0, delta)
X, Y = np.meshgrid(x, y)
Z1 = mlab.bivariate_normal(X, Y, 1.0, 1.0, 0.0, 0.0)

CS = plt.contour(X, Y, Z1)

ax1.annotate(r'$w_3$', xy=(-0.22, 0.16), xytext=(-0.49, 0.49),
             arrowprops=dict(width=2, headwidth=4, facecolor='black', shrink=0.01),)

ax1.annotate(r'$w_2$', xy=(-0.53, 0.53), xytext=(-0.85, 0.73),
             arrowprops=dict(width=2, headwidth=4, facecolor='black', shrink=0.01),)

ax1.annotate(r'$w_1$', xy=(-0.90, 0.76), xytext=(-1.02, 1.27),
             arrowprops=dict(width=2, headwidth=4, facecolor='black', shrink=0.01),)

ax1.annotate(r'$w_0$', xy=(-1.04, 1.30), xytext=(-1.61, 1.25),
             arrowprops=dict(width=2, headwidth=4, facecolor='black', shrink=0.01),)

plt.savefig('images/gradient-descent.pdf')
#+end_src

#+attr_latex: width=0.8\textwidth,placement=[p]
#+label: fig:gd
#+caption: Descenso de gradiente. Sea \(w\) un parámetro de \(\theta\), el gráfico ilustra cómo nuestra función de clasificación \(f\) alcaza un mínimo en \(w\) a medida que se actualiza su valor mediante la substracción del gradiente calculado en ese parámetro. Puesto de otra manera, podemos imaginar a \(w\) como una pelota que se suelta desde la cima de una montaña y desciende por la fuerza de la gravedad hasta el valle (instancia \(w_3\)). Una vez que la pelota alcanza el punto más bajo, se detendrá.
[[file:images/gradient-descent.pdf]]

Existen variantes mas sofisticadas del descenso de gradiente
(\textit{Momentum}, \textit{Nesterov Momentum}, \textit{Adagrad},
\textit{Rmsprop} entre otros). Lo más comun es utilizar alguna de
ellas con una técnica llamada \textit{descenso de gradiente
estocástico}, que se basa en calcular el gradiente de un subconjunto
del total de datos (\textit{batch}) y actualizar \weights{} al final
de cada \textit{batch}. Esto es muy útil dado que es
computacionalmente costoso calcular el gradiente de todo un conjunto
de datos con miles de imágenes a la vez y calcular el gradiente de un
\textit{batch} aproxima bastante bien el gradiente del total.

**** Clasificador \textit{Softmax}
Antes de saltar de lleno a las redes neuronales artificiales vamos a
describir brevemente un tipo de clasificador muy utilizado en las
mismas, el clasificador \textit{Softmax}.

La función \textit{Softmax} tiene la siguiente forma:

\begin{equation}
    \sigma(x)_j =  \frac{e^{f(x;\theta)_{j}}} {\sum_{k} e^{f(x;\theta)_{k}}}
\end{equation}

Actúa tomando un vector de valores reales arbitrarios y
transformándolos en un vector de probabilidades normalizadas (cuya
suma da uno).

Por lo tanto el clasificador Softmax tiene una función de pérdida
diferente. En vez de tratar a los resultados como puntajes para cada
clase (lo cual puede ser confuso y dificíl de comparar), Softmax
devuelve probabilidades normalizadas para cada clase.

Un clasificador Softmax no modifica la funcion \(f\) que ya
conocemos, pero sí interpreta los puntajes como probabilidades
logarítmicas sin normalizar, reemplazando la pérdida bisagra por una
\textit{entropía cruzada}:

\begin{equation}
     L_i = - \log \bigg( \frac{e^{f(x_i, \theta)_{y_{i}}}} {\sum_j e^{f(x_i, \theta)_j}}\bigg)
\end{equation}

Que es equivalente a:

\begin{equation}
     L_i = - f(x_i, \theta)_{y_{i}} + \log {\Big( \sum_j e^{f(x_i, \theta)_j}\Big)}
\end{equation}

Donde \(f_{y_{i}}\) representa el elemento \textit{j}-ésimo del vector
de puntajes calculado por \(f\). Nuevamente, la pérdida total es el
promedio de las pérdidas de cada imagen.

** Redes Neuronales Artificiales

Hasta ahora analizamos clasificadores lineales y un tipo particular
llamado softmax. Si conectáramos la salida de un clasificador lineal
\(s_1=W_1x+b_1\) con la entrada de otro clasificador \(s_2=W_2y+b_2\),
entonces obtendríamos un tercero:

\begin{equation}
s_3 = W_2 (W_1x + b_1) + b_2 = (W_2 W_1) x + (W_2 b_1) + b_2
\end{equation}

\begin{equation}
s_3 = W_3 x + b_3
\end{equation}

Es fácil hacer un chequeo de dimensiones para ver que efectivamente
podemos "colapsar" las matrices \(W_2\) y \(W_1\) en una sola, por lo
cual terminamos con otro clasificador lineal.

Notemos que por más que combinemos miles de clasificadores lineales
vamos a obtener un nuevo clasificador también lineal.  Una manera de
romper la linealidad de estas "capas" de clasificadores es, por
ejemplo, agregar lo que se llama \textit{función de activación}:
 
\begin{equation}
    s = W_2 \max{(0, W_1 x + b_1)} + b_2
\end{equation}
 
 
Lo que acabamos de definir es una red neuronal básica de dos capas, de
una neurona cada una.

Una sola neurona puede funcionar como un clasificador también (notar
el parecido con los clasificadores lineales), siempre que se eliga la
función de pérdida adecuada.
 
*** Funciones de activación comunes

Se han propuesto varias funciones de activación a lo largo de los
años. 

Inicialmente se intentó simular el comportamiento de las conexiones
sinápticas mediante la función de activación Sigmoide (\(\sigma\)),
por tener la propiedad de transformar la entrada a un rango entre 0 y
1, y tener además una derivada fácil de calcular (útil para
\textit{backpropagation}).  Luego se propuso la Tangente Hiperbólica
(\(\tanh\)), pero ambas fueron desplazadas en favor de las unidades
\textit{ReLU}, o \textit{Rectifier Linear Unit} en inglés, que son más
fáciles de calcular y no sufren del problema de saturación de
gradiente que poseen \(\sigma\) y \(\tanh\).

Nos concentraremos entonces en las unidades \textit{ReLU}, actualmente
muy populares en las redes convolucionales debido a sus buenas
propiedades.

Hay tres tipos de rectificadores lineales:

**** \textit{ReLU}
Una unidad ReLU establece un umbral en \(0\) a la salida de la
neurona. Es decir, la activación de una neurona va a ser \(0\) si su
salida fue negativa o un numero positivo en caso contrario (Figura
\ref{fig:relu}.a):

\begin{equation}
f(x) = \max{(0,x)}
\end{equation}

Comparada con \(\sigma\) y \(\tanh\), requiere menos operaciones, no
es saturante y converge hasta 6 veces más rápido que las funciones
sigmoide y tanh \cite{NIPS2012_4824}.

Una desventaja de las \textit{ReLU} es que pueden provocar la "muerte"
de neuronas durante el entrenamiento. Si un gran gradiente fluye a
través de una \textit{ReLU} durante el proceso de
\textit{backpropagation} entonces va a actualizar los pesos de esa
neurona de tal manera que no se vuelva a activar. Pensemos que el
proceso de actualización de \weights{} implica restar un porcentaje
del gradiente en \weights{}. Si el gradiente es muy grande entonces
los pesos sobre los que se realice la actualización terminarán siendo
muy pequeños. Como consecuencia, la unidad \textit{ReLU} no volverá a
activarse, pues sus valores de entrada siempre van a ser valores
negativos. Esta situación puede agravarse si la tasa de
aprendizaje es muy grande.

Una vez que la ReLU alcanza este estado, es improbable que vuelva a
activarse, dado que su gradiente en \(0\) es también \(0\), por lo que
un entrenamiendo mediante descenso de gradiente y
\textit{backpropagation} no va a modificar los pesos locales, dejando
a esa neurona "muerta".

**** \textit{Leaky ReLU}

Se puede solucionar el problema de la "muerte" de neuronas agregando
una pequeña pendiente negativa (de 0.01 por ejemplo) en los valores
negativos de la \textit{ReLU}. Esta función de activación es la que se
conoce como \textit{Leaky ReLU} \cite{zhang2014improving} (Figura
\ref{fig:relu}.b):

\begin{equation}
f(x) = 1(x<0)(\alpha x) + 1(x >= 0)(x)
\end{equation}

De esta manera nos aseguramos que al menos un pequeño gradiente fluya
durante \textit{backpropagation} cuando la neurona emite resultados
negativos, permitiendo que se normalicen los pesos a mediano/largo
plazo. Sin embargo no está demostrado del todo que las \textit{Leaky
ReLU} presenten una mejora sustancial en el entrenamiento de las
redes, por lo que las \{ReLU} convencionales siguen siendo ampliamente
usadas.

**** \textit{Maxout}

\begin{equation}
f(x) = \max{(w^{T}_{1} x + b_{1}, w^{T}_{2} x + b_{2})}
\end{equation}

\textit{Maxout} \cite{Maxout} es una generalización de las funciones
\textit{ReLU}, y obtiene lo mejor de los dos mundos: por un lado la
forma lineal y no saturante de las \textit{ReLUs} y por el otro evita
el problema de las neuronas que se mueren. A pesar de ello tiene la
desventaja de duplicar los parámetros para cada neurona, lo cual no
siempre es deseable, pues implica más tiempo de entrenamiento y
más consumo de memoria y recursos, sobre todo en redes profundas.
 
Notar que una \textit{ReLU} normal es básicamente una \textit{maxout}
con \(w_1,b_1 = 0\).

#+name: relus
#+begin_src python :session :exports none :results silent
import matplotlib
matplotlib.use('Agg')

import matplotlib.pyplot as plt
from matplotlib import style
import numpy as np

style.use("ggplot")

def config_ax(ax):
    ax.set_axis_bgcolor('white')
    ax.grid(False, which='both')
    ax.axes.get_xaxis().set_ticks([])
    ax.axes.get_yaxis().set_ticks([])
    ax.spines['right'].set_visible(False)
    ax.spines['left'].set_visible(False)
    ax.spines['top'].set_visible(False)
    ax.spines['bottom'].set_visible(False)
    ax.plot((0, 0), (0, 5), 'grey')
    ax.plot((-10, 10), (0, 0), 'grey')

fig, axes = plt.subplots(nrows=1, ncols=2)

for ax in axes:
    config_ax(ax)
    ax.set_xlim([-5, 5])
    ax.set_ylim([-1, 10])

X = np.arange(-10, 10)
axes[0].set_xlabel('a) ReLU')
axes[0].plot(X, np.maximum(0, X))

X = np.arange(0, 10)
Y = np.arange(0, 10)
X2 = np.arange(-10, 0)
Y2 = X2 *  0.1
print X2, Y2
X = np.append(X2, X)
Y = np.append(Y2, Y)
axes[1].set_xlabel('b) Leaky ReLU')
axes[1].plot(X, Y)

plt.savefig('images/relus.pdf')
#+end_src

#+attr_latex: width=0.8\textwidth,placement=[p]
#+label: fig:relu
#+caption: \textit{ReLU} vs. \textit{Leaky ReLU}. Se puede observar la pendiente negativa de la \textit{Leaky ReLU} para \(x<0\), la cual produce un gradiente \(\neq 0\) y evita la muerte de neuronas.
[[file:images/relus.pdf]]
*** Inspiración biológica de las redes neuronales artificiales

Nuestro cerebro está compuesto de más de doscientos tipos de neuronas,
sin embargo nos centraremos en el tipo estándar de neurona, un modelo
\textit{näive}.

#+name: neuron
#+begin_src python :session :exports none :results silent
import matplotlib.pyplot as plt
import matplotlib.patches as patches
import matplotlib.cbook as cbook

image = plt.imread("images/neuron.png")

fig, ax = plt.subplots()
im = ax.imshow(image)

ax.annotate('dendrita', xy=(540.73, 63.20), xytext=(422.78, 26.51),
             arrowprops=dict(width=2, headwidth=6, facecolor='black', shrink=0.01),)
ax.annotate('nucleo', xy=(493.11,151.44), xytext=(355.95, 70.19),
             arrowprops=dict(width=2, headwidth=6, facecolor='black', shrink=0.01),)
ax.annotate('axon', xy=(302.65,143.58), xytext=(305.28, 230.95),
             arrowprops=dict(width=2, headwidth=6, facecolor='black', shrink=0.01),)
ax.annotate('terminal', xy=(144.52, 326.18), xytext=(192.57, 362.87),
             arrowprops=dict(width=2, headwidth=6, facecolor='black', shrink=0.01),)

plt.axis('off')

plt.savefig('images/neuron.pdf')
#+end_src

#+attr_latex: width=0.8\textwidth,placement=[p]
#+label: fig:neuron
#+caption:
[[file:images/neuron.pdf]]

El cuerpo de la neurona esta compuesto de tres partes principales, el
arbol dendrítico, el cuerpo celular o soma y una extensión llamada
axón con ramificaciones en su extremo (Figura \ref{fig:neuron}). El
árbol dendrítico se conecta con los axones de otras neuronas y recibe
impulsos de éstas.  Una neurona puede estar conectada a cientos de
neuronas desde las que recibe impulsos, los cuales pueden o no activar
a la neurona en cuestión.  Si la esta se activa, entonces
retransmite el impulso a través de su axón.

Las conexiones del árbol dendrítico con otras neuronas no son todas
iguales.  Los axones y las extremidades del arbol tienen un
pequeño espacio entre ellos llamado espacio sináptico. Si la exitación
que proviene de un axón es suficiente, entonces el impulso se
transmite a la neurona, caso contrario no. Decimos que la primera es
una transmisión exitadora, pues aumenta la posibilidad de transmitir
el impulso, mientras que el otro caso se denomina transmisión
inhibidora, dado que reduce esa posibilidad.  De esta manera surge la
noción de \textit{pesos sinápticos}, que determinan cuando se activan
las conexiones y cuando no.  Otro aspecto a tener en cuenta es el
\textit{estímulo acumulativo}, en donde los estímulos de varios
receptores del arbol dendrítico se combinan de alguna manera para
activar o no la neurona (no hay punto intermedio). Este sistema de
tomar los impulsos de entrada y determinar si emitir el impulso de
salida se corresponde con nuestra \textit{función de activación} que
ya vimos. La función de activación representa entonces la frecuencia
con la que se activa la neurona.

#+name: neuron
#+begin_src python :session :exports none :results silent
import matplotlib.pyplot as plt
import matplotlib.patches as patches
import matplotlib.cbook as cbook

image = plt.imread("images/artificial-neuron.png")

fig, ax = plt.subplots()
im = ax.imshow(image)

props = {'ha': 'center', 'va': 'center'}
ax.text(75.50, 31.16, r'$x_1$', props, rotation=0, fontsize=15)
ax.text(75.50, 237.25, r'$x_2$', props, rotation=0, fontsize=15)
ax.text(75.50, 361.72, r'$x_3$', props, rotation=0, fontsize=15)
ax.text(84.50, 650.98, r'$x_{n-1}$', props, rotation=0, fontsize=15)
ax.text(75.50, 822.76, r'$x_n$', props, rotation=0, fontsize=15)

ax.text(419.30, 140.16, r'$* w_1$', props, rotation=-25, fontsize=15)
ax.text(419.30, 285.41, r'$* w_2$', props, rotation=-15, fontsize=15)
ax.text(419.30, 387.19, r'$* w_3$', props, rotation=-8, fontsize=15)
ax.text(450.30, 598.43, r'$* w_{n-1}$', props, rotation=11, fontsize=15)
ax.text(419.30, 729.36, r'$* w_n$', props, rotation=28, fontsize=15)

ax.text(856.71, 470.73, r'$\mathbf{\sum_{i=0}^n w_i x_i + b}$', props, rotation=0, fontsize=18)

ax.text(1219.67, 433.80, r'$\mathbf{Y}$', props, rotation=0, fontsize=18)

ax.text(1529.7, 480.88, r'$\mathbf{f(Y)}$', props, rotation=0, fontsize=18)

ax.text(1808, 433.80, r'$\mathbf{\widetilde{Y}}$', props, rotation=0, fontsize=18)

plt.axis('off')

plt.savefig('images/artificial-neuron.pdf')
#+end_src

#+attr_latex: width=0.8\textwidth,placement=[p]
#+label: fig:art-neuron
#+caption: Esquema de una neurona artificial. Las entradas (\(x\)) interactuan multiplicativamente con los pesos sinapticos (\(w\)) y se adicionan junto con un vector de sesgo (\(b\)). El resultado pasa por una funcion de activacion (\(f\)) que decide si la señal debe propagarse o no.
[[file:images/artificial-neuron.pdf]]

En la Figura \ref{fid:art-neuron} vemos un model formal de una neurona
estandar, en el que las entradas \(x_i\) interactúan
multiplicativamente con los pesos \(w_i\). En nuestra analogía con la
neurona biológica, esas son las sinapsis. Luego, el el cuerpo de la
célula, esos resultados se suman junto con un \textit{bias}, y luego se
calcula la función de activación que decide si transmitir o no la salida.

** Entrenamiento de redes neuronales artificiales

Entrenar una red neuronal artificial no es muy distinto a entrenar un
clasificador lineal. Necesitamos definir una función de pérdida y un
método para ajustar los parámetros. Veremos además, como en otras
tareas de aprendizaje automático, que hay que tener en cuenta el
formato de los datos de entrada al model (tal vez eliminar ruido o
redundancia, normalizar las dimensiones). Esta tarea se denomina
preprocesamiento de datos.

También analizaremos varias técnicas para evitar el sobre-ajuste de
modelos. El sobre-ajuste surge cuando un modelo aprende "ruido" y
detalles particulares del conjunto de datos en vez e características
generales que ayuden a la tarea de clasificación. 

Finalizaremos esta sección con un análisis de la organización interna
de las redes neuronales artificiales y qué algoritmos se utilizan
para entrenar.

*** Preprocesamiento de datos

Antes de comenzar con el entrenamiento de una red neuronal artificial
es conveniente analizar los datos y si es necesario normalizarlos para
que todos estén en el mismo rango de valores.

El preprocesamiento de datos, como alinear imágenes o normalizar
valores ayuda a una mejor convergencia de los modelos. Las dos
técnicas más comunes de preprocesamiento de datos para redes
neuronales son la substracción de la media y la normalización.

**** Substracción de la media

Como su nombre lo indica, se le resta la media a cada elemento del
conjunto de datos con el objetivo de \textit{centrar} los datos
alrededor del origen en todas las dimensiones (Figura
\ref{fig:mean}.b). En las redes convolucionales esto equivale a
restarle el valor medio de los píxeles a cada píxel de la imagen de
entrada.

#+name: mean-substraction
#+begin_src python :session :exports none :results silent
import matplotlib
import matplotlib.pyplot as plt
from matplotlib import style
from matplotlib import gridspec
import numpy as np

matplotlib.use('Agg')
style.use("ggplot")

fig = plt.figure(figsize=(10, 4)) 
gs = gridspec.GridSpec(1, 3, width_ratios=[1, 1, 1])
ax0 = plt.subplot(gs[0])
ax1 = plt.subplot(gs[1])
ax2 = plt.subplot(gs[2])
axes = [ax0, ax1, ax2]

axes[0].set_axis_bgcolor('white')
axes[0].grid(False, which='both')
axes[0].axes.get_xaxis().set_ticks([])
axes[0].axes.get_yaxis().set_ticks([])
axes[0].spines['right'].set_visible(False)
axes[0].spines['left'].set_visible(False)
axes[0].spines['top'].set_visible(False)
axes[0].spines['bottom'].set_visible(False)
axes[0].plot((0, 0), (-4, 4), 'grey')
axes[0].plot((-4, 4), (0, 0), 'grey')
axes[0].set_xlim([-4, 4])
axes[0].set_ylim([-4, 4])

axes[1].set_axis_bgcolor('white')
axes[1].grid(False, which='both')
axes[1].axes.get_xaxis().set_ticks([])
axes[1].axes.get_yaxis().set_ticks([])
axes[1].spines['right'].set_visible(False)
axes[1].spines['left'].set_visible(False)
axes[1].spines['top'].set_visible(False)
axes[1].spines['bottom'].set_visible(False)
axes[1].plot((0, 0), (-4, 4), 'grey')
axes[1].plot((-4, 4), (0, 0), 'grey')
axes[1].set_xlim([-4, 4])
axes[1].set_ylim([-4, 4])

axes[2].set_axis_bgcolor('white')
axes[2].grid(False, which='both')
axes[2].axes.get_xaxis().set_ticks([])
axes[2].axes.get_yaxis().set_ticks([])
axes[2].spines['right'].set_visible(False)
axes[2].spines['left'].set_visible(False)
axes[2].spines['top'].set_visible(False)
axes[2].spines['bottom'].set_visible(False)
axes[2].plot((0, 0), (-4, 4), 'grey')
axes[2].plot((-4, 4), (0, 0), 'grey')
axes[2].set_xlim([-4, 4])
axes[2].set_ylim([-4, 4])
    
N = 150
x1 = np.random.normal(2, 0.5, size=N)
y1 = np.random.normal(2, 0.5, size=N)

mx = np.mean(x1)
my = np.mean(y1)

x2 = x1 - mx
y2 = y1 - my
axes[0].set_xlabel('a) Original')
axes[0].scatter(x1, y1, s=20, c='royalblue', marker="s")

axes[1].set_xlabel('b) Substraccion de media')
axes[1].scatter(x2, y2, s=20, c='seagreen', marker="s")

x3 = x2 / 2.0
y3 = y2 / 2.0

axes[2].set_xlabel('c) Normalizacion')
axes[2].scatter(x3, y3, s=20, c='firebrick', marker="s")

plt.tight_layout()
plt.savefig('images/mean.pdf')
#+end_src

#+attr_latex: width=0.8\textwidth,placement=[p]
#+label: fig:mean
#+caption: Se puede observar en b) cómo al substraer la media de a) logramos "centrar" nuestro conjunto de datos. En c) podemos apreciar los resultados de la normalización de datos, logrando que todos los elementos pertenezcan al mismo rango de valores.
[[file:images/mean.pdf
]]
**** Normalización

Una manera de normalizar los datos es dividir cada dimensión por su
desviación estándar una vez que haya sido centrada en cero. De esta
manera se logra que las dimensiones tengan aproximadamente la misma
escala (Figura \ref{fig:mean}.c). Notar que en general los píxeles
tienen valores en el rango de 0 a 255, por lo que sus dimensiones ya
se encuentran en escalas parecidas y cuando se trabaja con redes
convolucionales no es estrictamente necesario normalizar los datos de
entrada.

**** Otras maneras de preprocesar datos

A la hora de entrenar redes convolucionales importan dos cosas: la
calidad de los datos y la cantidad. Es necesario que además de
preprocesar los datos con las técnicas usuales (substracción de media
por ejemplo), se tengan en cuenta aspectos de más alto nivel. Por ejemplo,
si estuvieramos entrenando una red de reconocimiento de rostros, es
mucho mejor contar con un dataset de caras alineadas en vez de un
dataset de caras en diferentes posiciones y ángulos. De esa manera
vamos a lograr que la red aprenda mejor que \textit{features} extraer
de las imágenes.

Además no siempre se puede contar con un dataset de millones de
imágenes para entrenar nuestra red, por lo que hay que aumentar
nuestros datos con técnicas de \textit{data augmentation}: repetir la
misma imagen pero con diferentes variaciones en el color, brillo,
saturación, incluso hacer leves desplazamientos y rotaciones.

#+name: augmentation
#+begin_src python :session :exports none :results silent
import matplotlib.pyplot as plt
import matplotlib.patches as patches
import matplotlib.cbook as cbook


fig, (ax1,ax2,ax3,ax4) = plt.subplots(nrows=1, ncols=4)


im1 = plt.imread("images/face-original.jpg")
im2 = plt.imread("images/face-aligned.jpg")
im3 = plt.imread("images/face-augmented1.jpg")
im4 = plt.imread("images/face-augmented2.jpg")

render1 = ax1.imshow(im1)
render2 = ax2.imshow(im2)
render3 = ax3.imshow(im3)
render4 = ax4.imshow(im4)

def setup(ax):
    ax.axes.get_xaxis().set_ticks([])
    ax.axes.get_yaxis().set_ticks([])
    ax.spines['right'].set_visible(False)
    ax.spines['left'].set_visible(False)
    ax.spines['top'].set_visible(False)
    ax.spines['bottom'].set_visible(False)

for ax in [ax1,ax2,ax3,ax4]:
    setup(ax)

ax1.set_xlabel('a) Original')
ax2.set_xlabel('b) Alineamiento')
ax3.set_xlabel('c) Color-Brillo')
ax4.set_xlabel('d) Traslaciones')

plt.savefig('images/augmentation.pdf')
#+end_src

#+attr_latex: width=0.8\textwidth,placement=[p]
#+label: fig:augm
#+caption: Diferentes formas de aumentar datos. Si trabajamos con rostros es muy común alinearlos, por ejemplo, utilizando el eje que conforman los ojos (a). Traslaciones, recortes en la imagen y cambios en el brillo, contraste y color son otras técnicas muy usadas.
[[file:images/augmentation.pdf]]

*** Inicialización de pesos

A la hora de inicializar los pesos es escencial romper con la
simetría. Imaginemos que inicializamos todos los pesos en \(0\), algo
que podría parecer razonable. En una capa completamente conectada,
entonces todas las neuronas van a recibir el mismo valor de entrada
\(0\) (\(f(x)=\sum_i w_i x\) con \(w_i=0\)) por lo que sus salidas van
a ser todas iguales y por ende los gradientes que se calculen serán
los mismos, produciendo que los pesos se actualicen todos iguales y la
red no aprenda.

En cambio podemos inicializar los pesos con pequeños números
aleatorios cercanos a cero. Una opción común es utilizar una
distribución gaussiana con media cero y desviación estándar 0.01. Este
método, si bien es bastante \textit{ad-hoc}, es bastante usado. Hay
muchas otras maneras más sofisticadas de inicializar los pesos de una
red, pero su análisis escapa al alcance de este trabajo final.

*** Evitando el sobre-ajuste: Regularización y Dropout
#+LaTeX: \label{sec:regular}

Cuando se aprende un modelo sobre un conjunto de datos, puede surgir
el problema del \textit{sobre-ajuste}, más conocido por su nombre en
inglés \textit{overfitting}. El \textit{overfitting} significa que
nuestro modelo ajustó sus parámetros demasiado bien al conjunto de
datos de entrenamiento, provocando que aprendiera detalles
insignificantes del mismo, principalmente \textit{ruido}
aleatorio. Como consecuencia, cuando se lo aplica en un conjunto de
datos nuevos, el modelo presenta un bajo rendimiento. En contrapartida
al \textit{overfitting}, a veces puede pasar que nuestro modelo
aprendió pocas características de nuestro conjunto de entrenamiento y
termina siendo muy genérico e inflexible a la hora de ser aplicado en
un conjunto nuevo, obteniendo también baja precisión (Figura
\ref{fig:overfit}).

#+name: overfitting
#+begin_src python :session :exports none :results silent
import matplotlib.pyplot as plt
from matplotlib.colors import ListedColormap
from sklearn.datasets import make_moons
from sklearn.cross_validation import train_test_split
from sklearn.neighbors import KNeighborsClassifier
from sklearn import metrics
import numpy as np
from sklearn.cross_validation import train_test_split, cross_val_score


def detect_plot_dimension(X, h=0.02, b=0.05):
    x_min, x_max = X[:, 0].min() - b, X[:, 0].max() + b
    y_min, y_max = X[:, 1].min() - b, X[:, 1].max() + b
    xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))
    dimension = xx, yy
    return dimension


def detect_decision_boundary(dimension, model):
    xx, yy = dimension # unpack the dimensions
    boundary = model.predict(np.c_[xx.ravel(), yy.ravel()])
    boundary = boundary.reshape(xx.shape) # Put the result into a color plot
    return boundary


def plot_decision_boundary(panel, dimension, boundary, colors=['paleturquoise', 'khaki']):
    xx, yy = dimension # unpack the dimensions
    panel.contourf(xx, yy, boundary, cmap=ListedColormap(colors), alpha=1)
    panel.contour(xx, yy, boundary, colors="brown", alpha=1, linewidths=0.5) # the decision boundary in green


def plot_dataset(panel, X, y, colors=["darkorange","darkcyan"], markers=["s", "o"]):
    panel.scatter(X[y == 1, 0], X[y == 1, 1], color=colors[0], marker=markers[0])
    panel.scatter(X[y == 0, 0], X[y == 0, 1], color=colors[1], marker=markers[1])


def calculate_prediction_error(model, X, y):
    yPred = model.predict(X)
    score = 1 - round(metrics.accuracy_score(y, yPred), 2)
    return score


def explore_fitting_boundaries(model, n_neighbors, datasets, width):
    # determine the height of the plot given the
    # aspect ration of each panel should be equal
    height = float(width)/len(n_neighbors) * len(datasets.keys())
    nrows = len(datasets.keys())
    ncols = len(n_neighbors)
    # set up the plot
    figure, axes = plt.subplots(
        nrows,
        ncols,
        figsize=(width, height),
        sharex=True,
        sharey=True
    )
    dimension = detect_plot_dimension(X, h=0.02) # the dimension each subplot based on the data
    # Plotting the dataset and decision boundaries
    i = 0
    for n in n_neighbors:
        model.n_neighbors = n
        model.fit(datasets["Training Set"][0], datasets["Training Set"][1])
        boundary = detect_decision_boundary(dimension, model)
        j = 0
        for d in datasets.keys():
            try:
                panel = axes[j, i]
            except (TypeError, IndexError):
                if (nrows * ncols) == 1:
                    panel = axes
                elif nrows == 1: # if you only have one dataset
                    panel = axes[i]
                elif ncols == 1: # if you only try one number of neighbors
                    panel = axes[j]
            plot_decision_boundary(panel, dimension, boundary) # plot the decision boundary
            plot_dataset(panel, X=datasets[d][0], y=datasets[d][1]) # plot the observations
            score = calculate_prediction_error(model, X=datasets[d][0], y=datasets[d][1])
            # make compacted layout
            panel.set_frame_on(False)
            panel.set_xticks([])
            panel.set_yticks([])
            j += 1
        if i==0:
            panel.set_xlabel(r'a) $\mathit{Underfitting}$')
        elif i==1:
            panel.set_xlabel(r'b) Ajuste aceptable')
        elif i==2:
            panel.set_xlabel(r'c) $\mathit{Overfitting}$')
        i += 1
        plt.subplots_adjust(hspace=0, wspace=0) # make compacted layout
    plt.savefig('images/overfitting.pdf')


X, y = make_moons(
n_samples=500,
random_state=1,
noise=0.3
)
# Split into training and test sets
XTrain, XTest, yTrain, yTest = train_test_split(X, y, random_state=1, test_size=0.5)

# specify the model and settings
model = KNeighborsClassifier()
n_neighbors = [200, 23, 1]
datasets = {"Training Set": [XTrain, yTrain]}
width = 20

# explore_fitting_boundaries(model, n_neighbors, datasets, width)
explore_fitting_boundaries(model=model, n_neighbors=n_neighbors, datasets=datasets, width=width)
#+end_src

#+attr_latex: width=0.8\textwidth,placement=[p]
#+label: fig:overfit
#+caption: Ejemplo de \textit{overfitting} y \textit{underfitting}. Se puede observar un gran sesgo en el caso de \textit{underfitting} (a) que si bien permite una mayor generalización no logra distinguir el límite entre ambas clases, lo cual se traduce en menor precisión a la hora de evaluar el modelo. En (c) observamos un típico caso de \textit{overfitting} con mucha variación y sensibilidad a los datos de entrenamiento, lo cual implica poca generalización a nuevos datos.
[[file:images/overfitting.pdf]]


Queremos elegir los mejores parámetros de \weights{} para evitar estos
problemas, y eso lo podemos hacer agregando una penalidad de
regularización \(R(W)\). Lo que buscamos con esto es poner
preferencias para algunos conjuntos de \weights{} sobre otros.

De esta manera, nuestra función de pérdida ahora cuenta con dos
componentes: \textit{pérdida de los datos} y \textit{componente de
regularización}:

\begin{equation}
     \boldsymbol{ L =\frac{1}{N} \sum_{i} L_i + \lambda R(W)}
\end{equation}

Notar que la pérdida total es el promedio de las pérdidas de cada
imagen, y que la penalización de la regularización sólo se suma una
vez.

Las técnicas de regularizacion más usadas son:

**** L2

Para cada peso de la red se calcula \(\frac{1}{2} \lambda w^2\) donde
\(\lambda\) es la tasa de regularización y se le suma a la función
objetivo. 

Una buena propiedad de la regularizacion es que al penalizar los pesos
grandes, obliga a \weights{} a generalizar y contemplar todas las
clases a la hora de clasificar. De esa manera, nuestro clasificador
final va a tomar en cuenta todas las dimensiones de entrada (algunas
con más o menos probabilidad) sin dar prioridad a una sola.

**** L1

Similar a la aterior, sólo que se le adiciona \(\lambda |w|\) a la
función objetivo. Los pesos tienden a converger a cero bajo la
regularización L1 y las redes tienden a usar un subconjunto de los
datos de entrada, convirtiendose en invariantes al ruido. En general
se prefiere la regularización L2 por obtenerse mejores resultados.

**** \textit{Dropout}

La técnica de \textit{dropout} \cite{dropout} consiste en mantener
activa una neurona con una probabilidad \(\boldsymbol{p}\), o
establecer su salida a cero en caso contrario.

Si consideramos una red neuronal con \(L\) capas, sea \(l \in
\{1,\dots,L\}\) el índice de cada capa oculta de la red. Sea
\(\boldsymbol{z}^{(l)}\) el vector de entrada a la capa \(l\),
\(\boldsymbol{y}^{(l)}\) el vector de salidas de la capa \(l\)
(\(\boldsymbol{y}^{(0)} = \boldsymbol{x}\) son los datos de entrada a
la red). \(W^{(l)}\) y \(\boldsymbol{b}^{(l)}\) son los parametros de
la capa \(l\). Dada una neurona \(i\) de la capa \(l\), la operacion
de \textit{feed-forward} de la red puede ser descripta como:

\begin{equation}
z^{(l+1)}_{i} = \boldsymbol{w}^{(l+1)}_{i} \boldsymbol{y}^{l} + b^{(l+1)}_{i},
\end{equation}

\begin{equation}
y^{(l+1)}_{i} = A(z^{(l+1)}_{i})
\end{equation}

Donde \(A\) es una función de activación. Si ahora agregamos \textit{dropout}:

\begin{equation}
r^{(l)}_{j} \sim Bernoulli(p),
\end{equation}

\begin{equation}
\tilde{\boldsymbol{y}}^{(l)} = \boldsymbol{r}^{(l)} * \boldsymbol{y}^{(l)},
\end{equation}

\begin{equation}
z^{(l+1)}_{i} = \boldsymbol{w}^{(l+1)}_{i} \tilde{\boldsymbol{y}}^{l} + b^{(l+1)}_{i},
\end{equation}

\begin{equation}
y^{(l+1)}_{i} = A(z^{(l+1)}_{i})
\end{equation}

Aquí \(*\) denota el producto elemento a elemento y
\(\boldsymbol{r}^{(l)}\) es un vector de variables aleatorias de
Bernoulli con probabilidad \(p\) de ser \(1\). Para cada capa se
calcula este vector \(\boldsymbol{r}^{(l)}\) y luego se lo multiplica
elemento a elemento por \(\boldsymbol{y}^{(l)}\) para reducir la
cantidad de neuronas activas, obteniendo como resultado
\(\tilde{\boldsymbol{y}}^{(l)}\) que a su vez va a ser la entrada de
la capa siguiente.

En cada iteración del entrenamiento, \textit{dropout} elimina neuronas
aleatoriamente y utiliza una \textit{subred} con menos neuronas que la
original, lo cual impide a las neuronas co-adaptarse entre si. La
co-adaptación ocurre cuando dos o más neuronas consecutivas dependen
mucho entre ellas para detectar \textit{features}, en vez de que cada
neurona busque un tipo particular de \textit{feature}.

Otra manera de pensarlo es la siguiente: una red neuronal con \(n\)
neuronas puede ser vista como una colección de \(2^n\)
\textit{subredes} que comparten todas los mismos pesos (\weights{}),
por lo cual la cantidad total de parámetros sigue siendo a lo sumo
\(O(n^2)\). Para cada elemento en el conjunto de entrenamiento se
elige una de estas \(2^n\) redes y apenas se la entrena. Esto es
comparable a entrenar distintos modelos y luego promediar sus
predicciones, algo que en general es muy útil en aprendizaje
automático pero rara vez se hace en aprendizaje profundo debido a que
cada modelo tarda mucho en entrenarse y es muy tedioso elegir buenos
hiperparámetros.
***** TODO dibujo de dropout (sacar del paper de dropout)
*** Organización de las redes neuronales

Las redes neuronales estan organizadas como un grafo acíclico de
neuronas, donde las salidas de unas se transforma en la entrada de
otras. Las neuronas se organizan en distintas capas conectadas, de esa
manera los cálculos se hacen con operaciones entre matrices, algo que
no podríamos hacer tan fácil si tuvieramos neuronas conectadas
aleatoriamente entre ellas.

El tipo más común de capa de neuronas es la capa \textit{totalmente
conectada}, en donde cada neurona de la capa anterior se conecta con
todas las neuronas de la capa siguiente, pero no comparten conexiones
dentro de la misma capa.

Usualmente no se cuenta a la capa de entrada de las redes como una
capa más, y la capa de salida no tiene funciones de activación, dado
que generalmente representan las puntuaciones de cada clase (en
clasificación) o alguna métrica (en regresión).

**** TODO dibujo de capas de una red neuronal artificial (FC, input, output)
Las redes neuronales se entrenan partiendo del principio del descenso
del gradiente que se explicó en la Sección \ref{sec:sgd}. Notemos que
\loss{} es una función que depende de las imágenes de entrada \img{},
\weights{} y \bias{}. Sin embargo, como ya dijimos, el conjunto de
datos de entrenamiento es algo fijo en nuestro modelo, por lo que sólo
nos interesa calcular el gradiente sobre \weights{} y \bias{} para
poder actualizar sus parámetros. Ahora bien, derivar una función con
millones de parámetros (cantidad que suelen tener las redes neuronales
artificiales) es computacionalmente costoso, por lo que para
actualizar \weights{} con los nuevos pesos se utiliza un algoritmo
llamado \textit{backpropagation}.

*** Entrenamiento: \textit{Backpropagation}
El entrenamiento de las redes neuronales se basa en el algoritmo de
\textit{descenso de gradiente} que ya vimos. Sea \(g\) una funcion de
una dimension, entonces su derivada se expresa como:

\begin{equation}
     \boldsymbol{\frac{dg(x)}{dx} = \lim_{h\to 0} \frac{g(x + h) - g(x)}{h} }
\end{equation}

Cuando la función toma un vector de números en vez de uno solo, a las
derivadas las llamamos derivadas parciales y el \textit{gradiente} es
simplemente un vector de esas derivadas. Por ejemplo, sea \(g\) una
función que toma dos parámetros \(x\) e \(y\), entonces el gradiente
de \(g\) es \(\nabla g = [\frac{\partial g}{\partial x},
\frac{\partial g}{\partial y}]\)

Usualmente podemos diferenciar con métodos numéricos, asignando a
\(h\) números muy pequeños por ejemplo, pero esto requiere de muchos
cálculos, es lento y tan sólo una aproximación. Veremos más
adelante que la función \loss{} de las redes neuronales suele tener
decenas de millones de parámetros, y realizar tantas
operaciones para una sola actualización de \weights{} no es
conveniente. En la práctica usaremos el cálculo analítico del
gradiente, en el cual derivamos una fórmula directa que es muy rápida
de computar valiéndonos de la \textit{regla de la cadena}.

La \textit{regla de la cadena} nos ayuda a descomponer el cálculo del
gradiente de expresiones complejas en pequeños pasos. Por ejemplo,
tomemos nuevamente una función \(g\):

\begin{equation}
    g(x,y,z) = \frac{x}{y^2} + z
\end{equation}

Si quisieramos obtener su gradiente en \(x\) de la manera tradicional,
calculando el cociente de \(g(x+h) - g(x)\) con \(h\) cuando \({h \to
0}\) deberíamos realizar muchos cálculos computacionalmente
costosos. En cambio, podemos ver a \(g\) como una composición de
funciones:

\begin{equation}
    g(x,y,z) = \frac{x}{y^2} + z = q + z
\end{equation}

Y calcular su gradiente valiéndonos de la \textit{regla de la cadena}:

\begin{equation}
\frac{\partial g}{\partial z} = q
\end{equation}

\begin{equation}
\frac{\partial g}{\partial q} = z
\end{equation}

\begin{equation}
\frac{\partial g}{\partial x} = \frac{\partial g}{\partial q} \frac{\partial q}{\partial x} = \frac{z}{y^2}
\end{equation}

\begin{equation}
\frac{\partial g}{\partial y} = \frac{\partial g}{\partial q} \frac{\partial q}{\partial y} = \frac{-2zx}{y^3}
\end{equation}

Ahora podemos comenzar a estructurar nuestro algoritmo de optimización
en dos pasos: primero, evaluamos nuestra función \loss{} en los
parámetros actuales (\textit{forward pass}). Luego, partiendo de ese
resultado calculamos el gradiente en cada variable utilizando la
\textit{regla de la cadena}. De esta manera "propagamos" el error de la
predicción hacia atrás (\textit{backpropagation}) y corregimos
ligeramente los pesos para mejorar las futuras predicciones.

**** TODO dibujo de regla de la cadena para aplicar backpropagation

Una vez que contamos con el gradiente, actualizamos los parámetros de
\loss{} restándole un porcentaje del gradiente negativo calculado
(negativo porque queremos ir en dirección opuesta a donde crece la
función, o sea, ir a su mínimo). Ese porcentaje es llamado
\textit{tasa de aprendizaje} (\textit{learning rate}) y suele ser uno
de los parámetros más difíciles de elegir, ya que la calidad y rapidez
de aprendizaje dependen de él.

Idealmente computaríamos el gradiente sobre todo el conjunto de datos,
actualizaríamos los parámetros, y repetiríamos el ciclo hasta
conseguir un buen resultado. Sin embargo los conjuntos de datos para
entrenar las redes neuronales suelen tener cientos de miles o incluso
millones de imágenes, por lo cual se utiliza una técnica llamada
\textit{Descenso de Gradiente Estocástico} o \textit{SGD} por sus
siglas en inglés, en el cual se calcula el gradiente para una cantidad
predeterminada de imágenes (\textit{batches}), se actualizan los
parámetros y se vuelve a repetir el ciclo con otro subconjunto
distinto. Esto parte de la suposición de que todas las imágenes del
conjunto de datos estan correlacionadas entre sí. En teoría
\textit{SGD} utiliza una sola imagen por batch, pero dada la alta
paralelización que provee el hardware actual, conviene hacer lotes de
imágenes de 62, 128, 512 imágenes. El tamaño de los \textit{batches}
no es estrictamente un hiperparámetro que uno pueda
\textit{cross-}validar, sino que más bien depende del hardware sobre
el que se esté entrenando la red (en general se eligen potencias de
dos por cuestiones de eficiencia).

**** Transferencia de aprendizaje

Entrenar un modelo con un tipo específico de problema y luego utilizar
su \textit{conocimiento} para resolver otro problema nuevo, tal vez
incluso en un área distinta a la que fue pensado originalmente, es lo
que se llama transferencia de aprendizaje. Esta técnica ha cobrado
importancia en \textit{deep learning} dado que a menudo las redes son
muy profundas y tardan semanas en entrenarse, por lo que contar con
modelos preentrenados sobre los cuales se puedan ajustar ligeramente
los parámetros para resolver un nuevo problema es una ventaja. La
mayoría de los \textit{frameworks} modernos para implementar redes
neuronales soportan realizar transferencia de aprendizaje utilizando
modelos pre-entrenados.

** Redes Convolucionales
*** Introducción

Antes de introducirnos en el mundo de las redes convolucionales es
necesario definir qué es una convolución.

Una matriz de convolución, o \textit{kernel}, es una matriz
generalmente cuadrada y pequeña utilizada extensamente para detectar o
resaltar bordes y enfocar o desenfocar imágenes dependiendo de sus
valores y tamaño. Son muy utilizadas en el mundo de la visión por
computadoras, sobre todo en los pasos de extracción de
\textit{features} de una imagen a la hora de aplicar algoritmos de
aprendizaje automático.

Una convolución entre un \textit{kernel} y una imagen se realiza
sumando las multiplicaciones elemento a elemento entre \textit{kernel}
y una región de la imagen. Por ejemplo, sea \(C\) un \textit{kernel}
de \(3x3\) y \(A\) un pedazo de una imagen también de dimension
\(3x3\), entonces la convolución entre \(C\) y \(A\) (denotada con el símbolo\(*\)) es:

\begin{equation}
C
=
\begin{bmatrix}
    0  & 1 & 0 \\
    1  & -4 & 1 \\
    0  & 1 & 0 \\
\end{bmatrix}
\end{equation}

\begin{equation}
A
=
\begin{bmatrix}
    a  & b & c \\
    d  & e & f \\
    g  & h & i \\
\end{bmatrix}
\end{equation}

\begin{equation}
A * C = (a*0) + (b*1) + (c*0) + (d*1) + (e*-4) + (f*1) + (g*0) + (h*1) + (i*0)
\end{equation}

Observemos dos cosas: 
\begin{enumerate}

\item El resultado de la convolución entre un \textit{kernel} y su
correspondiente pedazo en la imagen (que hasta ahora es de un canal)
es un valor escalar, o sea un píxel correspondiente al canal de la
imagen sobre el cual hayamos convolucionado. Es decir, si
convolucionamos un \textit{kernel} a través de los 3 canales de una
imagen (rojo, verde y azul) vamos a obtener como resultado 3 valores
que se van a combinar para crear un píxel RGB (\textit{Red-Green-Blue}
por sus siglas en inglés).

\item Uno no realiza una sola convolución con un solo pedazo de la imagen,
sino que lo hace sobre \textit{toda} la imagen. Esto significa que el
\textit{kernel} se va "desplazando" a lo largo y ancho de la imagen
para generar, en cada ocasión, un escalar que va a formar parte de la
nueva imagen convolucionada.

\end{enumerate}

**** TODO ejemplos de convoluciones

Las redes convolucionales hacen uso extensivo de estos
\textit{kernels}. De hecho, \textit{aprenden a generar}
\textit{kernels} para encontrar diversas características en las
imágenes, tanto de bajo nivel (bordes o colores) como de alto nivel
(neuronas que se activan cuando una persona sonríe, por ejemplo). Si
sumamos esto con la no linealidad propia de las redes neuronales
artificiales, obtenemos una poderosa herramienta de clasificación de
imágenes.

*** Diferencias con redes neuronales artificales convencionales
Las redes convolucionales cuentan con los mismos artefactos que las
redes convencionales que ya discutimos (neuronas con pesos, funciones
de pérdida, capas completamente conectadas). Incluso los mismos
métodos de entrenamiento pueden ser aplicados. La diferencia radica en
que las redes convolucionales asumen que están trabajando con
imágenes, lo que permite optimizar la arquitectura de las mismas,
reduciendo parámetros y mejorando el proceso de aprendizaje.

Imaginemos por un momento que quisieramos aprender a clasificar un
conjunto de imágenes de 200x200 píxeles con 3 canales de colores. Eso
nos da una dimensión de entrada de 200x200x3, por lo que una neurona
completamente conectada en la primer capa oculta tendría 120000
conexiones y por ende esa misma cantidad de pesos a entrenar. Si
tenemos en cuenta que seguramente vamos a requerir más de una neurona
(comúnmente cientos de ellas en una misma capa) podemos concluir que
este enfoque no escala bien para el procesamiento de imágenes.

Una red neuronal convolucional se aprovecha de la ventaja de que los
datos de entrada son imágenes y organiza las neuronas en 3
dimensiones: ancho, alto y profundidad. Tal como hicimos con las redes
neuronales convencionales, en la siguiente sección analizaremos los
tipos de capas de una red neuronal convolucional. Al final de la
Sección se dará una descripción general de la arquitectura de una red
convolucional y varios ejemplos de redes convolucionales conocidas.

*** Capas de una red convolucional
**** Capas Convolucionales

Una capa convolucional consta de un conjunto de filtros (o
\textit{kernels}) cuyos parámetros se pueden aprender. En general cada
filtro es pequeño a lo ancho y alto, pero se aplica a toda la
profundidad del volumen de entrada. Notar que el volumen de entrada
puede bien ser una imagen o las activaciones de otra capa.

Durante el entrenamiento o la clasificación de imagenes, estos filtros
se convolucionan a traves del ancho y alto de la imagen, produciendo
un mapa de activaciones en 2-D para cada filtro. Si "apilamos" los
mapas de activaciones de todos los filtros de una capa convolucional,
obtenemos un \textit{volumen} de salida.  En otras palabras, se
computa un producto punto entre el filtro y las distintas regiones de
la entrada. De esta manera cada elemento en el volumen de salida puede
ser interpretado como la salida de una neurona conectada a una pequeña
region de los datos de entrada, la cual comparte parámetros (pesos)
con las otras neuronas que corresponden al mismo filtro.

Esta conexión a una pequeña región en los datos de entrada es un
hiperparámetro de la red llamado \textit{campo receptivo}. Es
importante notar que los \textit{campos receptivos} son locales en una
pequeña área en cuanto al ancho y alto de la entrada, pero abarcan la
totalidad de la profundidad del volumen de entrada.

Otros hiperparámetros relacionados con las capas convolucionales son
la cantidad de filtros (\textit{K}), el espacio en píxeles entre cada
aplicacion de los filtros (\textit{stride}) y por ultimo el relleno
con ceros o \textit{zero-padding}, donde se le agrega un "marco" de 1
o más ceros a la entrada de la capa.
***** TODO dibujos de capaz convolucionales
**** \textit{Pooling}

Las capas de \textit{pooling} reducen la dimensión espacial de sus
entradas y por ende reducen la cantidad de parametros en la red,
ayudando a controlar el \textit{overfitting}. Lo más común es
insertar capas de \textit{pooling} luego de capas convolucionales.

Un método de \textit{pooling} muy usado es \textit{MAX Pooling}, en el
cual se calcula el máximo de un área local (generalmente 2x2 o 3x3) en
el ancho y largo del volumen de entrada y a través de cada una de las
"rodajas" que conforman la profundidad del volumen. De esta manera se
reduce espacialmente la entrada, pero no su profundidad.
***** TODO dibujo de pooling
**** Capas Completamente Conectadas (Fully-Connected)

Como su nombre lo indica, cada neurona de esta capa tiene conexiones a
todas las salidas (o activaciones) de la capa anterior. Por lo tanto
sus activaciones se pueden calcular con una multiplicacion de matrices
junto con el calculo del \textit{bias}, como ya se vio para las redes
neuronales convencionales.

*** Arquitecturas conocidas de redes convolucionales 

Normalmente una red convolucional esta compuesta de varias capas
convolucionales (CONV), capas de \textit{pooling} (POOL), capas
completamente conectadas (FC por sus siglas en ingles) y funciones de
activacion, generalmente rectificadores lineales (RELU).

El patron usual en redes convolucionales es una capa CONV seguida de
una capa RELU seguida de una capa de \textit{pooling}. Esto se repite
una o varias veces hasta reducir espacialmente las dimensiones de la
entrada de la red. Luego es comun utilizar capas FC hasta reducir las
dimensiones a las dimensiones de salida, que en el caso de
clasificacion son las probabilidades de cada clase.

A lo largo de los años ha habido varias arquitecturas de redes
convolucionales que cuentan con nombre propio, como por ejemplo LeNet
\cite{Lecun98gradient-basedlearning}, creada en los 90 por Yann LeCun
y utilizada para el reconocimiento de digitos manuscriptos. Esta red
fue utilizada con exito para leer codigos postales y cheques
bancarios.

En 2012, el ganador del desafio ImageNet ILSVRC, Alex Krizhevsky,
obtuvo un 16% de error utilizando una arquitectura llamada AlexNet
\cite{NIPS2012_4824}. Su arquitectura es muy similar a la de LeNet,
aunque mas profunda y fue una de las primeras en concatenar varias
capas CONV antes de una capa de \textit{pooling}.

Los ganadores del ISLVRC 2013 utilizaron una red llamada ZFNet
\cite{DBLP:journals/corr/ZeilerF13}, que era basicamente una
modificacion de AlexNet, con cambios en los hiperparametros y las
capas convolucionales.

En la misma competencia ILSVRC del 2014 se dieron a conocer dos redes,
GoogLeNet \cite{43022} y VGGNet \cite{Simonyan14c}. Ambas demostraron
que la profundidad de la red es una caracteristica critica a la hora
de obtener buenos resultados.

Si bien GoogLeNet fue la ganadora ese año, luego se demostro que
VGGNet es superior en muchas tareas de transferencia de aprendizaje,
por lo que es mas popular que GoogLeNet y se pueden encontrar muchos
modelos ya preentrenados.

Finalmente, ResNet (Residual Network) \cite{he15deepresidual}, la red
ganadora del ILSRVC 2015, cuenta con nada menos que 152 capas (VGGNet
cuenta con 19) y obteniendo un error de 3.57% en el top-5.

* Redes neuronales siamesas
#+LaTeX: \label{sec:siamesa}
* Entrenamiento de modelos de aprendizaje profundo utilizando información odométrica
#+LaTeX: \label{sec:odometry}
** datasets, de que son, sobre que cosa van a entrenar (predecir cambios en la imagen)
** Egomotion
** SFA

* Conclusiones 
#+LaTeX: \label{sec:concl}
* Plan de Trabajo                                :noexport:
** Datasets
1. MINST: http://yann.lecun.com/exdb/mnist/

2. KITTI (odometry): http://www.cvlibs.net/datasets/kitti/eval_odometry.php

3. SF: aparentemente es un challenge de ICMLA 2011, hay que mandar un mail para pedirlo: http://www.icmla-conference.org/icmla11/challenge.htm

4. ILSVRC2012: http://www.image-net.org/download-images (hay que crearse una cuenta)

** Prueba de Concepto con MNIST
DEADLINE: <2016-04-29 vie> 

EL objetivo es entender como hacer redes siamesas con Caffe

*** [100%] Preprocesamiento
Train set: 60K imagenes. Test set 10K imagenes.

Para pretraining de la red, hay que hacer un preprocesamiento del
dataset:
  1. Traslación relativa en un rango de [-3,3]
  2. Rotación relativa en un rango de [-30°,30°]
Tanto las traslaciones como las rotaciones fueron hechas con numeros
enteros (es decir, los angulos son -30º,-29º,-28º,..,29,30; igual para
las traslaciones).

Para cada par nuevo creado se eligieron las traslaciones y rotaciones
de manera aleatoria, de manera que cada par esta compuesto por la
imagen original y la imagen transformada aleatoriamente.

En total entrenaron con 5 millones de pares de imagenes. Eso significa
que hay que hacer 85 pares para 10000 imagenes y 83 pares para las
otras 50000 imagenes.

DUDA: no queda claro en el paper si el par esta compuesto por la
imagen original mas la imagen transformada o si esta compuesto por una
imagen previamente transformada a la cual se le hace una
transformacion relativa. Por lo pronto voy a efectuar el experimento
con la original+transformada.
**** DONE Crear codigo (c++) para levantar MNIST y devolver una lista de Mat's
**** DONE Modificar codigo para crear las transformaciones de rotacion y traslacion (OpenCV)
**** DONE Hacer que las rotaciones y traslaciones sean aleatorias
**** DONE Modificar codigo para guardar lmdb
**** DONE Modificar algunos aspectos de la parte de lmdb para guardar las nuevas imagenes (dos imagenes mergeadas en una, dimensiones: 28x28x2)
**** DONE Investigar como guardar multiples etiquetas por imagen (traslacion y rotacion)
https://groups.google.com/forum/#!searchin/caffe-users/multilabel/caffe-users/RuT1TgwiRCo/hoUkZOeEDgAJ
https://github.com/BVLC/caffe/issues/2407

Se probaron varias cosas:
***** Armar una DB para cada label (X,Y y Z) pero no anduvo
***** Armar una sola DB para todas las labels y despues slicearla pero no anduvo
para cada clase crear array de bytes asi: 0 0 0 1 donde si hay un cero
significa que esa label esta inactiva y si hay 1 significa que esta
activa

Va a haber un solo 1 por clase claramente

Entonces agarro y creo la base de datos de labels nomas, con la
dimension a lo ancho que sea la dimension de la clase de mayor tama;o
(en este caso las rotaciones, que son 61) y la profundidad que sea la
cantidad de clases a clasificar (en este caso 3: X, Y y Z).

Luego Sliceo la base de datos y con la capa ArgMax obtengo el indice
del mayor elemento de ese arreglo, que termina siendo la clase a la
que corresponde la imagen. A ese argmax obtenido lo mando a la capa de
accuracy/softmax por ejemplo

***** Armar una sola DB para datos y labels y despues slicear los labels
*** [66%] Entrenamiento
**** DONE Armar la red (.prototxt) teniendo en cuenta el Slice, los multiple Softmax y loss
Slice de los labels:
https://groups.google.com/forum/#!searchin/caffe-users/multilabel/caffe-users/RuT1TgwiRCo/hoUkZOeEDgAJ

BCCN: C96-P-C256-P
TCCN: F1000-D-Op

Para finetuning: BCCN-F500-D-Op

Para SFA, los valores optimos del parámetro m fueron 10 y 100.

La predicción es clasificación con tres capas soft-max loss (para
traslaciones en X,Y y rotacion en Z respectivamente). Cada SCNN
minimiza la suma de estas tres "losses".

Para que se pueda utilizar clasificación, hay que dividir los rangos
de traslación en en 7 classes y las rotaciones en 20 clases (donde
cada una corresponde a 3°)

Para MNIST, hay que tomar a las imágenes cuya traslación relativa esté
entre [-1,1] y rotación relativa entre [-3°,3°] como temporalmente
cercanas (es el parámetro T de la ecuación en la sección 3.3 del
paper).

**** DONE Iteraciones, learning rate, step
Para pretraining: 40K iteraciones con learning rate inicial de 0.01,
reducido en un factor de 2 cada 10K iteraciones.

Para finetuning: 4K iteraciones con un learning rate constante de
0.01.
**** TODO [84%] Experimentos a realizar
Todos se basan en el pre-entrenamiento descripto en el item y luego
finetuning.

Tanto para egomotion como para SFA, el pretraining se hizo durante 40K
iteraciones, con batches de 125 (5millones de imagenes.)

***** DONE Crear lmdb con 100, 300, 1000 y 10000 imagenes para testing
***** DONE Crear lmdb con 5m de pares de imagenes para egomotion
***** DONE Entrenar Egomotion, lr 0.01. 40K iter
***** DONE Entrenar Egomotion, lr 0.001. 40K iter
***** DONE Entrenar SFA, lr 0.01. 40K iter
***** DONE Entrenar SFA, lr 0.001. 40K iter

***** DONE Egomotion, lr 0.01. Finetuning con 100 imagenes lr 0.01
***** DONE Egomotion, lr 0.01. Finetuning con 300 imagenes lr 0.01
***** DONE Egomotion, lr 0.01. Finetuning con 1000 imagenes lr 0.01
***** DONE Egomotion, lr 0.01. Finetuning con 10000 imagenes lr 0.01
***** DONE Egomotion, lr 0.01. Finetuning con 100 imagenes lr 0.001
***** DONE Egomotion, lr 0.01. Finetuning con 300 imagenes lr 0.001
***** DONE Egomotion, lr 0.01. Finetuning con 1000 imagenes lr 0.001
***** DONE Egomotion, lr 0.01. Finetuning con 10000 imagenes lr 0.001

***** DONE Egomotion, lr 0.001. Finetuning con 100 imagenes lr 0.01
***** DONE Egomotion, lr 0.001. Finetuning con 300 imagenes lr 0.01
***** DONE Egomotion, lr 0.001. Finetuning con 1000 imagenes lr 0.01
***** DONE Egomotion, lr 0.001. Finetuning con 10000 imagenes lr 0.01
***** DONE Egomotion, lr 0.001. Finetuning con 100 imagenes lr 0.001
***** DONE Egomotion, lr 0.001. Finetuning con 300 imagenes lr 0.001
***** DONE Egomotion, lr 0.001. Finetuning con 1000 imagenes lr 0.001
***** DONE Egomotion, lr 0.001. Finetuning con 10000 imagenes lr 0.001
***** DONE Egomotion, lr 0.001. Finetuning con 100 imagenes lr 0.0001
***** DONE Egomotion, lr 0.001. Finetuning con 300 imagenes lr 0.0001
***** DONE Egomotion, lr 0.001. Finetuning con 1000 imagenes lr 0.0001
***** DONE Egomotion, lr 0.001. Finetuning con 10000 imagenes lr 0.0001

***** DONE SFA, lr 0.01. Finetuning con 100 imagenes lr 0.01
***** DONE SFA, lr 0.01. Finetuning con 300 imagenes lr 0.01
***** DONE SFA, lr 0.01. Finetuning con 1000 imagenes lr 0.01
***** DONE SFA, lr 0.01. Finetuning con 10000 imagenes lr 0.01
***** DONE SFA, lr 0.01. Finetuning con 100 imagenes lr 0.001
***** DONE SFA, lr 0.01. Finetuning con 300 imagenes lr 0.001
***** DONE SFA, lr 0.01. Finetuning con 1000 imagenes lr 0.001
***** DONE SFA, lr 0.01. Finetuning con 10000 imagenes lr 0.001

***** DONE SFA, lr 0.001. Finetuning con 100 imagenes lr 0.01
***** DONE SFA, lr 0.001. Finetuning con 300 imagenes lr 0.01
***** DONE SFA, lr 0.001. Finetuning con 1000 imagenes lr 0.01
***** DONE SFA, lr 0.001. Finetuning con 10000 imagenes lr 0.01
***** DONE SFA, lr 0.001. Finetuning con 100 imagenes lr 0.001
***** DONE SFA, lr 0.001. Finetuning con 300 imagenes lr 0.001
***** DONE SFA, lr 0.001. Finetuning con 1000 imagenes lr 0.001
***** DONE SFA, lr 0.001. Finetuning con 10000 imagenes lr 0.001
***** DONE SFA, lr 0.001. Finetuning con 100 imagenes lr 0.0001
***** DONE SFA, lr 0.001. Finetuning con 300 imagenes lr 0.0001
***** DONE SFA, lr 0.001. Finetuning con 1000 imagenes lr 0.0001
***** DONE SFA, lr 0.001. Finetuning con 10000 imagenes lr 0.0001

***** TODO Entrenamiento standar desde cero, lr 0.01. Finetuning con 100 imagenes
***** TODO Entrenamiento standar desde cero, lr 0.01. Finetuning con 300 imagenes
***** TODO Entrenamiento standar desde cero, lr 0.01. Finetuning con 1000 imagenes
***** TODO Entrenamiento standar desde cero, lr 0.01. Finetuning con 10000 imagenes
***** TODO Entrenamiento standar desde cero, lr 0.001. Finetuning con 100 imagenes
***** TODO Entrenamiento standar desde cero, lr 0.001. Finetuning con 300 imagenes
***** TODO Entrenamiento standar desde cero, lr 0.001. Finetuning con 1000 imagenes
***** TODO Entrenamiento standar desde cero, lr 0.001. Finetuning con 10000 imagenes
*** Evaluación
Las features obtenidas de las BCNN preentrenadas se evaluan teniendo
en cuenta el error en la clasificación de dígitos.  Se utilizan
conjuntos de entrenamiento de 100,300, 1K y 10K obtenidos del training
set de MNIST (sin transformaciones).  El test set que viene con MNIST
se utiliza para testing.

** Experimentos con KITTI y SF
*** Preprocesamiento
DEADLINE: <2016-05-13 vie>

Analizar como se eligen las clases (es un problema de
clasificacion). Hacer todos los scripts de preprocesamiento.
Crear las lmdb.

**** KITTI
Tiene 20501 imágenes. Se calculan las transformaciones entre las
imágenes cercanas utilizando los datos odométricos del dataset.
Similar a MNIST: se crean 20 clases para las transformaciones en X,Y,Z
(el paper no explica como). Se toman imágenes que estén separadas a lo
sumo por +-7 frames.  Para el entrenamiento se extraen patches de
227x227 de las imágenes (Caffe tiene la opcion de cropear la imagen a
la hora de entrenar, pero no se como se aplica a redes siamesas,
probablemente tenga que hacerlo como parte del preprocesamiento).

Para SFA, el threshold para imágenes temporalmente cercanas (T) es
también de +-7
El numero total de imagenes usadas para entrenamiento es 20501

**** SF
Análogo a KITTI, solo que además de las transformaciones en X,Y,Z
agregan los 3 "euler angles" (no entendi eso).

*** Arquitectura
BCNN: C96-P-C256-P-C384-C384-C256-P (dice que estan inspiradas en las
primeras capas de AlexNet, extraer tamaño de filtros de esa red)
TCNN: C256-C128-F500-D-Op. Los kernels convolucionales con 3x3.

*** Entrenamiento
DEADLINE: <2016-05-31 mar>
Se entrena por 60K iteraciones con batch size de 128, learning rate
inicial de 0.001 (reducido en un factor de 2 cada 20K iteraciones)

*** Evaluación
Los modelos KITTI-Net y SF-Net deben ser entrenados utilizando
alrededor de 20K imagenes unicas. Para hacer la comparacion mas justa
con las redes entrenadas con clases de imagenes, un model con AlexNet
sera entrenado con 20K imagenes tomadas de ILSVRC12 (20 ejemplos por
clase).  Las secciones de evaluacion en Intra-Class Keypoint Matching
y Visual Odometry los dejo para mas adelante.
**** Scene Recognition
Utilizar SUN database para el finetuning de las redes (SF-Net,
KITTI-Net y AlexNet-20K). El paper no aporta informacion sobre la
cantidad de iteraciones ni el learning rate usado.  Referirse al paper
para comparar resultados obtenidos.
**** Object Recognition
Utilizando subconjuntos de ILSVRC-2012 con 1, 5, 10 y 20 imagenes por
clase, hacer finetuning de KITTI-Net, KITTI-SFA-Net y AlexNet-Scratch
(AlexNet con pesos inicializados de manera aleatoria). Nuevamente el
paper no explica las iteraciones ni el learning rate utilizados.
** Mejoras al sistema
DEADLINE: <2016-06-17 vie>
Probar con otras redes.
Otros datasets (elegir datasets pequeños y ver que pasa).

* Bibliografía
#+LaTeX: \bibliographystyle{abbrv}
#+LaTex: \bibliography{MarcoTeorico}
