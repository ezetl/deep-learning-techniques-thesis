name: "MNIST"
layer {
  name: "data"
  type: "Data" 
  top: "data"
  include {
    phase: TRAIN
  }
  #transform_param {
  #  mean_file: "../data/mean_mnist.binaryproto"
  #}
  data_param {
    source: "/media/eze/Datasets/MNIST/mnist_train_egomotion_lmdb"
    batch_size: 512 
    backend: LMDB
  }
}

layer {
  name: "data"
  type: "Data" 
  top: "data"
  include {
    phase: TEST
    stage: "test-on-train"
  }
  data_param {
    source: "/media/eze/Datasets/MNIST/mnist_train_egomotion_lmdb"
    batch_size: 512 
    backend: LMDB
  }
}


layer {
    name: "slice_data"
    type: "Slice"
    bottom: "data"
    top: "data0"
    top: "data1"
    top: "labelx"
    top: "labely"
    top: "labelz"
    slice_param {
      axis: 1
      slice_point: 1 
      slice_point: 2
      slice_point: 3
      slice_point: 4
    }
}

layer {
  name: "argmaxX"
  type: "ArgMax"
  bottom: "labelx"
  top: "argmxX"
}

layer {
  name: "argmaxY"
  type: "ArgMax"
  bottom: "labely"
  top: "argmxY"
}

layer {
  name: "argmaxZ"
  type: "ArgMax"
  bottom: "labelz"
  top: "argmxZ"
}


# First component of siamese network
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data0"
  top: "conv1"
  param {
    name: "conv1_w"
    lr_mult: 1
    decay_mult: 1
  }
  param {
    name: "conv1_b"
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 96
    kernel_size: 11 
    stride: 4
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}

layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}

layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}

layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  param {
    name: "conv2_w"
    lr_mult: 1
    decay_mult: 1
  }
  param {
    name: "conv2_b"
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256 
    pad: 2
    group: 2
    kernel_size: 5
    # stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
} 

layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}


#layer {
#  name: "pool2"
#  type: "Pooling"
#  bottom: "conv2"
#  top: "pool2"
#  pooling_param {
#    pool: MAX
#    kernel_size: 3
#    stride: 2
#  }
#}


# Second component of siamese network
layer {
  name: "conv1_p"
  type: "Convolution"
  bottom: "data1"
  top: "conv1_p"
  param {
    name: "conv1_w"
    lr_mult: 1
    decay_mult: 1
  }
  param {
    name: "conv1_b"
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 96
    kernel_size: 11 
    stride: 4
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}

layer {
  name: "relu1_p"
  type: "ReLU"
  bottom: "conv1_p"
  top: "conv1_p"
}

layer {
  name: "pool1_p"
  type: "Pooling"
  bottom: "conv1_p"
  top: "pool1_p"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}

layer {
  name: "conv2_p"
  type: "Convolution"
  bottom: "pool1_p"
  top: "conv2_p"
  param {
    name: "conv2_w"
    lr_mult: 1
    decay_mult: 1
  }
  param {
    name: "conv2_b"
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256 
    pad: 2
    group: 2
    kernel_size: 5
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
} 

layer {
  name: "relu2_p"
  type: "ReLU"
  bottom: "conv2_p"
  top: "conv2_p"
}


#layer {
#  name: "pool2_p"
#  type: "Pooling"
#  bottom: "conv2_p"
#  top: "pool2_p"
#  pooling_param {
#    pool: MAX
#    kernel_size: 3 
#    stride: 2
#  }
#}



layer {
  name: "concat"
  bottom: "conv2"
  bottom: "conv2_p"
  top: "concat"
  type: "Concat"
  concat_param {
    axis: 1
  }
}


layer {
  bottom: "concat"
  top: "fcn"
  name: "fcn"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  type: "InnerProduct"
  inner_product_param {
    num_output: 1000 
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}

layer {
  name: "relu3"
  type: "ReLU"
  bottom: "fcn"
  top: "fcn"
}

layer {
  name: "drop"
  type: "Dropout"
  bottom: "fcn"
  top: "fcn"
  dropout_param {
    dropout_ratio: 0.5
  }
}




layer {
  bottom: "fcn"
  top: "fcnx"
  name: "fcnx"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  type: "InnerProduct"
  inner_product_param {
    num_output: 7 
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}

layer {
  bottom: "fcn"
  top: "fcny"
  name: "fcny"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  type: "InnerProduct"
  inner_product_param {
    num_output: 7 
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}

layer {
  bottom: "fcn"
  top: "fcnz"
  name: "fcnz"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  type: "InnerProduct"
  inner_product_param {
    num_output: 20
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}

layer {
  name: "loss_x"
  type: "SoftmaxWithLoss"
  bottom: "fcnx"
  bottom: "argmxX"
  top: "loss_x"
  loss_weight:1
  include {
      phase: TRAIN
    }
}

layer {
  name: "loss_y"
  type: "SoftmaxWithLoss"
  bottom: "fcny"
  bottom: "argmxY"
  top: "loss_y"
  loss_weight:1
  include {
      phase: TRAIN
    }
}

layer {
  name: "loss_z"
  type: "SoftmaxWithLoss"
  bottom: "fcnz"
  bottom: "argmxZ"
  top: "loss_z"
  loss_weight:1
  include {
      phase: TRAIN
    }
}


### TEST NETWORK ON TRAIN SET
layer {
  name: "test_loss_x"
  type: "SoftmaxWithLoss"
  bottom: "fcnx"
  bottom: "argmxX"
  top: "test_loss_x"
  loss_weight:1
  include {
    phase: TEST
    stage: "test-on-train"
  }
}

layer {
  name: "test_loss_y"
  type: "SoftmaxWithLoss"
  bottom: "fcny"
  bottom: "argmxY"
  top: "test_loss_y"
  loss_weight:1
  include {
    phase: TEST
    stage: "test-on-train"
  }
}

layer {
  name: "test_loss_z"
  type: "SoftmaxWithLoss"
  bottom: "fcnz"
  bottom: "argmxZ"
  top: "test_loss_z"
  loss_weight:1
  include {
    phase: TEST
    stage: "test-on-train"
  }
}

layer {
  name: "accuracy_X"
  type: "Accuracy"
  bottom: "fcnx"
  bottom: "argmxX"
  top: "accuracy_X"
  include {
    phase: TEST
    stage: "test-on-train"
  }
}

layer {
  name: "accuracy_Y"
  type: "Accuracy"
  bottom: "fcny"
  bottom: "argmxY"
  top: "accuracy_Y"
  include {
    phase: TEST
    stage: "test-on-train"
  }
}

layer {
  name: "accuracy_Z"
  type: "Accuracy"
  bottom: "fcnz"
  bottom: "argmxZ"
  top: "accuracy_Z"
  include {
    phase: TEST
    stage: "test-on-train"
  }
}
